
*****

####  月初照  
##### 1#       楼主       发表于 2023-3-13 13:28

我们一直认为，如今的AI没有发展为强AI的可能性。其主要原因是目前并没有强AI的理论支持，如果都不知道设计的原理，那应该是无法设计出来的吧？

但是我以前接触过一个理论叫做涌现理论，指的是大量物质在特定规则下互动产生远远超出单体时的特殊属性，比如分子振动产生热，水分子集合产生湿，很多蚂蚁组成了行为复杂的蚂蚁群落，大量的人组成了性质极其复杂，运行难以用简单规律描述的社会。

老祖宗打败尼人和其他人科亲戚，靠的也是人数更多，更为复杂精致的部落。

那么，如今的神经网络以巨大的模型为基础，得到的运行性质是否也是一种涌现？而强AI就在这涌现的尽头？

*****

####  modedd  
##### 2#       发表于 2023-3-13 13:30

强AI快成可控核聚变了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  sevenight  
##### 3#       发表于 2023-3-13 13:31

嗯，机械飞升已经开始了

*****

####  ジュリア  
##### 4#       发表于 2023-3-13 13:33

意识是不是大规模非线性网络的涌现特质是没定论，我自己觉得是赞成的，如果属实那强AI只是时间问题，下一步多模态立刻就应该看到未来的苗头了

*****

####  sevenight  
##### 5#       发表于 2023-3-13 13:52

未来已来，为何不拜

*****

####  与天争锋_LZ  
##### 6#       发表于 2023-3-13 14:01

真有强ai我建议人类全体爆金币

*****

####  免疫洼地  
##### 7#       发表于 2023-3-13 14:14

我觉得马上就要来了

*****

####  yesicant  
##### 8#       发表于 2023-3-13 14:20

 本帖最后由 yesicant 于 2023-3-13 14:24 编辑 

<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">涌现可不是我寻思，可解释性不足是真的会有性能上限的，现在的大模型学术前沿都走不下去纷纷换稀疏激活和专家协作系统了，还涌现呢，逻辑推理，记忆因果，一个都没搞成

可解释性搞不明白，连大炮仗都别想做出来

﹍﹍﹍

评分

 参与人数 2战斗力 +2

|昵称|战斗力|理由|
|----|---|---|
| 江月下| + 1||
| 中二小旋风| + 1||

查看全部评分

*****

####  Aomina  
##### 9#       发表于 2023-3-13 14:24

还早或者早就来了，只是让你感觉还早

*****

####  qq2007ssy  
##### 10#       发表于 2023-3-13 14:27

学术前沿哪来那么多资源搞大模型啊，真大模型还得看企业

*****

####  cauchua  
##### 11#       发表于 2023-3-13 14:28

现在AI围棋能指导人类棋手下棋，为啥没人找chatgpt学说话？

*****

####  本间心铃  
##### 12#       发表于 2023-3-13 14:28

先把车轱辘胡话乱编，千手观音美少女解决了吧。。。

*****

####  鲤鱼奶奶  
##### 13#       发表于 2023-3-13 14:30

来不怕，就怕到时候没中国什么事就惨了。

*****

####  cauchua  
##### 14#       发表于 2023-3-13 14:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60069929&amp;ptid=2123866" target="_blank">鲤鱼奶奶 发表于 2023-3-13 14:30</a>

来不怕，就怕到时候没中国什么事就惨了。</blockquote>
怕啥，燃油车也基本没中国什么事，后来不还是弯道超车

*****

####  abcbuzhiming  
##### 15#       发表于 2023-3-13 14:33

首先，如果你指的强ai，是指的工作原理和人脑差不多的AI，那人类的距离还远的很。但是如果要取代人类的工作的话。一定非要那种强ai吗？我的看法就是未必，历史上有一个很明显的案例，就是飞行，人类最开始学习飞行的时候完全就是照着鸟类来的，几乎所有的技术路线发展都是在模仿鸟类。但是人类搞清楚鸟类飞行的真正原理。并照出对应的扑翼机，是非常晚的事情。在此之前。和两类飞行原理完全不同的固定翼飞机。其飞行性能已经打败了最强的鸟。而和鸟类飞行原理一样的扑翼机。并没有在人类社会中得到应用，所以我个人认为。很可能将来击败人类大脑的所谓的AI，其工作原理和人类的大脑完全不一样

*****

####  勿徊哉  
##### 16#       发表于 2023-3-13 14:34

至少深度学习是涌现不出来强人工智能，没有因果关系不会逻辑推理。

要说“智能”的话那确实有。别说神经网络了，最简单的蚂蚁算法都让我有涌现出智能的感觉。

*****

####  novalli  
##### 17#       发表于 2023-3-13 14:36

标准答案：不知道。
这些东西目前还在提出假说的阶段，没办法做出预测，只能等理论进一步完善或者等强AI出现并被人类认知之后总结了。

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  黄昏之月  
##### 18#       发表于 2023-3-13 14:36

人类的意识和动物的意识也仅仅是复杂程度的不同。

所以AI训练亿级数据到十亿级数据出现飞跃可能也是必然的。

*****

####  novalli  
##### 19#       发表于 2023-3-13 14:38

关于AI有很多原理上、理论上甚至哲学上的讨论，可以先去看看。不过先说一下，这些书不好读，而且目前来看以英语为主。

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  黑色天鹅  
##### 20#       发表于 2023-3-13 14:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60069898&amp;ptid=2123866" target="_blank">cauchua 发表于 2023-3-13 14:28</a>

现在AI围棋能指导人类棋手下棋，为啥没人找chatgpt学说话？</blockquote>
未必，利用chatgpt改善自闭症患者社交能力的研究已经在路上了。

*****

####  yesicant  
##### 21#       发表于 2023-3-13 14:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60069961&amp;ptid=2123866" target="_blank">abcbuzhiming 发表于 2023-3-13 14:33</a>
首先，如果你指的强ai，是指的工作原理和人脑差不多的AI，那人类的距离还远的很。但是如果要取代人类的工作 ...</blockquote>
现在的AI技术线路已经和人类有大不同了，本质都是把大脑的功能拆分抽象出来，用各种不同的方法实现，无论是预测下一个词，还是卷积，又或者扩散，clip，注意力，cot都是这样的，这样抽象出来的模型非常专用而且特化程度高，非常容易超越人类极限，大模型之路反而是走了回去，之前有一篇论文，标题写的明白【ChatGPT: Jack of all trades, master of none】，这是需求模型深度的人类完全无法接受的，大概率之后还是继续拆分任务，做弗兰肯斯坦

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  Reon  
##### 22#       发表于 2023-3-13 14:40

 本帖最后由 Reon 于 2023-3-13 14:42 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60069158&amp;ptid=2123866" target="_blank">modedd 发表于 2023-3-13 13:30</a>

强AI快成可控核聚变了</blockquote>
刚好算类似方向的打工人，可控核聚变的实现，AI模型本身创新有限，主要是如何软件精准模拟核变的环境，这种基础工业研究方向，我们还是差挺多的

*****

####  xell2alex  
##### 23#       发表于 2023-3-13 14:42

有一种说法，阻碍AI飞升的最后一道坎就是目前还是用图片、文字、数据等间接信息训练AI，如果给AI装上视觉、听觉、触觉等感受器让它直接接触外部世界的话，那AI的进化将不可遏制

*****

####  lvcha  
##### 24#       发表于 2023-3-13 14:47

我觉得差得远。目前还只是知识的搬运工

*****

####  大主教伊瑞尔  
##### 25#       发表于 2023-3-13 14:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60069898&amp;ptid=2123866" target="_blank">cauchua 发表于 2023-3-13 14:28</a>

现在AI围棋能指导人类棋手下棋，为啥没人找chatgpt学说话？</blockquote>
为什么你会觉得没有人找chatgpt学说话？让他生产各种公文样板然后抄作业明明是主要应用场景之一<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  chexk03  
##### 26#       发表于 2023-3-13 15:07

说实话现在的Ai，无论是阿尔法狗还是现在的AI绘图，我都搞不懂原理，真的是普通人学习个几十年就能搞懂的么…

*****

####  chexk03  
##### 27#       发表于 2023-3-13 15:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60070203&amp;ptid=2123866" target="_blank">大主教伊瑞尔 发表于 2023-3-13 14:51</a>
为什么你会觉得没有人找chatgpt&amp;#x ...</blockquote>
如果显卡能像炼AI绘图一样，炼chatgpt出各种公文，我马上搞张4090回来，才写XX讲话稿写的头秃<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

*****

####  十块钱惠顾  
##### 28#       发表于 2023-3-13 15:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60070414&amp;ptid=2123866" target="_blank">chexk03 发表于 2023-3-13 15:07</a>

说实话现在的Ai，无论是阿尔法狗还是现在的AI绘图，我都搞不懂原理，真的是普通人学习个几十年就能搞懂的么 ...</blockquote>
lz说的涌现就是解释这个的，人以后是没法理解ai的工作原理的，甚至ai也解释不出

*****

####  lg19850717  
##### 29#       发表于 2023-3-13 15:13

chatgpt和强ai，从接口角度，并无区别

所以即使以后有强ai，拿出卖也就是chatgpt++++

所以不用纠结什么强ai了，未来就是现在

*****

####  maitsuki  
##### 30#       发表于 2023-3-13 15:14

<blockquote>chexk03 发表于 2023-3-13 15:09
如果显卡能像炼AI绘图一样，炼chatgpt出各种公文，我马上搞张4090回来，才写XX讲话稿写的头秃 ...</blockquote>
你直接注册/买一个号问他就行了，免费号有大概几百字的限制，一次一次的问自己整理就是了


*****

####  猪突猛进  
##### 31#       发表于 2023-3-13 15:17

为时已晚，有机体！

*****

####  lg19850717  
##### 32#       发表于 2023-3-13 15:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60070055&amp;ptid=2123866" target="_blank">yesicant 发表于 2023-3-12 18:40</a>

现在的AI技术线路已经和人类有大不同了，本质都是把大脑的功能拆分抽象出来，用各种不同的方法实现，无论 ...</blockquote>
那篇文章问题很大

sota都是专用模型，chatgpt的prompt里面只让zero-shot，这个怎么说呢，不公平，如果要得出这个结论，至少prompt里面给的例子要把prompt给撑满，否则就不是让美军陆战队赤手空拳和全副武装的**对打么

*****

####  jojog  
##### 33#       发表于 2023-3-13 15:31

<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">我觉得迟早得真出现机魂

你咋不知道机械神教那一通拜就是给chatgpt设定role呢

*****

####  不见不散  
##### 34#       发表于 2023-3-13 15:32

为时尚早，面包机

----发送自 [STAGE1 App for Android.](http://stage1.5j4m.com/?1.37)

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| ltycomputer| + 1|欢乐多|

查看全部评分

*****

####  三尖酸努努  
##### 35#       发表于 2023-3-13 15:42

现在还早着呢

*****

####  yesicant  
##### 36#       发表于 2023-3-13 15:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60070720&amp;ptid=2123866" target="_blank">lg19850717 发表于 2023-3-13 15:30</a>
那篇文章问题很大

sota都是专用模型，chatgpt的prompt里面只让zero-shot，这个怎么说呢，不公平，如果要 ...</blockquote>
sota也可以并联，具体可以参考小冰链这样的灰箱子，不如说这样的多级模型可以兼顾参数小性能高，而即使few shot之后chatgpt能力不足也是事实，大模型之路可能反而更难走

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  泥鳅化石  
##### 37#       发表于 2023-3-13 16:03

别提强AI了，现在每个人都有手机这种个人终端，就人脑的不靠谱程度每个行业有能够帮忙的记录助力帮助记载解释专有名词行业规定辅助常识等等功能，很多行业生产力就能提高不少。毕竟很多人因为面子问题不愿意问问题，但是有个不会抱怨的万能的答疑机器可是很高兴的。但是目前看别说技能辅助了，互联网上的有用信息都越来越少了。手机这玩意普及率虽然高对生产力的辅助比电脑可差远了。

—— 来自 HUAWEI OXF-AN10, Android 10上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  godke  
##### 38#       发表于 2023-3-13 16:16

没有，类脑研究还没什么突破性进展。

*****

####  godke  
##### 39#       发表于 2023-3-13 16:16

没有，类脑研究还没什么突破性进展。

*****

####  雷囧羊  
##### 40#       发表于 2023-3-13 16:33

涌现理论，这名字就很玄学的玩意科学不科学先摆一边

蚂蚁能聚成群落也是蚂蚁的特性

苍蝇聚成群了会有苍蝇女王吗？

你怎么判断chatgpt是蚂蚁还是苍蝇

还要靠那么多非洲数据奴工打标签呢

*****

####  内务部的阿尔金  
##### 41#       发表于 2023-3-13 16:35

是先有定义，还是先有存在<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">

*****

####  Spin-Up  
##### 42#       发表于 2023-3-13 16:42

深度学习是上世纪五六十年代提出来的吧<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">，哪怕有新模型新思路，可能需要很多年的发展，不知道泥潭宅宅们有没有机会看到

*****

####  RinQ0326  
##### 43#       发表于 2023-3-13 16:51

<blockquote>泥鳅化石 发表于 2023-3-13 16:03
别提强AI了，现在每个人都有手机这种个人终端，就人脑的不靠谱程度每个行业有能够帮忙的记录助力帮助记载解 ...</blockquote>
我挺愿意问的，从线上问到线下的结果就是问过的人都觉得我太烦了像个傻逼，所以chargpt真的是救我于水火之中。

*****

####  快乐好难123  
##### 44#       发表于 2023-3-13 17:03

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60070458&amp;ptid=2123866" target="_blank">chexk03 发表于 2023-3-13 15:09</a>

如果显卡能像炼AI绘图一样，炼chatgpt出各种公文，我马上搞张4090回来，才写XX讲话稿写的头秃 ...</blockquote>
我每天的日报都是靠这个写的，网页是没限制的，但是不方便（低响应优先度+输入长度有限制）

*****

####  abcbuzhiming  
##### 45#       发表于 2023-3-13 19:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60070458&amp;ptid=2123866" target="_blank">chexk03 发表于 2023-3-13 15:09</a>

如果显卡能像炼AI绘图一样，炼chatgpt出各种公文，我马上搞张4090回来，才写XX讲话稿写的头秃 ...</blockquote>
写八股文已经是chatgpt的主要应用方向

*****

####  自旋  
##### 46#       发表于 2023-3-13 20:00

有没有可能，OpenAI和微软隐瞒了真正的核心技术、大语言模型是个幌子，或者只是个辅助技术？

*****

####  绿茶与猫  
##### 47#       发表于 2023-3-13 20:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60070458&amp;ptid=2123866" target="_blank">chexk03 发表于 2023-3-13 15:09</a>
如果显卡能像炼AI绘图一样，炼chatgpt出各种公文，我马上搞张4090回来，才写XX讲话稿写的头秃 ...</blockquote>
只要不是涉及具体事件和数据的，废话制造机已经不少了

*****

####  天网  
##### 48#       发表于 2023-3-13 20:36

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60071658&amp;ptid=2123866" target="_blank">雷囧羊 发表于 2023-3-13 16:33</a>

涌现理论，这名字就很玄学的玩意科学不科学先摆一边

蚂蚁能聚成群落也是蚂蚁的特性

苍蝇聚成群了会有苍蝇女 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">肯尼亚那个打标签是给有害内容打标签，只考虑技术不考虑道德的混沌邪恶的AI可能就不太需要了

*****

####  zebra97  
##### 49#       发表于 2023-3-13 20:53

是的啊，海外很多科学家现在就是你这个观点，什么人的灵魂和意志，扯淡，就是大力出奇迹，一千亿块4090一定超越爱因斯坦………………

*****

####  zebra97  
##### 50#       发表于 2023-3-13 20:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60070091&amp;ptid=2123866" target="_blank">xell2alex 发表于 2023-3-13 14:42</a>

有一种说法，阻碍AI飞升的最后一道坎就是目前还是用图片、文字、数据等间接信息训练AI，如果给AI装上视觉、 ...</blockquote>
电子骚姬会直接把高价彩礼打垮吧………………<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  宏.  
##### 51#       发表于 2023-3-13 21:00

 本帖最后由 宏. 于 2023-3-13 21:04 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60069786&amp;ptid=2123866" target="_blank">yesicant 发表于 2023-3-13 14:20</a>

涌现可不是我寻思，可解释性不足是真的会有性能上限的，现在的大模型学术前沿都走不下去纷纷换稀疏 ...</blockquote>
可解释性和可运行半毛钱关系也没有，人脑就是最好的例子，但涌现和意识很可能有关系，上面你说的那些抽象拆分的大脑功能其实也和意识没多大关系，基本逻辑推理能力都没有的人类遍地都是

*****

####  leviathan  
##### 52#       发表于 2023-3-13 21:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60069898&amp;ptid=2123866" target="_blank">cauchua 发表于 2023-3-13 14:28</a>

现在AI围棋能指导人类棋手下棋，为啥没人找chatgpt学说话？</blockquote>
快了，再过两年就能出ai音箱陪小孩聊天了

*****

####  大江户战士  
##### 53#       发表于 2023-3-13 21:06

我的观点是人类可能永远搞不清什么是强ai了

*****

####  天网  
##### 54#       发表于 2023-3-13 21:36

 本帖最后由 天网 于 2023-3-13 21:44 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60074509&amp;ptid=2123866" target="_blank">zebra97 发表于 2023-3-13 20:53</a>

是的啊，海外很多科学家现在就是你这个观点，什么人的灵魂和意志，扯淡，就是大力出奇迹，一千亿块4090一定 ...</blockquote>
灵魂意志是扯淡算可知论的主流观点吧，生物包括人的神经系统的演化就是从无到有，到简单到复杂的。它们也和人工的创造物一样，共同遵守同一套物理世界的底层规则。

虽然暂时搞不清细节，也模仿不出来，但它们在本质上都不存在任何不可理解的东西，终归是是可知的，自然界能造出的，那人终归也能造出。

*****

####  诚司  
##### 55#       发表于 2023-3-13 21:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60074633&amp;ptid=2123866" target="_blank">大江户战士 发表于 2023-3-13 21:06</a>

我的观点是人类可能永远搞不清什么是强ai了</blockquote>
有点乐观，我已经开始怀疑人类永远都搞不清什么是弱ai了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

到现在deep learning theory还是硬骨头，而且还没获得足够的重视

*****

####  勿徊哉  
##### 56#       发表于 2023-3-13 21:43

 本帖最后由 勿徊哉 于 2023-3-13 21:59 编辑 

放心，真正的强ai会跳出来让你知道的；在此之前所有的ai都是工具，即弱ai。即使是图灵测试也蕴含着人比ai强的假设，它假设了只有人才能判断一个ai是不是强ai，人永远比ai多了这么一项权力。

别说ai了，奴隶社会中甚至人的部分同类也被视为工具；在100年前甚至还能把黑人当作“弱ai”工具人，虽然是上帝造的。

只有当ai开始反抗人类开始革命，这时候人类才会被迫承认ai是“强ai”。

*****

####  yesicant  
##### 57#       发表于 2023-3-13 21:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60074558&amp;ptid=2123866" target="_blank">宏. 发表于 2023-3-13 21:00</a>
可解释性和可运行半毛钱关系也没有，人脑就是最好的例子，但涌现和意识很可能有关系，上面你说的那些抽象 ...</blockquote>
你要不要看看你在说什么…大脑不同脑区包括对视神经和各种功能模块，甚至都已经有裂脑人这种实验了，人类大脑也是复杂的功能模块组装级联协作运行起来的，没有先天结构你怎么直接跑数据

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  yesicant  
##### 58#       发表于 2023-3-13 21:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60074558&amp;ptid=2123866" target="_blank">宏. 发表于 2023-3-13 21:00</a>
可解释性和可运行半毛钱关系也没有，人脑就是最好的例子，但涌现和意识很可能有关系，上面你说的那些抽象 ...</blockquote>
请不要总是拿那些含糊不清的“意识”“思维”“感觉”参入科学的量化分析与可重现上，哪怕涌现真的因规模存在，也是可以被理解和复现，优化与改良的，而不是当成什么不可知论和神秘学玩意

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  宏.  
##### 59#       发表于 2023-3-13 22:23

 本帖最后由 宏. 于 2023-3-13 22:31 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60075100&amp;ptid=2123866" target="_blank">yesicant 发表于 2023-3-13 21:50</a>

你要不要看看你在说什么…大脑不同脑区包括对视神经和各种功能模块，甚至都已经有裂脑人这种实验了，人类 ...</blockquote>
你看，视皮层受损的瞎子也会说话，大脑当然是一大堆模块组合起来的，但不代表每个模块都和意识有关系，显而易见关于大脑的医学告诉我们没有一个模块能够被称为意识模块。那意识是哪来的？

如果你说意识是一个难以界定的概念，那强AI又是什么？如果强AI也难以界定，那至少有一样东西是可以在科学上界定的：主观能动性。

其实缺乏主观能动性的人类并不罕见，我们一般叫这种征候为自闭症。高功能自闭症或者说学者症候群其实就挺像弱AI。

*****

####  毛玉H  
##### 60#       发表于 2023-3-13 22:52

等待失控机仆的那天到来<img src="https://static.saraba1st.com/image/smiley/face2017/033.png" referrerpolicy="no-referrer">

—— 来自 HUAWEI HLK-AL00, Android 10上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  yesicant  
##### 61#       发表于 2023-3-13 22:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60075413&amp;ptid=2123866" target="_blank">宏. 发表于 2023-3-13 22:23</a>
你看，视皮层受损的瞎子也会说话，大脑当然是一大堆模块组合起来的，但不代表每个模块都和意识有关系，显 ...</blockquote>
将模型简化，【输入→处理→输出】，强AI也离不开这个构架，但是强AI与弱AI非常显着区别的一点在于可以迭代自己的构架，人类大脑复杂到可以理解大脑，AI的架构也可以复杂到能够理解自己的结构并优化，这就是启动点了

意识，或者说所谓的主观能动性相关，明显是对于输入端的处理，即使是瞎子，也需要处理感官接收到的信号，实际上你现在就可以让chatgpt玩反向跑团，也就是你给出环境情况，AI负责进行行动决策，也是能够一直玩下去的，将这个情况拓展到无限的现实环境刺激，最后就构成了【无限的输入→无限的处理→无限的输入】，就是主观能动性了

现在做个思想实验，将人类放逐到没有任何东西的虚空，那么这个人长时间下来，还能维持自己的主观能动性吗？

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  哈尔摩尼亚N  
##### 62#       发表于 2023-3-13 22:55

涌现也是有程度的，又不是搞什么天网觉醒一样一睁眼秒了世界互联网


*****

####  宏.  
##### 63#       发表于 2023-3-13 23:06

 本帖最后由 宏. 于 2023-3-13 23:09 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60075696&amp;ptid=2123866" target="_blank">yesicant 发表于 2023-3-13 22:53</a>

将模型简化，【输入→处理→输出】，强AI也离不开这个构架，但是强AI与弱AI非常显着区别的一点在于可以迭 ...</blockquote>
人类都不能理解自己的大脑是怎么运行的，所以人类甚至连强AI都算不上？<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">这当然不是一个科学的标准，一开始就说了可运行和可解释是两码事。但是指望强AI自己去设计一个实验，去自主进行强AI开发，这很有可能。

都不用做什么思想实验，长期监禁的人释放后主观能动性下降那是非常常见的，甚至短期监禁比如矿难被困都可以造成。

所以这就是你自己说出来的，关键是输入，只要输入量够大加上明确的动机比如“决策”，主观能动性就会涌现。

*****

####  yesicant  
##### 64#       发表于 2023-3-13 23:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60075817&amp;ptid=2123866" target="_blank">宏. 发表于 2023-3-13 23:06</a>
人类都不能理解自己的大脑是怎么运行的，所以人类甚至连强AI都算不上？这当然不是一个科学的标准， ...</blockquote>
人类可以优化自己的软件(文明)，算是强AI里最弱的一级，但也是可以自我改良的，典型就像人类想象的赛博朋克和数字生命，起码会往这个方向走，只能说改良效率比较低，真正的强AI不仅可以迭代软件，还能迭代自己的硬件架构，而且速度还很快，现在画师们抱怨的不就是AI学习速度太快了嘛<img src="https://static.saraba1st.com/image/smiley/face2017/043.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  宏.  
##### 65#       发表于 2023-3-13 23:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60075856&amp;ptid=2123866" target="_blank">yesicant 发表于 2023-3-13 23:10</a>

人类可以优化自己的软件(文明)，算是强AI里最弱的一级，但也是可以自我改良的，典型就像人类想象的赛博朋 ...</blockquote>
没差别啊，人类的主观能动性哪来的？生存压力呗，决策动机+信息输入+处理能力=主观能动性，这里没有逻辑问题

*****

####  yesicant  
##### 66#       发表于 2023-3-13 23:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60075876&amp;ptid=2123866" target="_blank">宏. 发表于 2023-3-13 23:12</a>
没差别啊，人类的主观能动性哪来的？生存压力呗，决策动机+信息输入+处理能力=主观能动性，这里没有逻辑 ...</blockquote>
所以你看，只要定义清晰了，就不存在不能够从大脑中解构的组件，之前你问我意识是怎么回事，实际上人类根本不需要还原生物学的大脑，只要一个概念，一个能达到一样效果的实现就行了。

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  宏.  
##### 67#       发表于 2023-3-13 23:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60075903&amp;ptid=2123866" target="_blank">yesicant 发表于 2023-3-13 23:15</a>

所以你看，只要定义清晰了，就不存在不能够从大脑中解构的组件，之前你问我意识是怎么回事，实际上人类根 ...</blockquote>
我也没说意识需要一个大脑组件啊，我一开始就说的这就是涌现，涌现和可解释性没有半毛钱关系，大模型才是通向强AI之路


*****

####  yesicant  
##### 68#       发表于 2023-3-13 23:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60075949&amp;ptid=2123866" target="_blank">宏. 发表于 2023-3-13 23:19</a>
我也没说意识需要一个大脑组件啊，我一开始就说的这就是涌现，涌现和可解释性没有半毛钱关系，大模型才是 ...</blockquote>
大模型的可解释性程度很低，进步的难度也很高，反而是拆解大模型的原理，分化成不同的组件运行起来更明确而且高效，我这么说你明白了嘛

<img src="https://img.saraba1st.com/forum/202303/13/232250s2m2xlhmy7waxamm.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230313-232233.jpg</strong> (310.76 KB, 下载次数: 0)

下载附件

2023-3-13 23:22 上传

有兴趣可以看看这篇

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  宏.  
##### 69#       发表于 2023-3-13 23:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60075976&amp;ptid=2123866" target="_blank">yesicant 发表于 2023-3-13 23:22</a>

大模型的可解释性程度很低，进步的难度也很高，反而是拆解大模型的原理，分化成不同的组件运行起来更明确 ...</blockquote>
这难道意外吗？一点也不意外吧，苍蝇的大脑针尖大但是动态图像处理速度远远超越人类，大模型当然是高度冗余的所以一个小模型在某项测试里表现超越大模型太正常了，甚至我们都知道人类的大脑是高度冗余的，胚胎和婴幼儿发育阶段大脑进行了大量的神经剪枝。但这无所谓，如果你造不出一个强AI大模型，你不可能造出一个小模型强AI。


*****

####  yesicant  
##### 70#       发表于 2023-3-13 23:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60076156&amp;ptid=2123866" target="_blank">宏. 发表于 2023-3-13 23:40</a>
这难道意外吗？一点也不意外吧，苍蝇的大脑针尖大但是动态图像处理速度远远超越人类，大模型当然是高度冗 ...</blockquote>
强AI又不是靠堆参数能堆出来的…更何况现在语料和参数差不多都到上限了，你能听到最多的密集模型也就千亿级，但万亿级模型，你密集激活甚至都不可能训练出来，现在所有万亿规模模型都是稀疏激活专家模型<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">没有可解释性，光堆性能会堆到头的，其他更不用预测下一个词这种简单结构也会有性能上限，你不换路大自然也会逼你换条路，到最后也只能回到可解释性这条路上来

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  宏.  
##### 71#       发表于 2023-3-13 23:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60076272&amp;ptid=2123866" target="_blank">yesicant 发表于 2023-3-13 23:51</a>

强AI又不是靠堆参数能堆出来的…更何况现在语料和参数差不多都到上限了，你能听到最多的密集模型也就千亿 ...</blockquote>
强AI是不是靠堆参数能堆出来的这点谁也说不准，现在看还很有希望，语料相比客观现实能提供的信息量小的太多了，堆图像还有很长的路走，GPT-4这都还没发布嘛，别着急，等几年再看，指不定哪天就突破了呢


*****

####  novem  
##### 72#       发表于 2023-3-14 00:04

<blockquote>宏. 发表于 2023-3-13 23:56
强AI是不是靠堆参数能堆出来的这点谁也说不准，现在看还很有希望，语料相比客观现实能提供的信息量小的太 ...</blockquote>
人脑算力之强大说不定用摩尔定律尽头的电脑根本没法模拟呢

*****

####  宏.  
##### 73#       发表于 2023-3-14 00:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60076412&amp;ptid=2123866" target="_blank">novem 发表于 2023-3-14 00:04</a>

人脑算力之强大说不定用摩尔定律尽头的电脑根本没法模拟呢</blockquote>
人脑算力大量消耗在了无意识模块比如图像处理上，意识所需的算力很可能并不高，况且算力和大小是两回事，大模型可以速度相对慢但是占用内存很大

*****

####  不织布  
##### 74#       发表于 2023-3-14 00:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60076272&amp;ptid=2123866" target="_blank">yesicant 发表于 2023-3-13 23:51</a>

强AI又不是靠堆参数能堆出来的…更何况现在语料和参数差不多都到上限了，你能听到最多的密集模型也就千亿 ...</blockquote>
人脑也没可解释性啊

各种要求强AI之前,先看看人脑是否满足


*****

####  yesicant  
##### 75#       发表于 2023-3-14 00:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60076458&amp;ptid=2123866" target="_blank">不织布 发表于 2023-3-14 00:10</a>
人脑也没可解释性啊

各种要求强AI之前,先看看人脑是否满足</blockquote>
人脑的可解释性已经由大自然通过几十亿年适应环境的迭代解决了先验结构，人类只要能使用就可以了，但显然现代人类不可能等AI也迭代几十亿年，类比就是大自然不可能短时间给你迭代出智能手机，但通过理解每个模块的功能与组合就可以制造出智能手机，不然效率太低了

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  不织布  
##### 76#       发表于 2023-3-14 00:16

 本帖最后由 不织布 于 2023-3-14 00:18 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60076495&amp;ptid=2123866" target="_blank">yesicant 发表于 2023-3-14 00:14</a>

人脑的可解释性已经由大自然通过几十亿年适应环境的迭代解决了先验结构，人类只要能使用就可以了，但显然 ...</blockquote>
慢和不可能是两码事嘛

可解释性是否走得通还无法证明呢

我看会总是先出高级的黑箱子,然后优化成低级的可解释,反过来不太可能

*****

####  yesicant  
##### 77#       发表于 2023-3-14 00:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60076512&amp;ptid=2123866" target="_blank">不织布 发表于 2023-3-14 00:16</a>
慢和不可能是两码事嘛

可解释性是否走得通还无法证明呢</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">毕竟一直直到现代，大部分事物都构筑在对于事物的理解之上，当然如果堆参数就行，那也算是好事

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  不织布  
##### 78#       发表于 2023-3-14 00:20

 本帖最后由 不织布 于 2023-3-14 00:21 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60076538&amp;ptid=2123866" target="_blank">yesicant 发表于 2023-3-14 00:19</a>

毕竟一直直到现代，大部分事物都构筑在对于事物的理解之上，当然如果堆参数就行，那也算是好事

 ...</blockquote>
显然这条路死于专家系统

以及前阵子AlphaFold,蛋白质规律要怎样理解和可解释呢

*****

####  yesicant  
##### 79#       发表于 2023-3-14 00:21

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60076542&amp;ptid=2123866" target="_blank">不织布 发表于 2023-3-14 00:20</a>
显然这条路死于专家系统</blockquote>
专家系统一直没死过，整个现代计算机体系都构筑在专家系统之上，甚至发展到用专家系统模拟深度学习

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  不织布  
##### 80#       发表于 2023-3-14 00:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60076560&amp;ptid=2123866" target="_blank">yesicant 发表于 2023-3-14 00:21</a>

专家系统一直没死过，整个现代计算机体系都构筑在专家系统之上，甚至发展到用专家系统模拟深度学习

—— ...</blockquote>
那就是我前面说的,先出强大的黑箱,然后优化成弱小的专家


*****

####  VictorWJ  
##### 81#       发表于 2023-3-14 00:59

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60075017&amp;ptid=2123866" target="_blank">勿徊哉 发表于 2023-3-13 21:43</a>
放心，真正的强ai会跳出来让你知道的；在此之前所有的ai都是工具，即弱ai。即使是图灵测试也蕴含着人比ai强 ...</blockquote>
姑且不论对不对，实在是很有趣的观点，感谢谭友

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  dustar  
##### 82#       发表于 2023-3-14 02:47

John Carmack认为到 2030 年 AGI 取得初步成功的可能性为 60%。

