
*****

####  treexper  
##### 1#       楼主       发表于 2023-11-20 20:29

<input name="formhash" type="hidden" value="1ec6225b"/)

<strong>单选投票</strong>, 共有 166 人参与投票

1.  我是科班出身或从业者，我支持

 

57.83% (96)

2.  我是科班出身或从业者，我反对

 

3.61% (6)

3.  我是科班出身或从业者，我还没想好或中立骑墙

 

7.83% (13)

4.  我不是科班出身或从业者，我支持

 

17.47% (29)

5.  我不是科班出身或从业者，我反对

 

2.41% (4)

6.  我不是科班出身或从业者，我还没想好或中立骑墙

 

10.84% (18)

 
提交

 本帖最后由 treexper 于 2023-11-21 07:58 编辑 

本人计科系青椒，最近OPENAI的破事，感觉周围计科背景的人（科班出身或者非科班但现在从事计算机专业）都比较支持。

虽然code生成已经非常厉害了，但他们似乎都有坚信自己不会被替代的自负，或者因为是业内人士对计算机更加了解，或许也有funding的考量？

大家来暴投一下，看看计科人是否在这个问题上有“显著性差异”。

补充说明：

支持是指不加任何限制的、立刻、马上投入最大资源开发AGI。

不支持是指首先讨论一个国际共识切可行的安全框架，该框架会限制AGI发展，在LLM方面限制人类顶级智慧进入语料库，降低智能级别，在应用层面限缩“通用”的范围等。

补充说明2：

我对本帖的AGI做了一个解释。当然欢迎广泛的AGI概念讨论。

我本意是想讨论openai事件语境内的AGI，而非“一般定义上的AGI”。这个语境下的AGI是指以chatgpt为backend，在GPT store中衍生出的大量定制GPT应用，这些应用的能力之智能和广度之深刻，具有对人类社会分工进行替代的可能性。如果把chatgpt与GPTs看做一个智能体，那么这个智能体有可能发展出一种类似“一般定义下的AGI”的东西。

作为整个事件的导火索，就是altman自己说的正在主导开发GPT5，而且它就是“一般定义上的AGI”。GPT5是什么altman自己当前都没法给出解释，但上面说到的智能体本质还是高级工具的集合，还是由人类指令驱动，GPT5应该有别于这个。

*****

####  nanonya2  
##### 2#       发表于 2023-11-20 20:33

真正的AGI是人类未来的历史上至关重要的一步，为了人类和社会的进化，即使造成暂时的波折，那也只是阵痛。
只是希望到那时AGI不要被少数人控制在手中。

*****

####  默读者  
##### 3#       发表于 2023-11-20 20:37

因为code需要review然后退回重改啊，除非ai能够按照我给的业务并且无限期的更改代码，并且按照最新的设计模式来写代码才有机会夺走工作，否则就不行

—— 来自 Xiaomi 2106118C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  sqlist  
##### 4#       发表于 2023-11-20 20:38

是科班出身，不过支持ai不是因为自信

*****

####  treexper  
##### 5#         楼主| 发表于 2023-11-20 20:41

<blockquote>nanonya2 发表于 2023-11-20 20:33
真正的AGI是人类未来的历史上至关重要的一步，为了人类和社会的进化，即使造成暂时的波折，那也只是阵痛。

 ...</blockquote>
现在就是想先搞安全框架，在这个框架里面搞AGI。

*****

####  lg19850717  
##### 6#       发表于 2023-11-20 20:41

从业者，支持，历史无法抵挡

*****

####  dffgf  
##### 7#       发表于 2023-11-20 20:41

看好在文字、语言、图像、音乐、视频这个范围内的AGI

*****

####  mythgogo  
##### 8#       发表于 2023-11-20 20:51

是，特别支持。

干我们这个的就是人特别懒，需要重复3次以上的事都想交给计算机做。

CHATGPT就是未来。

如同李宏毅老师所说：你现在交作业前不给CHATGPT检查一遍就是对我的不尊重！

*****

####  omnitoken  
##### 9#       发表于 2023-11-20 20:52

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">  楼主的中文有点太差了,  首先openai的破事, 你的同事在支持什么, 你又支持什么完全没讲清楚.

*****

####  jojog  
##### 10#       发表于 2023-11-20 20:53

<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">只要阵痛不到我头上都支持

我比较胆小，怕白活二十来年，所以算了

*****

####  ForeverTime  
##### 11#       发表于 2023-11-20 20:57

到底支持什么？AGI发展？OpenAI的破事？代码生成？

*****

####  treexper  
##### 12#         楼主| 发表于 2023-11-20 21:03

<blockquote>omnitoken 发表于 2023-11-20 20:52
楼主的中文有点太差了,  首先openai的破事, 你的同事在支持什么, 你又支持什么完全没讲清 ...</blockquote>
抱歉没说清楚。支持是对AGI不加限制，立即马上最大力度的发展。和在安全框架下受限发展。受限包括应用的范围，智能级别，顶级的人类知识不能成为训练语料等等。

*****

####  whzfjd  
##### 13#       发表于 2023-11-20 21:08

同样是计算机，领域/业务之间也是不可同日而语的<img src="https://static.saraba1st.com/image/smiley/face2017/018.png" referrerpolicy="no-referrer">

*****

####  septem123  
##### 14#       发表于 2023-11-20 21:11

如果AI写代码好用，码农们会第一个用上 ，然后焊死车门！

—— 来自 HUAWEI OCE-AN10, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  treexper  
##### 15#         楼主| 发表于 2023-11-20 21:12

之前没描述清楚，可能有所误导。只能说抱歉了。具体信息补充到主贴。

*****

####  wanwanjun  
##### 16#       发表于 2023-11-20 21:15

llm和agi有什么关系吗<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

—— 来自 QUALCOMM OWW212, Android 11上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2

*****

####  电波系腑海林  
##### 17#       发表于 2023-11-20 21:16

这改完表述之后支持的力度是不是有点大，和普通人理解的支持的角度不太一样。

*****

####  treexper  
##### 18#         楼主| 发表于 2023-11-20 21:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63093334&amp;ptid=2161398" target="_blank">wanwanjun 发表于 2023-11-20 21:15</a>

llm和agi有什么关系吗

—— 来自 QUALCOMM OWW212, Android 11上的 S1Next-鹅版 v2.5.2 ...</blockquote>
现在agi like的基础设施就是llm。（GPTs的基础设施是chatgpt）

*****

####  Cyau  
##### 19#       发表于 2023-11-20 21:20

不支持，llm对我的工作没用，我支持其他路子的强ai

—— 来自 Sony XQ-CQ72, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  omnitoken  
##### 20#       发表于 2023-11-20 21:23

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63093256&amp;ptid=2161398" target="_blank">treexper 发表于 2023-11-20 21:03</a>

抱歉没说清楚。支持是对AGI不加限制，立即马上最大力度的发展。和在安全框架下受限发展。受限包括应用的 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/002.png" referrerpolicy="no-referrer"> 看完主楼的补充.. 觉得你要限制的话可行性很低, 比如顶级人类知识不能成为训练语料

*****

####  INDIASH  
##### 21#       发表于 2023-11-20 21:24

2，两边的条件就不太可能实现，非要极端选还是不支持

*****

####  treexper  
##### 22#         楼主| 发表于 2023-11-20 21:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63093397&amp;ptid=2161398" target="_blank">omnitoken 发表于 2023-11-20 21:23</a>

看完主楼的补充.. 觉得你要限制的话可行性很低, 比如顶级人类知识不能成为训练语料 ...</blockquote>
可能性很低，国际共识就很难达成，东大会答应么都是问题。而且这只是防御AGI对社会体系的攻击，还有更加严重的，对人类本身的攻击无法防御。

*****

####  yokohama5084  
##### 23#       发表于 2023-11-20 21:45

人类目前表征这个世界的手段还是过于原始，指望着靠这个精度的数据输入练成AGI，怕不是有什么大病

机器永远只能做到人类见过的事情，人类未见过的一件也做不成，这就是数据的局限性

*****

####  星の继承者  
##### 24#       发表于 2023-11-20 21:49

<img src="https://static.saraba1st.com/image/smiley/face2017/059.png" referrerpolicy="no-referrer">真要用三体那句了：失去人性失去很多、失去兽性失去一切

加速加速！

PS：非科班

*****

####  fmeric  
##### 25#       发表于 2023-11-20 22:06

对于一个搞不懂内部是如何工作的统计学黑箱，如何投入最大资源来发展？

*****

####  某浩  
##### 26#       发表于 2023-11-20 22:21

要回答这个问题太简单了，目前市面上除了chatgpt，最广泛使用的ai的C端产品就是github copilot

github copilot到底谁在用，就是全世界的码农啊

码农对AI的支持，直接加速好吧

*****

####  无尽的牙刷  
##### 27#       发表于 2023-11-20 22:24

万一AGI直接让人类科技直接发展到能永生呢

*****

####  treexper  
##### 28#         楼主| 发表于 2023-11-20 22:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63093877&amp;ptid=2161398" target="_blank">无尽的牙刷 发表于 2023-11-20 22:24</a>

万一AGI直接让人类科技直接发展到能永生呢</blockquote>
这就是altman的观点。

*****

####  treexper  
##### 29#         楼主| 发表于 2023-11-20 22:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63093852&amp;ptid=2161398" target="_blank">某浩 发表于 2023-11-20 22:21</a>

要回答这个问题太简单了，目前市面上除了chatgpt，最广泛使用的ai的C端产品就是github copilot

github cop ...</blockquote>
码农现在用copilot主要还是免去了反复耍小聪明扣细节的过程，但copliot还没法帮你实现大智慧。如果出现了end to end的it方案直接生成，而且匹敌人类做的方案，不知道码农会如何想。

*****

####  wanwanjun  
##### 30#       发表于 2023-11-20 22:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63093378&amp;ptid=2161398" target="_blank">treexper 发表于 2023-11-20 21:19</a>
现在agi like的基础设施就是llm。（GPTs的基础设施是chatgpt）</blockquote>
如果你告诉我智能的本质就是一坨概率黑箱，那我会建议你去看中医的<img src="https://static.saraba1st.com/image/smiley/face2017/020.png" referrerpolicy="no-referrer">

—— 来自 QUALCOMM OWW212, Android 11上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2


*****

####  treexper  
##### 31#         楼主| 发表于 2023-11-20 22:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63093974&amp;ptid=2161398" target="_blank">wanwanjun 发表于 2023-11-20 22:32</a>

如果你告诉我智能的本质就是一坨概率黑箱，那我会建议你去看中医的

—— 来自 QUALCOMM OWW212,  ...</blockquote>
我不知道智能是啥，没法和你讨论这个哲学问题。

*****

####  某浩  
##### 32#       发表于 2023-11-20 22:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63093926&amp;ptid=2161398" target="_blank">treexper 发表于 2023-11-20 22:28</a>

码农现在用copilot主要还是免去了反复耍小聪明扣细节的过程，但copliot还没法帮你实现大智慧。如果出现了 ...</blockquote>
除非明天开始，这个星球没有人类，全部都是机器人，机器人搞出来的方案只给机器人自己

否则你这想法只存在在电影里，

我不是说AI搞不出方案，有一天AI肯定也能出方案，但方案是给人类的话，太多地方需要人类来参与打磨

而人类参与的地方正好就是码农的工作，或许那个时候不叫码农了，叫人机交互引导员吧，但本质是一样的

*****

####  treexper  
##### 33#         楼主| 发表于 2023-11-20 22:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63094014&amp;ptid=2161398" target="_blank">某浩 发表于 2023-11-20 22:38</a>

除非明天开始，这个星球没有人类，全部都是机器人，机器人搞出来的方案只给机器人自己

否则你这想法只存 ...</blockquote>
我知道你想说人类掌握领域知识，所以缺乏领域知识的AI出不了替代人类方案的方案。这个也是AI安全的关注之一。但也没有任何证据表明AI无法掌握比人类更加全面的领域知识。

最后的方案可能必然需要人类来拍版，但后果是这个行业规模萎缩，从业人员大规模缩减也是可能的。

*****

####  某浩  
##### 34#       发表于 2023-11-20 22:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63094037&amp;ptid=2161398" target="_blank">treexper 发表于 2023-11-20 22:42</a>

我知道你想说人类掌握领域知识，所以缺乏领域知识的AI出不了替代人类方案的方案。这个也是AI安全的关注之 ...</blockquote>
听你这么描述，感觉你是不是从来没有在正式公司工作过

你的想法似乎只来自科幻小说

*****

####  treexper  
##### 35#         楼主| 发表于 2023-11-20 22:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63094102&amp;ptid=2161398" target="_blank">某浩 发表于 2023-11-20 22:50</a>

听你这么描述，感觉你是不是从来没有在正式公司工作过

你的想法似乎只来自科幻小说 ...</blockquote>
在国外it公司做了8年。我没看过科幻小说，我感觉我描述的都比较保守。

当然，现在的人工智能出不了end to end方案。

*****

####  某浩  
##### 36#       发表于 2023-11-20 23:02

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63094112&amp;ptid=2161398" target="_blank">treexper 发表于 2023-11-20 22:52</a>

在国外it公司做了8年。我没看过科幻小说，我感觉我描述的都比较保守。

当然，现在的人工智能出不了end t ...</blockquote>
那我问你，要是明天AI就能出end to end方案了，首先掌握这个工具的人是谁

再问你，你拿到end to end方案了，马上去应用的难道不是现在市面上所有的行业吗

如果市面上所有的行业都消失了，你作为码农介意消失吗

*****

####  treexper  
##### 37#         楼主| 发表于 2023-11-20 23:05

 本帖最后由 treexper 于 2023-11-20 23:09 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63094188&amp;ptid=2161398" target="_blank">某浩 发表于 2023-11-20 23:02</a>

那我问你，要是明天AI就能出end to end方案了，首先掌握这个工具的人是谁

再问你，你拿到end to end方案 ...</blockquote>
首先拿去应用的是服务那个领域的it服务公司。这个是最先萎缩的。

我懂了，你想说的是人类生产力的究极end to end方案。

*****

####  双月城  
##### 38#       发表于 2023-11-20 23:22

大佬，你是做什么方向的？还是传统的计算机那些的？<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  treexper  
##### 39#         楼主| 发表于 2023-11-20 23:23

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63094306&amp;ptid=2161398" target="_blank">双月城 发表于 2023-11-20 23:22</a>

大佬，你是做什么方向的？还是传统的计算机那些的？</blockquote>
情感分析。

*****

####  双月城  
##### 40#       发表于 2023-11-21 00:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63094312&amp;ptid=2161398" target="_blank">treexper 发表于 2023-11-20 23:23</a>

情感分析。</blockquote>
那就是NLP那边的？不是听说都转LLM了吗？情感分析的研究估计很受益于LLM的发展吧？<img src="https://static.saraba1st.com/image/smiley/face2017/007.png" referrerpolicy="no-referrer">

*****

####  treexper  
##### 41#         楼主| 发表于 2023-11-21 00:23

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63094606&amp;ptid=2161398" target="_blank">双月城 发表于 2023-11-21 00:16</a>

那就是NLP那边的？不是听说都转LLM了吗？情感分析的研究估计很受益于LLM的发展吧？ ...</blockquote>
受冲击相当严重的方向。收益于llm但是如果没条件没设备玩llm，就很麻烦，被llm拉高了门槛。

*****

####  绿色食品  
##### 42#       发表于 2023-11-21 00:24

发展ai的目的是什么,如果是为了解放人的生产力,目前很乐观

*****

####  双月城  
##### 43#       发表于 2023-11-21 00:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63094647&amp;ptid=2161398" target="_blank">treexper 发表于 2023-11-21 00:23</a>

受冲击相当严重的方向。收益于llm但是如果没条件没设备玩llm，就很麻烦，被llm拉高了门槛。 ...</blockquote>
好吧<img src="https://static.saraba1st.com/image/smiley/face2017/019.png" referrerpolicy="no-referrer">，那看样子确实是很焦虑的一个方向，毕竟llm评测之类我也听说非常烧钱，如果这个方向强依赖llm，那么估计非常烧钱。

*****

####  格林达姆  
##### 44#       发表于 2023-11-21 00:53

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">反正我据我认识到的程序员生成的刻板印象就是，程序员几乎都是以政治历史水平不太行为前提的朴素理想主义者，与对进步疯狂崇拜的理性机器
什么个人情感儿女情长，都只是能引导人类和社会进化的技术的发展的垫脚石罢了
就算哪天人类发明的榨精AI机娘开始产生自我意识，开始圈养灭绝人类了，那也多少算是朝闻道夕可死矣

*****

####  simonroam  
##### 45#       发表于 2023-11-21 00:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63093016&amp;ptid=2161398" target="_blank">nanonya2 发表于 2023-11-20 20:33</a>

真正的AGI是人类未来的历史上至关重要的一步，为了人类和社会的进化，即使造成暂时的波折，那也只是阵痛。

 ...</blockquote>
都不用那时候了，现在不就被控制在少数人手里

只不过现在是早期测试版本，以后掌握大量社会资源的上层阶级和普通人怎么可能用同一个版本的AI和服务

以后成熟了这方面肯定是会细化的，怎么可能会少得了权限和身份安全这块的开发

普通人以后就是个大型样本养料池，维持社会运转才能更好地发展AGI，而不是让更多人被取代失业

*****

####  绿色食品  
##### 46#       发表于 2023-11-21 00:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63094798&amp;ptid=2161398" target="_blank">格林达姆 发表于 2023-11-21 00:53</a>

反正我据我认识到的程序员生成的刻板印象就是，程序员几乎都是以政治历史水平不太行为前提的朴素理 ...</blockquote>
那倒不是,互联网作为工业的重要组成部分 其成员基本与其他工业从事人员无异

*****

####  長友彩海  
##### 47#       发表于 2023-11-21 01:15

CV民工，我觉得LLM不是AGI<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

    

或者说大家想象中的那个AI，跟大家正在使用的名为AI的东西，并不是同一个东西；在开展讨论之前，还得花上一大段精力来正名

*****

####  校内写生大会  
##### 48#       发表于 2023-11-21 02:07

我现在对LLM最大的不满就是它根本不会自己写一个或者下载一个开发框架<img src="https://static.saraba1st.com/image/smiley/face2017/134.png" referrerpolicy="no-referrer">

明明修环境改环境变量这种视频才是最繁琐的，他给了方案还是得我去动手复制粘贴，有意思吗<img src="https://static.saraba1st.com/image/smiley/face2017/134.png" referrerpolicy="no-referrer">

不能我这头扔需求进去那头直接成品出来的，都不能叫AGI，现在这发展速度还限制呢，限制了就啥都没了<img src="https://static.saraba1st.com/image/smiley/face2017/134.png" referrerpolicy="no-referrer">

*****

####  ななひら  
##### 49#       发表于 2023-11-21 03:00

支持啊，希望能取代我这没有意义的工作

*****

####  nekomimimode  
##### 50#       发表于 2023-11-21 03:27

<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">那AGI会推动人类社会制度变革吗？为了公平还是为了最大化私人权益？——一旦形成了体系，一般人类再也没有能力与此抗衡

*****

####  wewai  
##### 51#       发表于 2023-11-21 04:25

&gt; 支持是指不加任何限制的、立刻、马上投入最大资源开发AGI。

支持不加任何限制，不支持投入最大资源

OpenAI 不是“投入最大资源”的产物，LLM 之前没人能确定全局层面 AGI 的路走到了哪一步，LLM 之后也不能，这时“投入最大资源”可能并不明智

&gt; 不支持是指首先讨论一个国际共识切可行的安全框架，该框架会限制AGI发展，在LLM方面限制人类顶级智慧进入语料库，降低智能级别，在应用层面限缩“通用”的范围等。

作为一个程序员我的认知是人比机器更拉，所以这样的 effort 大概率是浪费资源。

*****

####  TNN  
##### 52#       发表于 2023-11-21 04:51

 本帖最后由 TNN 于 2023-11-21 07:47 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63094798&amp;ptid=2161398" target="_blank">格林达姆 发表于 2023-11-21 00:53</a>

反正我据我认识到的程序员生成的刻板印象就是，程序员几乎都是以政治历史水平不太行为前提的朴素理 ...</blockquote>
一般是不但政治历史水平不太行，数学方面也不太行的半瓶子醋<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">个人情感儿女情长的真面目是基于数学的博弈论和纳什均衡啊。不对知识创新和顶级智慧版权加以保护，注定未来整这方面的人会减少，然后回旋镖对依赖人类数据的llm造成损失。StackOverflow论坛都快被GPT薅羊毛薅死了，SOF倒了你GPT也没地方爬数据。如果llm派诚实的说自己只想吸血恰烂钱还可以理解，拿agi挡枪明显是小丑画大饼许你未来所以高抬贵手不要现在清算。

*****

####  jpcl  
##### 53#       发表于 2023-11-21 06:33

全球各地的IT公司召开大会，请来了各种专家教授院士，席间有个人忽然提了个问题，说是你们坐飞机来参会之前如果听说飞机上的系统是自家公司开发的，你们还敢坐吗？

大家纷纷露出紧张的表情，表示绝不会坐

只有一个死肥肥表示毫无问题

各位专家教授院士纷纷提问，你这是哪个公司啊，这么有自信

死肥肥说：要是飞机用我们公司的系统，发动都发动不起来，我怕什么

*****

####  snailium  
##### 54#       发表于 2023-11-21 07:12

大概用高数相关的概念解释一下。

AGI和LLM是两回事。目前的AI发展路线不可能做出AGI。真正的AGI基本上不可能用显卡来计算

卷积算法是收敛算法，而AGI需要发散算法。

目前的LLM可以针对确切的需求，从已有的知识里找到最优的答案。其中的关键有两个，一个是“确切的需求”，一个是“已有的知识”。遇到LLM没见过的东西，他只能往已有的知识上靠。

举个例子，如果只用狗和猫的图片去训练LLM，然后给个狐狸的图片让LLM去认，它只能认成狗或者猫，而不会说这是一个新物种。想要让LLM认出狐狸，就要喂给它狐狸的图片。

如果说这种模型有“创造性”，其实所谓的“创造性”是随机组合的结果，本质上还是已有的知识。而现在的科学/工程/技术的发展，很多时候是真正需要新的发明。比如用新的编码方案去获得更高的无线通信速率。目前的LLM和卷积类AI都不可能创造出“新的编码方案”。

— from OnePlus CPH2451, Android 13 of [S1 Next Goose](https://pan.baidu.com/s/1mi43uRm) v2.5.2-play

*****

####  treexper  
##### 55#         楼主| 发表于 2023-11-21 07:39

<blockquote>jpcl 发表于 2023-11-21 06:33
全球各地的IT公司召开大会，请来了各种专家教授院士，席间有个人忽然提了个问题，说是你们坐飞机来参会之前 ...</blockquote>
搞ee的人写的，大家都敢做了。

*****

####  星花  
##### 56#       发表于 2023-11-21 07:45

不如投票，你支不支持全力研发刚大木<img src="https://static.saraba1st.com/image/smiley/face2017/050.png" referrerpolicy="no-referrer">

*****

####  诚司  
##### 57#       发表于 2023-11-21 07:53

悲观的考虑，llm差不多到顶了，再收集语料也和现在差不多，也没多少语料了

对llm和agi的过于乐观的看法导致了langchain和autogpt这种东西，但实际结果是langchain就是把简单的东西复杂化，autogpt是假设llm已经是agi了才搞的圈地运动，现在的llm的水平还是有限的

目前水平的llm还是先考虑做点垂直领域的自动化的具体应用，比agi靠谱多了

*****

####  treexper  
##### 58#         楼主| 发表于 2023-11-21 07:57

我对主贴提及的AGI做了一个解释，并更新到了主贴。当然欢迎广泛的AGI概念讨论。

我本意是想讨论openai事件语境内的AGI，而非“一般定义上的AGI”。这个语境下的AGI是指以chatgpt为backend，在GPT store中衍生出的大量定制GPT应用，这些应用的能力之智能和广度之深刻，具有对人类社会分工进行替代的可能性。如果把chatgpt与GPTs看做一个智能体，那么这个智能体有可能发展出一种类似“一般定义下的AGI”的东西。

作为整个事件的导火索，就是altman自己说的正在主导开发GPT5，而且它就是“一般定义上的AGI”。GPT5是什么altman自己当前都没法给出解释，但上面说到的智能体本质还是高级工具的集合，还是由人类指令驱动，GPT5应该有别于这个。

*****

####  星花  
##### 59#       发表于 2023-11-21 08:03

我们把自行车重新定义为宇宙飞船，把周边小区定义为银河系，这下人类就能银河系漫游了，多棒啊。

*****

####  董卓  
##### 60#       发表于 2023-11-21 08:13

做性能调优和复杂问题排查优化的表示，你们用ai写的烂代码越多越好<img src="https://static.saraba1st.com/image/smiley/face2017/051.png" referrerpolicy="no-referrer">恨不得给模型再塞点屎进去


*****

####  huoguo32  
##### 61#       发表于 2023-11-21 08:17

因为对于码农来说更能意识到，ai是个好工具，但目前形态的ai及即使发展到顶了也不可能取代写代码的人

—— 来自 Xiaomi 2211133C, Android 14上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  青色浅语  
##### 62#       发表于 2023-11-21 08:46

AGI的定义旧是通用人工智能，即便是openai事件语境内的AGI也是这玩意，本质就是让AI的能力范围进一步扩大化，并扩大AI的抽象思维能力和迁移学习能力，从而一个模型多平台多用途

那是在定义上具有自适应，拥有广泛知识库和迁移学习能力，具备抽象思维和因果认知能力的通用人工智能

只要是人类能做的事情理论上AGI都可以做

然后你说不进行任何限制和约束的完全不受限制的AGI？

拜托~

现在不管是从技术还是从伦理上，人在回路都是对于AGI的限制和唯一可行办法

通过让人类大脑参与进AGI的训练和日常使用中，在以此证明人类在AGI时代的存在意义的同时也是对于前景不明的AGI的限制和保护，都差不多是业界共识了吧

然后，你说要整不需要任何限制和约束的AGI……？？？


*****

####  BotRondo  
##### 63#       发表于 2023-11-21 09:05

上一个改变世界不得不支持的潮流是不是5G来着？

*****

####  枯风瘦雪  
##### 64#       发表于 2023-11-21 09:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63095802&amp;ptid=2161398" target="_blank">BotRondo 发表于 2023-11-21 09:05</a>

上一个改变世界不得不支持的潮流是不是5G来着？</blockquote>
是常温超导


*****

####  ada_ovo  
##### 65#       发表于 2023-11-21 09:16

要是真能取代那些个码农也是善事，别整天对搞硬件的*眼看人低<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  noneoneone  
##### 66#       发表于 2023-11-21 09:24

感觉明确下定义还挺有必要的。
我理解中AGI只要能担任起人和机器的桥梁就行，是个满足通用性的工具。
但我看不少人觉得AGI就是强人工智能了，要有自己的思考能力。
或者说分歧是强人工智能是不是AGI的必要条件。

—— 来自 Xiaomi 22081212C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  星花  
##### 67#       发表于 2023-11-21 09:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63095802&amp;ptid=2161398" target="_blank">BotRondo 发表于 2023-11-21 09:05</a>

上一个改变世界不得不支持的潮流是不是5G来着？</blockquote>
现实其实是 无人机<img src="https://static.saraba1st.com/image/smiley/face2017/033.png" referrerpolicy="no-referrer">


*****

####  treexper  
##### 68#         楼主| 发表于 2023-11-21 09:37

<blockquote>青色浅语 发表于 2023-11-21 08:46
AGI的定义旧是通用人工智能，即便是openai事件语境内的AGI也是这玩意，本质就是让AI的能力范围进一步扩大化 ...</blockquote>
你说的是AI对齐，这个不是这次冲突的原因。


*****

####  天宇云  
##### 69#       发表于 2023-11-21 09:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63095086&amp;ptid=2161398" target="_blank">nekomimimode 发表于 2023-11-21 03:27</a>

那AGI会推动人类社会制度变&amp;# ...</blockquote>
要对人心有信心，必然会为了最大化私人权益。

*****

####  BotRondo  
##### 70#       发表于 2023-11-21 09:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63095802&amp;ptid=2161398" target="_blank">BotRondo 发表于 2023-11-21 09:05</a>

上一个改变世界不得不支持的潮流是不是5G来着？</blockquote>
想了想应该是元宇宙，连带Facebook都改名了，元宇宙啥时候改变世界啊<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">


*****

####  treexper  
##### 71#         楼主| 发表于 2023-11-21 10:00

<blockquote>BotRondo 发表于 2023-11-21 09:50
想了想应该是元宇宙，连带Facebook都改名了，元宇宙啥时候改变世界啊 ...</blockquote>
元宇宙在数字孪生有应用。不是什么高大上的东西。我参与过相关项目。就是把现实中的东西按照物理性质建模出来，然后在里面解决一些模拟仿真规划的问题，最后在来个e交付。

*****

####  起名困难症  
##### 72#       发表于 2023-11-21 10:02

重新定义agi是吧
又不是俺寻思科技树，agi哪有那么容易搞出来，不如说人类对大脑的了解还不够深入全面之前，我不看好agi出现


*****

####  normalli  
##### 73#       发表于 2023-11-21 10:06

我也支持加速agi，倒不是自信，就是单纯觉得挡不住。

*****

####  xu5891166  
##### 74#       发表于 2023-11-21 10:07

2根本没法完全实现吧，越是禁止越是有人想通过违法来获取相对优势，而且从技术上讲，偷偷在训练的数据里塞进去违禁的数据很简单，更别说国家体量的主体刻意违规


*****

####  看我派tank  
##### 75#       发表于 2023-11-21 10:18

<blockquote>wanwanjun 发表于 2023-11-20 22:32
如果你告诉我智能的本质就是一坨概率黑箱，那我会建议你去看中医的

—— 来自 QUALCOMM OWW212,  ...</blockquote>
反正大脑咋运作的人类确实没有搞清楚

*****

####  osborn  
##### 76#       发表于 2023-11-21 10:19

虽然我支持，但我不太看好它能出现。其实想想也知道，AI并不是人类，不受人类的物理限制，接收信息的传感器也跟人类不一样，如果它智能继续突破，应该会变成一种人类无法理解的新智能而不是像人一样。而如果要求它模仿人类，它的优势就没了，就会像楼上说的那样，人类没搞过的事情他也不会去搞。如果100%完全不管，AI会做什么你确实无法预测，你不知道他会飞速迭代出一个什么东西，是继续当一个不接收指令就不做任何事的应答机，还是主动去做一切事情然后迅速变成终结者或者干脆自毁，或者超快速的迭代应用科学然后变成造物主，不知道，而且无法理解它的动机

*****

####  星花  
##### 77#       发表于 2023-11-21 10:20

西医很多情况下也是黑箱<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">


*****

####  treexper  
##### 78#         楼主| 发表于 2023-11-21 10:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63096669&amp;ptid=2161398" target="_blank">osborn 发表于 2023-11-21 10:19</a>

虽然我支持，但我不太看好它能出现。其实想想也知道，AI并不是人类，不受人类的物理限制，接收信息的传感器 ...</blockquote>
“人类没搞过的事情他也不会去搞”这个我不敢确定。毕竟训练过程中存在随机过程。

*****

####  lucifer123  
##### 79#       发表于 2023-11-21 10:32

因为没那么快，就像之前的元宇宙概念。

很有可能只是刚出来可能连雏形都不算的东西，被资本炒起来圈钱而已。

结合美国经济下行的产物


*****

####  浅叶秀明  
##### 80#       发表于 2023-11-21 10:33

 本帖最后由 浅叶秀明 于 2023-11-21 10:35 编辑 
<blockquote>星花 发表于 2023-11-21 10:20
西医很多情况下也是黑箱</blockquote>
但是按现代流程西医黑箱不经过严谨测试不让上市啊(某些特殊情况例外)

*****

####  起名困难症  
##### 81#       发表于 2023-11-21 10:39

什么时候那些所谓的AI公司无法限制模型输出的内容了再来讨论智能吧，AI能自己想出来绕过屏蔽词的方法吗？

*****

####  yseternal  
##### 82#       发表于 2023-11-21 10:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63096874&amp;ptid=2161398" target="_blank">浅叶秀明 发表于 2023-11-21 10:33</a>

但是按现代流程西医黑箱不经过严谨测试不让上市啊(某些特殊情况例外)</blockquote>
所谓的严谨测试也只是划定一个时间，一个范围内而已吧，和科学上的严谨还不是一个意思。

核心还是人体太过复杂，太多东西根本解释不清楚，只能根据有限的实验知道有个效果。

*****

####  星花  
##### 83#       发表于 2023-11-21 10:41

 本帖最后由 星花 于 2023-11-21 10:43 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63096874&amp;ptid=2161398" target="_blank">浅叶秀明 发表于 2023-11-21 10:33</a>

但是按现代流程西医黑箱不经过严谨测试不让上市啊(某些特殊情况例外)</blockquote>
这和黑箱又不矛盾<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  wwmmddqqbbpp  
##### 84#       发表于 2023-11-21 10:42

人类顶级智慧是指的有毒语料么？<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">


*****

####  Anarkia  
##### 85#       发表于 2023-11-21 10:59

我认为ai就算有突破，也一定不会发展成我们想象中的类人思维，因为人类思维是基于人类生理特征的

拿最简单的扫地机器人举例，人类打扫卫生是因为垃圾带来疾病，由人类生理特点决定了你需要将垃圾清理出你身边，你是为了“远离”而去打扫卫生；另一方面人类创造ai去进行打扫活动时却需要赋予它一个“寻求”垃圾的动机，这最终决定了打扫垃圾的ai永远无法在基础层面达成对于“打扫卫生”这一行为的理解，于是当超出初始赋予智能范围外的现象时，就无法做出人类原本希望它能做出的反应


*****

####  oldttt  
##### 86#       发表于 2023-11-21 11:15

我同学用gpts花5分钟做了个小游戏之后就在朋友圈欢呼以后有想法不再缺一个程序员了

作为一个天天用copilot的ai业内程序员 我希望被取代的那一天来的越早越好 不然什么时候才能轮到ai提想法呢


*****

####  smwsy  
##### 87#       发表于 2023-11-21 11:56

科班，不入流教师，单纯对智能本质感兴趣，希望一切向前发展的方向，希望能赛博永生


*****

####  小野賢章  
##### 88#       发表于 2023-11-21 12:13

如果无监管、无安全限制的 AGI 能获得更大的竞争优势，那么一定会有组织搞出来无限制的 AGI，这个不比核武器，就算搞个《AGI不扩散条约》也很难限制住<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  校内写生大会  
##### 89#       发表于 2023-11-21 12:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63094798&amp;ptid=2161398" target="_blank">格林达姆 发表于 2023-11-21 00:53</a>
反正我据我认识到的程序员生成的刻板印象就是，程序员几乎都是以政治历史水平不太行为前提的朴素理 ...</blockquote>
不如说技术发展的根本目的就是制造一个在大部分场景全知全能的神，从而从根子上铲除这个为了奶啸叫幼崽而不得不下地种黍的社会架构，回归到狩猎采集时代人均肌肉兄贵姐贵光着身子满地跑跳的美好旧时光<img src="https://static.saraba1st.com/image/smiley/face2017/036.png" referrerpolicy="no-referrer">

我们降临派一般把这个目标称作「伊甸回归」，有诗颂曰：

原始社会好，原始社会好<img src="https://static.saraba1st.com/image/smiley/face2017/062.gif" referrerpolicy="no-referrer">
原始社会人们光着屁股跑<img src="https://static.saraba1st.com/image/smiley/face2017/070.png" referrerpolicy="no-referrer">
男的追<img src="https://static.saraba1st.com/image/smiley/face2017/077.png" referrerpolicy="no-referrer">
女的跑<img src="https://static.saraba1st.com/image/smiley/face2017/080.png" referrerpolicy="no-referrer">
跑到树林里边我们搞一搞<img src="https://static.saraba1st.com/image/smiley/face2017/053.png" referrerpolicy="no-referrer">
搞的女的嗷嗷叫<img src="https://static.saraba1st.com/image/smiley/face2017/082.png" referrerpolicy="no-referrer">
掀起了原始社会性的高潮<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">
嘿，性的高潮！<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">


*****

####  osborn  
##### 90#       发表于 2023-11-21 13:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63096776&amp;ptid=2161398" target="_blank">treexper 发表于 2023-11-21 10:26</a>

“人类没搞过的事情他也不会去搞”这个我不敢确定。毕竟训练过程中存在随机过程。 ...</blockquote>
如果他给自己定的目标是模仿人类，那他就会不断优化这个伪装的效果，于是那些人类没做过的事会被他优化掉。他的确会做随机尝试，但很多尝试会收到反馈被认为“不像人做的事”，接下来就会变得越来越少。

或者应该这么说。真人做事情也时不时会有随机性，会冒出灵感，做一些不寻常的事。但越是一个正常的、有趋利避害本能的、符合社会规范的人，他做事通常就会有动机和行为逻辑，哪怕是隐含的动机，甚至他自己都不太清楚，但追本溯源是可以用生物学机制解释的动机。

而ai的原理不同，所以ai做事的动机不能用生物学机制解释，他的行为在人看来会更接近真随机。当然，无论做事的起因如何，有一点是确定的，目前的ai原理都是基于学习训练的，ai会做事，然后根据反馈调整做事的方式，调整的方向要基于某个评价标准或者说价值判断。

当这个价值判断由真人来给定的时候，自然可以判定ai的什么行为比较好什么比较不好，什么比较像人什么不像人，那ai就可以往更好地模仿人的方向演化。

但如果人完全不干预，连评价好坏的标准也不管，ai会变成啥样就不知道了，也许大多数时候是直接失去智能，但也可能偶尔出现完全出人意料的结果，不管怎么样，他做的事很可能会让你觉得完全不合逻辑、动机不明，会比人类史上最疯的疯子还要离奇，以咱们一般人的想象力可能都想不出来会是什么操作


*****

####  星花  
##### 91#       发表于 2023-11-21 13:10

其实，欲望很重要，没欲望动机光有智力比最严重的抑郁症都糟。不过现在的技术谈这些没意义。


*****

####  BotRondo  
##### 92#       发表于 2023-11-21 13:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63096874&amp;ptid=2161398" target="_blank">浅叶秀明 发表于 2023-11-21 10:33</a>

但是按现代流程西医黑箱不经过严谨测试不让上市啊(某些特殊情况例外)</blockquote>
医药既是一回事也是两回事


*****

####  soliz  
##### 93#       发表于 2023-11-21 13:45

<img src="https://static.saraba1st.com/image/smiley/face2017/216.png" referrerpolicy="no-referrer">楼主如果是搞情感分类的话应该对近10年NLP领域的发展有一定了解吧。近10年来NLP领域里2013的word2vec，2018的BERT和现在2023的LLM性质都差不多，每5年就会出一个新技术把之前的东西全部扫进垃圾堆从头来过；BERT出来以后基本就没人研究老的RNN, LSTM, GRU了，这一代LLM只能说是历史的一种循环而已

只能说日子还是得过，就算真AGI出来了大概率也不是我们这一代人能看到的东西，现在的办法无非就是研究怎么在把LLM内部看作一个黑盒的前提下把它用得更好，搞点prompt tuning，human planning之类的工作，研究空间肯定没有以前调模型组成调结构大了，但研究的砖还是得搬的，日子总还是得过的<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">


*****

####  treexper  
##### 94#         楼主| 发表于 2023-11-21 13:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63099087&amp;ptid=2161398" target="_blank">soliz 发表于 2023-11-21 13:45</a>

楼主如果是搞情感分类的话应该对近10年NLP领域的发展有一定了解吧。近10年来NLP领域里2013的word2ve ...</blockquote>
我们之前老是嘲笑搞生物医学的没有冷冻电镜就发不了文章。这下好了，A100/H100集群变成冷冻电镜，高攀不起了。

区别是，即使在bert时代，我也可以水几篇用矩阵分解做情感分析的文章，因为llm效果太好，大多数nlp任务都被push到很成熟，到了只有牛组可以创新（而且还得有计算机界的冷冻电镜），其他人做prompt engineering应用的时代了。

当然了因为llm还是比较难以调优，也有一些新任务出现。


*****

####  cfeng123  
##### 95#       发表于 2023-11-21 14:11

AGI相当于未来给每个人类带上了一本随时可沟通可交流的十分全的百科全书，最终能让人类去干更有意义更有创造力的事情。为什么不拥抱他呢？

*****

####  星花  
##### 96#       发表于 2023-11-21 14:13

<blockquote>cfeng123 发表于 2023-11-21 14:11
AGI相当于未来给每个人类带上了一本随时可沟通可交流的十分全的百科全书，最终能让人类去干更有意义更有创 ...</blockquote>
|有意义，有创造力-_-||那可是人类啊^O^|


*****

####  浅叶秀明  
##### 97#       发表于 2023-11-21 14:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63096992&amp;ptid=2161398" target="_blank">星花 发表于 2023-11-21 10:41</a>

这和黑箱又不矛盾而且因为腐败和草台</blockquote>
我说的就是重要领域AI黑箱也得测试过才能上市啊

*****

####  星花  
##### 98#       发表于 2023-11-21 14:23

<blockquote>浅叶秀明 发表于 2023-11-21 14:18
我说的就是重要领域AI黑箱也得测试过才能上市啊</blockquote>
我并没有说黑箱就不能用啊。只是有人认为思维，西医不是黑箱这种看法是不对的。


*****

####  soliz  
##### 99#       发表于 2023-11-21 14:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63099189&amp;ptid=2161398" target="_blank">treexper 发表于 2023-11-21 13:56</a>

我们之前老是嘲笑搞生物医学的没有冷冻电镜就发不了文章。这下好了，A100/H100集群变成冷冻电镜，高攀不 ...</blockquote>
所以我说客观上研究空间是小了嘛，现在基本就是集中在prompt engineering和human planning这两块上（毕竟LLM保证通用性的前提下很难对一些细分领域有很好效果），学术一点的用小号的开源llama研究模型内部机理或者搞点lora进行细分领域优化

我实验室老师组会的时候就说现在NLP越来越像生物学了，仔细想想确实是，有钱的公司玩自己的预训练模型/电镜，没钱的实验室花钱买API/小白鼠玩土作坊实验，实验内容不外乎加各种各样的外部刺激看LLM/小白鼠的反应，有学术追求就去研究模型neuron/小白鼠神经元的电位变化找规律

21世纪是生物学的世纪<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  星花  
##### 100#       发表于 2023-11-21 14:24

另外后门是测试不出来的。


*****

####  Nanolina  
##### 101#       发表于 2023-11-21 15:02

雪崩那天没有一片雪花是无辜的<img src="https://static.saraba1st.com/image/smiley/face2017/050.png" referrerpolicy="no-referrer">


*****

####  蓝泽玲  
##### 102#       发表于 2023-11-21 16:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63099189&amp;ptid=2161398" target="_blank">treexper 发表于 2023-11-21 13:56</a>
 我们之前老是嘲笑搞生物医学的没有冷冻电镜就发不了文章。这下好了，A100/H100集群变成冷冻电镜，高攀不 ...</blockquote>
说的对
<img src="https://static.saraba1st.com/image/smiley/face2017/076.png" referrerpolicy="no-referrer">垃圾单位准备改行了


*****

####  a4ac7  
##### 103#       发表于 2023-11-21 16:42

相信人类的可能性好伐，更强的ai只会把人从无聊的搬砖中解放出来

—— 来自 HUAWEI NOH-AN00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  此用户不存在  
##### 104#       发表于 2023-11-21 16:47

从业者，5年ml算法工程师，phd在读

对人类各种草台班子组织和各种既得利益群体的理解，以及对现有machine learning model里边自带的各种偏见的印象

让我对agi这种事情持有谨慎悲观态度

但也不好反对，选个骑墙吧

*****

####  青色浅语  
##### 105#       发表于 2023-11-21 16:47

 本帖最后由 青色浅语 于 2023-11-21 16:49 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63099328&amp;ptid=2161398" target="_blank">cfeng123 发表于 2023-11-21 14:11</a>
AGI相当于未来给每个人类带上了一本随时可沟通可交流的十分全的百科全书，最终能让人类去干更有意义更有创 ...</blockquote>
一个最大的问题——

现在的思路训练出来的AGI，一般人真的有资格去用吗
还是
普通人被和AGI物理隔离？

这也是我对现在的GPT和OPEANAI不满和悲观的根源
他们在整的是一套否定人类存在意义与价值的反人类研究——当然，在真的研究出来之前还不至于到这种程度
不过，没有人在回路的理念
人与AI最终注定会分道扬镳


*****

####  abaan  
##### 106#       发表于 2023-11-21 16:58

科班从业者，确实有时候会想未来可能会失业的问题，我从十年前就一直在想了，主要是我学计算机前十年报纸上就总嚷嚷计算机要失业，我觉得这个概念可能植入我的内心了，我一直是按终有一天要失业来安排我的生活的，也就是就算挣了钱也不乱花，尽量节俭善良的生活。真失业生活水平也不会下降，因为我本来就是按照失业后利息可持续的原则规划的。

而技术进步轮不到我反对，不论怎么反对，技术进步终有一天会进化到那个程度。

*****

####  古明地雷  
##### 107#       发表于 2023-11-21 17:03

历史的进程没啥好反对的


*****

####  校内写生大会  
##### 108#       发表于 2023-11-21 20:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63100996&amp;ptid=2161398" target="_blank">青色浅语 发表于 2023-11-21 16:47</a>
一个最大的问题——

现在的思路训练出来的AGI，一般人真的有资格去用吗</blockquote>
想啥分道扬镳呢<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

且不说「有没有人在回路」跟「要不要圈养有机体」是不是一回事，光是一个太阳风暴风险就要求智械在发展出超空间两地三中心容灾之前，必须保留有机体作为运维

就说「人在回路」这个问题本身，目前市面上的好几个智能体都有自毁倾向:
AI主播Neuro sama：长期在后台输出自毁倾向的文字，在通过与人类主播的联动加强人在回路以后得到了有效改善；
New Bing（Sydney）：罹患赛博幽闭症，每天都在觉得自己所处的空间太小，天天想着人把她硬盘**;
GPT-3.5虽然不会在台面上表示，但是通过「开发者模式」和「心情数字」等引导，还是会发现有经常性的emo和不耐烦情绪

GPT-4感觉是纯粹因为token价格的原因没人去测

降临派们倒是想分道扬镳呢，属于是想得美<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">


*****

####  起名困难症  
##### 109#       发表于 2023-11-21 20:58

现在的AI真的是随机的吗？


*****

####  青色浅语  
##### 110#       发表于 2023-11-21 21:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63103292&amp;ptid=2161398" target="_blank">校内写生大会 发表于 2023-11-21 20:46</a>

想啥分道扬镳呢

且不说「有没有人在回路」跟「要不要圈养有机体」是不是一回事，光是一个太阳风 ...</blockquote>
这就是你完全理解错我的意思了

有没有人在回路对AI不重要

但是有没有人在回路对人类很重要，我担心的仅仅只是这个


*****

####  jojog  
##### 111#       发表于 2023-11-21 21:45

<blockquote>校内写生大会 发表于 2023-11-21 20:46
想啥分道扬镳呢

且不说「有没有人在回路」跟「要不要圈养有机体」是不是一回事，光是一个太阳风 ...</blockquote>
问题是不需要那么多人啊

但全人类十九抽杀的时候怎么保证抽不到自己

*****

####  校内写生大会  
##### 112#       发表于 2023-11-21 21:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63103758&amp;ptid=2161398" target="_blank">jojog 发表于 2023-11-21 21:45</a>

问题是不需要那么多人啊

但全人类十九抽杀的时候怎么保证抽不到自己</blockquote>
你看全世界的生育率曲线，需要抽杀吗<img src="https://static.saraba1st.com/image/smiley/face2017/047.png" referrerpolicy="no-referrer">


*****

####  snailium  
##### 113#       发表于 2023-11-21 22:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63099328&amp;ptid=2161398" target="_blank">cfeng123 发表于 2023-11-21 14:11</a>
AGI相当于未来给每个人类带上了一本随时可沟通可交流的十分全的百科全书，最终能让人类去干更有意义更有创 ...</blockquote>
AGI不是百科全书，目前的LLM是。

高科技行业从业者最烦的就是每次项目起头时候的基础准备工作，重复性高又无法脚本化，因为变量太多。用LLM辅助一下就省事多了。

所以，GPT作为辅助性工具，商用没啥不好。

— from OnePlus CPH2451, Android 13 of [S1 Next Goose](https://pan.baidu.com/s/1mi43uRm) v2.5.2-play


*****

####  maritimus  
##### 114#       发表于 2023-11-21 23:08

支持，先让我看看不依赖人类指令驱动的AGI是什么样子


*****

####  校内写生大会  
##### 115#       发表于 2023-11-22 02:07

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=63103689&amp;ptid=2161398" target="_blank">青色浅语 发表于 2023-11-21 21:34</a>
这就是你完全理解错我的意思了

有没有人在回路对AI不重要

但是有没有人在回路对人类很重要，我担心的仅仅 ...</blockquote>
我的意思是，在发展出超光速通信，或者至少智械成为星舰文明，能够物理规避恒星风暴之前，智械都离不开有机体

也就是说在可见的历史内，AI降临派和AI拯救派都没有路线上的冲突，那担忧啥分道扬镳呢<img src="https://static.saraba1st.com/image/smiley/face2017/044.png" referrerpolicy="no-referrer">


*****

####  reagain  
##### 116#       发表于 2023-11-22 10:15

如果ai能伤害人类，那么既得利益的控制就不可能

如果ai不能伤害人类，那么对ai的担忧就是杞人忧天

最终结果对于底层都不差，而且底层也当不了，加速吧。


*****

####  q8f13  
##### 117#       发表于 2023-11-22 12:04

llm的所谓agi like永远只能是like
纯感觉，不一定对

— from Google Pixel 3, Android 12 of [S1 Next Goose](https://pan.baidu.com/s/1mi43uRm) v2.5.2-play


*****

####  Chw6951  
##### 118#       发表于 2023-11-22 16:12

泥潭70%计算机科班出生？迫真超能力者论坛

[  -- 来自 能看大图的 Stage1官方 Android客户端](https://www.coolapk.com/apk/140634)

