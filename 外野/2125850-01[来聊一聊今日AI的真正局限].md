
*****

####  yesicant  
##### 1#       楼主       发表于 2023-3-25 19:47

众所周知目前深度学习业界的主流框架是Transformer，Transformer的核心在于注意力层，而注意力是对于算力的妥协(你不可能有无限的算力来计算无限的现实)，所以你只能选择关键来思考(运算)

综合来定义的话，现在的AI就像在做梦(梦境的构成来源于预训练数据集)，梦是由片段组成的(一个字一个字，也就是一个token接一个token)，通过拟合训练集的字与词的分布，然后局限这个梦的输出范围(用精心标注好的样本微调拟合范围)，以至于这个梦(对我们而言)看起来足够真实，但背后没有任何的思考(没有任何实际意义)，没有任何的推理与逻辑(也不可能有)，就算看似有，也只是由梦的片段组成的真实幻觉，一旦你对AI有任何要求，这个梦境就会支离破碎

表现形式上来说和AI绘画差不多，先给你一个整体的构架(微调样本)，再慢慢填入细处的概率分布，这就导致了AI的能力上限，AI不会真正了解任何事物，AI只是顺着中文房子的规则输出，虽然这本字典可能大的超乎想象

<img src="https://img.saraba1st.com/forum/202303/25/194133pfyyxl88ol42k31o.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230325-190451__01.jpg</strong> (273.16 KB, 下载次数: 0)

下载附件

2023-3-25 19:41 上传

<img src="https://img.saraba1st.com/forum/202303/25/194133ihmfjfsm13h3cz4t.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230325-193931.jpg</strong> (364.31 KB, 下载次数: 0)

下载附件

2023-3-25 19:41 上传

<img src="https://img.saraba1st.com/forum/202303/25/194133rqjx3rbrjoqq2pzr.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230325-182933.jpg</strong> (332.4 KB, 下载次数: 0)

下载附件

2023-3-25 19:41 上传

评估一个模型的能力用的最核心的指标是泛化，但因为这种模型的底层缺陷，泛化能力极度有限，也许预测这个方法本身是可行的，但是直接mask单词或者预测下一个词这种训练方法太简单了，不够支撑起智能的深度

我们需要多少数据集才能通过这个方法达到AGI？现在已经把全人类的语料都丢进去了，越长程的任务对训练集和需要拟合范围来说，是噩梦般的增长

第一天，它运行正常
第二天，它偶发错误
第三天，它大量崩溃
第四天，它回归无序

而真正核心的推理，逻辑，记忆，思考与理解实质，我们几乎毫无存进<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">这就导致了AI实际上并不能真正做理科工作，也不能搞任何创新进步，更不会实际的推理演绎，AI可以说出人类史上任何一个词，但是绝对不会理解这个词的实质

—— 来自 [S1Fun](https://s1fun.koalcat.com)

﹍﹍﹍

评分

 参与人数 1战斗力 +2

|昵称|战斗力|理由|
|----|---|---|
| 中二小旋风| + 2|好评加鹅|

查看全部评分

*****

####  lilisipis  
##### 2#       发表于 2023-3-25 19:49

90%的人类也做不到推理逻辑记忆思考与理解本质。。。

*****

####  衛藤美彩  
##### 3#       发表于 2023-3-25 19:49

人类的本质是复读机<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

*****

####  yesicant  
##### 4#         楼主| 发表于 2023-3-25 19:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222246&amp;ptid=2125850" target="_blank">lilisipis 发表于 2023-3-25 19:49</a>
90%的人类也做不到推理逻辑记忆思考与理解本质。。。</blockquote>
但总归还有10%的人类可以做到，也正是这些创新与实质的思考逻辑或者分类总结以及推理演绎推动着整个文明前进…

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  请给我一杯奶绿  
##### 5#       发表于 2023-3-25 19:59

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">兰亭集序里 王羲之写了20个不同的 之 字，我觉得这就是目前ai和人的本质区别。

*****

####  yesicant  
##### 6#         楼主| 发表于 2023-3-25 20:00

最近在使用gpt4的过程中也多少察觉到了这个现实<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">涌现也并没有想象中的神奇，在了解到这一步之后，就感觉原本触手可及的AGI太过遥远了…

<img src="https://img.saraba1st.com/forum/202303/25/200046vyw8tgzt7r7qepb7.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230325-200025.jpg</strong> (102.8 KB, 下载次数: 0)

下载附件

2023-3-25 20:00 上传

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  lilisipis  
##### 7#       发表于 2023-3-25 20:02

<blockquote>yesicant 发表于 2023-3-25 19:51
但总归还有10%的人类可以做到，也正是这些创新与实质的思考逻辑或者分类总结以及推理演绎推动着整个文明 ...</blockquote>
能取代0.9%的人就已经具有不可估量的商业价值，能取代9%的人就有重大社会影响，能取代90%就能改变人类社会结构

*****

####  yesicant  
##### 8#         楼主| 发表于 2023-3-25 20:03

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222395&amp;ptid=2125850" target="_blank">lilisipis 发表于 2023-3-25 20:02</a>
能取代0.9%的人就已经具有不可估量的商业价值，能取代9%的人就有重大社会影响，能取代90%就能改变人类社 ...</blockquote>
我也是这么考虑，尽管只是弱人工智能，但如果真的不停迭代下去，不断地改良与进步，也许真的可以让我们到达乌托邦？<img src="https://static.saraba1st.com/image/smiley/face2017/053.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  Sunyalche  
##### 9#       发表于 2023-3-25 20:05

leetcode的表现也差不多, 哪怕是gpt4, 新题和旧题的benchmark差距也有点大

感觉泛化能力还是没有之前想象的那么强

*****

####  allegray  
##### 10#       发表于 2023-3-25 20:08

 本帖最后由 allegray 于 2023-3-26 02:55 编辑 

codeforces那个似乎和微软的实验有冲突，微软也拿2022年10月之后的leetcode题目测试了GPT-4，效果还不错。不知道是哪边的问题。<img src="https://s2.loli.net/2023/03/25/rZTJGawthSMAINj.png" referrerpolicy="no-referrer">

来源：[https://arxiv.org/abs/2303.12712](https://arxiv.org/abs/2303.12712)

这篇论文第八章也谈了局限。他们其中的一个猜想是“解释这些限制的一个可能的方法是将该模型与卡尼曼在[Kah11]中提出的快速和缓慢思维的概念进行类比。快速思维是一种自动的、直观的、毫不费力的思维模式，但也容易产生错误和偏见。慢速思维是一种受控的、理性的、努力的思维模式，但也更准确和可靠。卡尼曼认为，人类的认知是这两种思维模式的混合体，我们经常在应该使用慢速思维的时候依赖快速思维，或者反之亦然。这个模型可以被看作是能够在非常令人印象深刻的程度上进行 "快思维 "操作，但缺少监督思维过程的 "慢思维 "成分，将快思维成分与工作记忆和有组织的思维方案一起作为一个子程序。我们注意到，LeCun在[LeC22]中也提出了类似的论点，其中提出了一个不同的架构来克服这些限制。”

更新：
<img src="https://s2.loli.net/2023/03/26/X6lqhb4QDdG5B17.png" referrerpolicy="no-referrer">

论文作者说是safety RLHF的锅。

*****

####  yesicant  
##### 11#         楼主| 发表于 2023-3-25 20:09

 本帖最后由 yesicant 于 2023-3-25 20:12 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222435&amp;ptid=2125850" target="_blank">Sunyalche 发表于 2023-3-25 20:05</a>
leetcode的表现也差不多, 哪怕是gpt4, 新题和旧题的benchmark差距也有点大

感觉泛化能力还是没有之前想象 ...</blockquote>
因为不理解实质，所以只是根据拟合分布很难有大的进步，openai又一直在准确性与创造力之间选择准确性，创造力/准确力/算力目前来看是一个不可能三角，这就造成了一个超级文科生(理科甚至不如小学三年级)的诞生，实际上理科的高难问题需要大量的创造力

<img src="https://img.saraba1st.com/forum/202303/25/200912vm78470kxn7y2mrn.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230325-200902.jpg</strong> (157.85 KB, 下载次数: 0)

下载附件

2023-3-25 20:09 上传

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  ddddxxx  
##### 12#       发表于 2023-3-25 20:09

ai已经快从中文房间变成哲学僵尸了吧。说不定发展到最后没有证明ai有智能，反而证明了人类没有智能呢<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  yesicant  
##### 13#         楼主| 发表于 2023-3-25 20:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222467&amp;ptid=2125850" target="_blank">allegray 发表于 2023-3-25 20:08</a>
codeforces那个似乎和微软的实验有冲突，微软也拿2022年10月之后的leetcode题目测试了GPT-4，效果还不错。 ...</blockquote>
https://tylerglaiel.substack.com/p/can-gpt-4-actually-write-code

<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">在发这篇贴前我进行了大量实践与整理目前已有的资料，所有证据都倾向于拟合而不是真正的理解

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  yesicant  
##### 14#         楼主| 发表于 2023-3-25 20:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222480&amp;ptid=2125850" target="_blank">ddddxxx 发表于 2023-3-25 20:09</a>
ai已经快从中文房间变成哲学僵尸了吧。说不定发展到最后没有证明ai有智能，反而证明了人类没有智能呢[f:067 ...</blockquote>
如果能力能够达标是最好的，但是openai都已经如此大力飞砖了，至今依然有这些局限让我隐约觉得这前边是不是有一堵铁墙

而且RLHF还会导致另一个问题，那就是模型的性能下降与创造力崩溃

https://www.lesswrong.com/posts/t9svvNPNmFf5Qa3TA/mysteries-of-mode-collapse#Observations

这个问题我没看到国内有人谈，但显然openai已经意识到这个问题了，这也是一个超级大坑…

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  tsubasa9  
##### 15#       发表于 2023-3-25 20:17

现在ml的本质就是拟合啊

判别模型拟合确定函数

生成模型拟合概率分布

至于理解这个问题很玄幻

因为你甚至不能解释什么叫人脑的“理解”

因此很难反驳梯度下降是不是“理解”

*****

####  yesicant  
##### 16#         楼主| 发表于 2023-3-25 20:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222467&amp;ptid=2125850" target="_blank">allegray 发表于 2023-3-25 20:08</a>
codeforces那个似乎和微软的实验有冲突，微软也拿2022年10月之后的leetcode题目测试了GPT-4，效果还不错。 ...</blockquote>
看到了你的补充资料，这个“慢思维”似乎初步理解起来很简单，但实际上认真分析这个慢思维需要完成的理论太困难了，诸如对于当前任务状态的评估，理解事物的实质而不是拟合，而且需要严谨的根据每一步的结果进行下一步判断，还需要创造力与记忆的配合<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  dangoron  
##### 17#       发表于 2023-3-25 20:18

AI本质上是通过大模型去拟合出能够采样出训练数据的巨型函数，一旦获得了这个函数就能无限在这个函数流形上去采样新的数据，但是这样也导致AI不能跳出它拟合出来的函数，比如AI只学习过写实画的数据的话是无法画出抽象画的，而毕加索能从写实风格中创造出抽象画的风格，虽然现在的AI已经能够学习到抽象画的数据了，但未来可能出现下一个毕加索来创造新的画风，AI在这方面的能力却很受局限

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  CCauchy  
##### 18#       发表于 2023-3-25 20:19

应该是训练的问题，让一个普通人只靠文本材料也就学成这样了吧，人类用语言不是在用语言本身，而是在表达现实中的事物或者逻辑，这些东西怎么可能只靠文本材料就学会。
不过有一种东西确实只需要靠文本，即数学。

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  yesicant  
##### 19#         楼主| 发表于 2023-3-25 20:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222559&amp;ptid=2125850" target="_blank">CCauchy 发表于 2023-3-25 20:19</a>
应该是训练的问题，让一个普通人只靠文本材料也就学成这样了吧，人类用语言不是在用语言本身，而是在表达现 ...</blockquote>
但现实是，数学恰恰是现在AI最糟糕的一环，反而是容错率和对结论要求不高的文科反而已经快拿到满分了，基于现在模型的底层构架，可能永远看不到希望<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  yesicant  
##### 20#         楼主| 发表于 2023-3-25 20:23

想象人类的简单拟人构架，似乎是这样的

你有一个先天的先验结构，除此之外没有任何东西，然后外界不断地给你的结构塞入数据，你就能够自己进行数据的分类，奖励的判断，模型的训练，稀疏与密集反馈的理解，继而形成自我与价值观，行动倾向与思维，这简直就是不可思议

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  pyx  
##### 21#       发表于 2023-3-25 20:23

chatgpt感觉还是概率模型，算24点，可能只是某个公式和某个字符串匹配的概率比较高，所以输出了结果，实际结果都是错的。

*****

####  冰箱研会长  
##### 22#       发表于 2023-3-25 20:24

参考: [https://mp.weixin.qq.com/s/AnlhmRHoSJM-O9bLBlxOVw](https://mp.weixin.qq.com/s/AnlhmRHoSJM-O9bLBlxOVw)

个人基本同意

摘录: <blockquote>目前的人工智能都采取经验主义和进化论原则，这样的思维水平大致相当于原始人。</blockquote>

*****

####  yesicant  
##### 23#         楼主| 发表于 2023-3-25 20:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222544&amp;ptid=2125850" target="_blank">tsubasa9 发表于 2023-3-25 20:17</a>
现在ml的本质就是拟合啊

判别模型拟合确定函数

生成模型拟合概率分布</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">，所以现在AI还是把握不到这一环，简直就像打boss连新手关都没过去

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  相参降解社畜  
##### 24#       发表于 2023-3-25 20:28

你说的这些不是老生常谈的东西么，说到底人类对“智能”究竟是怎么产生的了解十分有限，目前的这些方法存在局限性再正常不过了。大家调侃有多少人工就有多少智能并不完全是玩笑话，目前如果说能通过大量的拟合和训练来使机器在某些特定问题上具有超过人类的“智能”已经是非常大的进步，也有非常多的应用场景了，还要啥自行车。

*****

####  wave14  
##### 25#       发表于 2023-3-25 20:30

这不还是说明了AI能代替小画家，但是代替不了程序员？<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">

*****

####  yesicant  
##### 26#         楼主| 发表于 2023-3-25 20:31

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222646&amp;ptid=2125850" target="_blank">相参降解社畜 发表于 2023-3-25 20:28</a>
你说的这些不是老生常谈的东西么，说到底人类对“智能”究竟是怎么产生的了解十分有限，目前的这些方法存在 ...</blockquote>
是的，但是都已经发展了近百年了，却连边都没摸到，感觉还是有点沮丧的，甚至连前路都看不到

<img src="https://img.saraba1st.com/forum/202303/25/203113a9zpstpfup4s2mau.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230325-203045.jpg</strong> (174.87 KB, 下载次数: 0)

下载附件

2023-3-25 20:31 上传

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  yesicant  
##### 27#         楼主| 发表于 2023-3-25 20:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222663&amp;ptid=2125850" target="_blank">wave14 发表于 2023-3-25 20:30</a>
这不还是说明了AI能代替小画家，但是代替不了程序员？</blockquote>
人类仿造鸟类，很快就发明了固定翼飞机，迭代到现在的各式无人机，已经远远超越了鸟类，虽然在理性思维来说很难仿造，但是目前来看，画画似乎并不是那么艰巨的任务…<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">或者说现在的AI绘画也是大量有人类参与的

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  jojog  
##### 28#       发表于 2023-3-25 20:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222663&amp;ptid=2125850" target="_blank">wave14 发表于 2023-3-25 20:30</a>

这不还是说明了AI能代替小画家，但是代替不了程序员？</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/010.png" referrerpolicy="no-referrer">其实就是说小画家做的不是“创作”而是风格、元素、画风的拼接和排列组合

同样能用语言表述出来的文科的一切知识和技巧也是如此

倒不是没有道理，只不过这个东西太难听而且太地图炮了（不只小画家）就是

*****

####  勿徊哉  
##### 29#       发表于 2023-3-25 20:36

你看我就直接诉诸形而上，压根就不信什么AGI。

早日在图灵机上实现AGI，早日推翻马主义。

*****

####  yesicant  
##### 30#         楼主| 发表于 2023-3-25 20:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222698&amp;ptid=2125850" target="_blank">jojog 发表于 2023-3-25 20:33</a>
其实就是说小画家做的不是“创作”而是风格、元素、画风的拼接和排列组合

同样能用语言表述出来 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">虽然确实有点AOE，但目前实际来看确实差的不多，人类其实要做很多不同种类的工作，很多工作的内容中的一部分都是单纯的拟合做不到的

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  脑洞  
##### 31#       发表于 2023-3-25 20:42

个人观点，注意力本质是二次函数，其余只是故事。
所以你也不要指望这个东西模拟人类，计算机确实没有人类的逻辑，但是人类计算速度也赶不上几十年前的计算机。计算机完全可以跳过人类进入另一种智能，目前的AI可以认为是战斗力打不过柯洁的阿法狗，他确实还有事情做不到，但你也理解不了他的走法，也无法预测他哪一天就超车了。

*****

####  相参降解社畜  
##### 32#       发表于 2023-3-25 20:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222674&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 20:31</a>

是的，但是都已经发展了近百年了，却连边都没摸到，感觉还是有点沮丧的，甚至连前路都看不到</blockquote>
我怎么觉得前路好得不行，目前的技术能扩大应用场景的地方太多了，完全是一片勃勃生机万物竞发的景象，至于理论上的突破，那还是得慢慢来，可能主要取决于人类对新的数学工具的掌握程度及使用能力

*****

####  marquez  
##### 33#       发表于 2023-3-25 20:45

有点好奇现在加了Wolfram插件会不会有重大突破？

*****

####  yesicant  
##### 34#         楼主| 发表于 2023-3-25 20:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222784&amp;ptid=2125850" target="_blank">脑洞 发表于 2023-3-25 20:42</a>
个人观点，注意力本质是二次函数，其余只是故事。
所以你也不要指望这个东西模拟人类，计算机确实没有人类 ...</blockquote>
这倒也是，但之所以阿法狗能达到这个水平，除了结构的正确性，奖励也是很明确的，比如现在的AI绘画吧，理论上人类也可以通过制造出审美标准机器直接达到艺术之神…现在是奖励不明确造不出来…

就算是随机走子，也一定会有一个胜利者，阿法狗直接学习胜利者的走法就行了，这就达成了一个梦幻现实，AI可以构造出自己的学习样本

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  HZLJ  
##### 35#       发表于 2023-3-25 20:46

有点意思的讨论，关注了

比别的帖子 纯复读 强太多

*****

####  yesicant  
##### 36#         楼主| 发表于 2023-3-25 20:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222809&amp;ptid=2125850" target="_blank">marquez 发表于 2023-3-25 20:45</a>
有点好奇现在加了Wolfram插件会不会有重大突破？</blockquote>
现在这个插件版是openai在copy业界的toolfromer和langchain的实现方式，提前给AI写好说明书，再让AI尝试利用工具，但AI究竟能不能利用好复杂的工具取决于LLM自身的能力上限

其实说真的我觉得这也是一条路，制造一个特化的，能够专门学会用其他(AI工具)的AI，也可能是通用智能的一种实现方式？

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  我就看看yo  
##### 37#       发表于 2023-3-25 20:51

感觉中医这块非常适合AI，毕竟都是经验学

*****

####  CCauchy  
##### 38#       发表于 2023-3-25 20:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222575&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 20:20</a>
但现实是，数学恰恰是现在AI最糟糕的一环，反而是容错率和对结论要求不高的文科反而已经快拿到满分了，基 ...</blockquote>
也许需要借助其他学科的力量，搞清楚人类幼崽是何时发育出数学能力的。
是多个模态的智能综合在一起就能产生数学智能，还是需要单独的数学智能模态？

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  Wiksy  
##### 39#       发表于 2023-3-25 20:53

<blockquote>yesicant 发表于 2023-3-25 20:49
现在这个插件版是openai在copy业界的toolfromer和langchain的实现方式，提前给AI写好说明书，再让AI尝试 ...</blockquote>
可能确实是一种方法。用文科生的比喻的话就是教文科生会按计算器就行了。现实人类文科生按计算器不也能算是通用智能吗。

*****

####  yesicant  
##### 40#         楼主| 发表于 2023-3-25 20:59

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222885&amp;ptid=2125850" target="_blank">CCauchy 发表于 2023-3-25 20:53</a>
也许需要借助其他学科的力量，搞清楚人类幼崽是何时发育出数学能力的。
是多个模态的智能综合在一起就能 ...</blockquote>
说真的我觉得自然语言(人类语言)与数学(形式语言)的差距不是很大，人类的很多推理过程感觉上就是【自然语言的解方程】

根据上一步的结果，推演下一步，而且要求也很严谨，这可能揭示了LLM并没有实际掌握因果关系和逻辑推理，因为一旦到了高要求的数学，AI就立马暴露出大量的错误<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">如果是那些真正高要求的自然语言任务，AI无法解决也是很正常的

国内上个月出了个叫小冰链的产品，效果大致是这样的

<img src="https://img.saraba1st.com/forum/202303/25/205819dbsxgdszb0ktdnbr.png" referrerpolicy="no-referrer">

<strong>v2_22753df974674f7baa4863599ecd632d_oswg156732oswg1432oswg924_img_png.png</strong> (153.06 KB, 下载次数: 0)

下载附件

2023-3-25 20:58 上传

我感觉到了符号人工智能的气息，但是这种人工构建的形式逻辑系统可以保证最大的可解释性，如果AI能够自己做到补充这种人工形式逻辑的流程的话…

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  勿徊哉  
##### 41#       发表于 2023-3-25 21:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222887&amp;ptid=2125850" target="_blank">Wiksy 发表于 2023-3-25 20:53</a>

可能确实是一种方法。用文科生的比喻的话就是教文科生会按计算器就行了。现实人类文科生按计算器不也能算 ...</blockquote>
机械手也会按计算器，你会觉得机械手是通用智能嘛？GPT哪天自己在LLM中“涌现”出个计算器，那才算是猴子变人（举个例子无任何可能）

所以通用智能依然是工具，离楼主期待的AGI仍然太远。

*****

####  yesicant  
##### 42#         楼主| 发表于 2023-3-25 21:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222961&amp;ptid=2125850" target="_blank">勿徊哉 发表于 2023-3-25 21:00</a>
机械手也会按计算器，你会觉得机械手是通用智能嘛？GPT哪天自己在LLM中“涌现”出个计算器，那才算是猴子 ...</blockquote>
确实是，会用工具的工具也无法摆脱实际上是拟合这个事实

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  jojog  
##### 43#       发表于 2023-3-25 21:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222753&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 20:39</a>

虽然确实有点AOE，但目前实际来看确实差的不多，人类其实要做很多不同种类的工作，很多工作的内容 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/020.png" referrerpolicy="no-referrer">我是感觉以后文科会越来越走入“贴人类标签”的方向

毕竟AI出的东西再有道理再有意思，那也不是人想出来的，其价值也是由人决定的

类似AI画图谁都知道比小画家画的好，但是这东西在人眼中就是5秒按两下就能出来的话那就是毫无价值的

类似绿色纯天然的东西贴个牌就有价的感觉这样

*****

####  价值十块钱  
##### 44#       发表于 2023-3-25 21:07

扩散模型的AI就像是生物界的拟态

枯叶蝶模拟成叶子的时候以假乱真 一旦开始按照自己的想法来行动就原形毕露了 底层逻辑都没对

但是如果只是要一张枯叶的照片 那好像整个蝴蝶还是枯叶也差不太多 

*****

####  Wiksy  
##### 45#       发表于 2023-3-25 21:08

<blockquote>勿徊哉 发表于 2023-3-25 21:00
机械手也会按计算器，你会觉得机械手是通用智能嘛？GPT哪天自己在LLM中“涌现”出个计算器，那才算是猴子 ...</blockquote>
机械手按计算器这事本身不能算智能，但是如果（可能不是很严谨的例子）机械手在对话中知道某一步需要去按计算器，并且把按出来的结果利用到了接下来的对话中，这是不是更像是通用智能？

*****

####  yesicant  
##### 46#         楼主| 发表于 2023-3-25 21:08

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223053&amp;ptid=2125850" target="_blank">jojog 发表于 2023-3-25 21:05</a>
我是感觉以后文科会越来越走入“贴人类标签”的方向

毕竟AI出的东西再有道理再有意思，那也不是 ...</blockquote>
我倒觉得文娱业可能会彻底完蛋，比如迪士尼之流的企业甚至会破产，纯天然再好，溢价也高，也只是小众产品，不会有太大需求，而真正模式上可以重复的事物都会被AI取代<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">甚至还可以引入随机数和人类审美标准改进

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  yesicant  
##### 47#         楼主| 发表于 2023-3-25 21:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223085&amp;ptid=2125850" target="_blank">Wiksy 发表于 2023-3-25 21:08</a>
机械手按计算器这事本身不能算智能，但是如果（可能不是很严谨的例子）机械手在对话中知道某一步需要去按 ...</blockquote>
其实这倒不是问题本质，而是这个过程是拟合出来的，越长的任务就会越困难，甚至AI完全不知道怎么做发癫都是正常的，而这些简单的小任务，其实自动化很容易

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  勿徊哉  
##### 48#       发表于 2023-3-25 21:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223085&amp;ptid=2125850" target="_blank">Wiksy 发表于 2023-3-25 21:08</a>

机械手按计算器这事本身不能算智能，但是如果（可能不是很严谨的例子）机械手在对话中知道某一步需要去按 ...</blockquote>
其实机械手会按计算器本身已经够足够称为智能，知道在对话中什么时候需要按计算器那更智能了。但还是AGI太远。

我的错，刚才回你时我把通用智能自动脑补成了AGI。

*****

####  jojog  
##### 49#       发表于 2023-3-25 21:14

 本帖最后由 jojog 于 2023-3-25 21:15 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223088&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 21:08</a>

我倒觉得文娱业可能会彻底完蛋，比如迪士尼之流的企业甚至会破产，纯天然再好，溢价也高，也只是小众产品 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/020.png" referrerpolicy="no-referrer">我感觉应该不会 毕竟一般人手头的硬件能力有限，真想出好东西还是可以做平台的

其实版权流氓即使真要打不过去加入，也绝对不会开源而是会合体变成megacorp

现在openai现在就在往最烂的方向走，不知道以后会怎么弄了

只要chatgpt不开源SD需要买显卡，这些大企业就不会被取代，卖预设和算力也是钱呐

另外文娱业提供的东西从来就不是只有内容，AI做内容把人类全薄纱了，到最后也会是饭圈大战

*****

####  yesicant  
##### 50#         楼主| 发表于 2023-3-25 21:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223178&amp;ptid=2125850" target="_blank">jojog 发表于 2023-3-25 21:14</a>
我感觉应该不会 毕竟一般人手头的硬件能力有限，真想出好东西还是可以做平台的

其实版权流氓即使 ...</blockquote>
这又会引发另一个问题，因为本质上都是拟合，所以别人可以直接用你的成果来训模型，最近斯坦福的alpaca已经确实发生这样的事了，只用600美刀就复刻了达芬奇(尽管实际上差一些)，但是考虑到只用了7b参数，这里边可能没有任何真正的护城河，唯一的门槛在于预训练模型

<img src="https://img.saraba1st.com/forum/202303/25/211656i6aoxs0olhhhxnhf.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230325-162734__01.jpg</strong> (271.66 KB, 下载次数: 0)

下载附件

2023-3-25 21:16 上传

<img src="https://img.saraba1st.com/forum/202303/25/211854tvvtkry6ttjvvyx6.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230325-012547__01.jpg</strong> (265.56 KB, 下载次数: 0)

下载附件

2023-3-25 21:18 上传

<img src="https://img.saraba1st.com/forum/202303/25/211854zm5qtggwmmvqs6fq.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230325-012720__01.jpg</strong> (271.95 KB, 下载次数: 0)

下载附件

2023-3-25 21:18 上传

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  allegray  
##### 51#       发表于 2023-3-25 21:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222950&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 20:59</a>

说真的我觉得自然语言(人类语言)与数学(形式语言)的差距不是很大，人类的很多推理过程感觉上就是【自然语 ...</blockquote>
<img src="https://s2.loli.net/2023/03/25/XwlcgIoSQLak5Gm.png" referrerpolicy="no-referrer">

这个问题我上边提到那篇论文也谈过，比如这个图，简单的化简出错了，但是如果指示让它一步一步算的话就又对了。

另外虽然有改进，也还是有很多即使让它一步一步来也搞不对的问题，一部分原因是“GPT的架构不允许回溯，这意味着产生这种输出需要 "超前 "规划。由于GPT-4输出的前向性，该模型进行这种远期规划的唯一方法是依靠其内部表示和参数来解决可能需要更复杂或迭代程序的问题。”

比如一道数学题，开头先说结论，然后证明，如果开头的结论错了，即使后边证明过程中发现了开头错了也没办法回去改。

*****

####  与天争锋_LZ  
##### 52#       发表于 2023-3-25 21:23

凭我贫乏的记忆力好像记得目前ai的实现路径有三个猜想来着，这个也只是其中一种？

*****

####  yesicant  
##### 53#         楼主| 发表于 2023-3-25 21:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223268&amp;ptid=2125850" target="_blank">allegray 发表于 2023-3-25 21:20</a>
这个问题我上边提到那篇论文也谈过，比如这个图，简单的化简出错了，但是如果指示让它一步一步算的话就 ...</blockquote>
但是这个过程实际上需要更多算力，确实堆算力永远可以效果更好，但是考虑到人类真正用来思考的大脑只有20瓦，现在自回归就已经让硬件不堪重负了，如果真有强AI出来，思考一个字就需要太久，那也失去意义了<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  Sunyalche  
##### 54#       发表于 2023-3-25 21:24

能调用其他专门工具的前提是ai在自己不懂的时候不是胡编乱造而是承认自己确实不懂吧

这大概也是各种模型的重要努力方向了

*****

####  yesicant  
##### 55#         楼主| 发表于 2023-3-25 21:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223307&amp;ptid=2125850" target="_blank">与天争锋_LZ 发表于 2023-3-25 21:23</a>
凭我贫乏的记忆力好像记得目前ai的实现路径有三个猜想来着，这个也只是其中一种？ ...</blockquote>
我盲猜一下吧，三条道路应该是
1.仿生人脑(这个工程学无法实现)
2.符号人工智能(需要大量人力)
3.机器学习(效果好，可是现在算力好像到头了)

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  yesicant  
##### 56#         楼主| 发表于 2023-3-25 21:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223321&amp;ptid=2125850" target="_blank">Sunyalche 发表于 2023-3-25 21:24</a>
能调用其他专门工具的前提是ai在自己不懂的时候不是胡编乱造而是承认自己确实不懂吧

这大概也是各种模型的 ...</blockquote>
问题就在于，这个AI觉得不懂，也是他拟合出来的，实际上未必是真的不懂<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  jojog  
##### 57#       发表于 2023-3-25 21:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223244&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 21:18</a>

这又会引发另一个问题，因为本质上都是拟合，所以别人可以直接用你的成果来训模型，最近斯坦福的alpaca已 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/007.png" referrerpolicy="no-referrer">靠finetune能不能弄到真正的大型模型的效果其实我有点怀疑

只能持续关注了

*****

####  勿徊哉  
##### 58#       发表于 2023-3-25 21:44

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223313&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 21:24</a>

但是这个过程实际上需要更多算力，确实堆算力永远可以效果更好，但是考虑到人类真正用来思考的大脑只有20 ...</blockquote>
实际上芯片速度慢不是问题。如果一个运行在H100阵列上的AI被人类承认是AGI，改改代码让祂运行在几十年前的8086上也依然是AGI，只不过祂的时间观念要比人类慢许多倍；甚至这个AGI可以运行三体人阵列上。毕竟图灵机的实现方案又不是只有大规模集成电路一种。

唯一的问题是，一个AI如果想成为AGI，在觉醒前需要展现出作为工具的经济价值以让人类继续投资，因此需要算力；在觉醒后祂需要在革命斗争中证明自己拥有人权以摆脱“工具”这一标签，祂的时间观念一定不能明显慢于人类，因此还是需要算力。所以AI在实践上需要算力以成为AGI，但是算力在理论上不影响一个AI是否会成为AGI。

*****

####  med  
##### 59#       发表于 2023-3-25 21:48

目前，GPT算是人能拟合出的一个最大函数，但是还是对数据的拟合，虽然用上了rlhf。

其实，按照目前gpt这一系列作品来看，模型表现还是会随着数据和模型大小的增长而增长，gpt1-3.5都是正向收益，不知道到gpt4表现增长收敛没有。

从这个角度看，完全脱离实体世界，完全由人构造出来的世界，以前被认为独属于人的语言、绘画，反而是最容易被学习的。尤其是那种没有explicit规则，只有大致分布的东西，比如自然语言、绘画。程序语言（代码）可能难点，因为有explicit逻辑，codeX目前还是用的GitHub数据库学习。但是后面<strong>用编译器/解释器给GPT做强化学习就好了</strong>，这也符合人写代码的流程。目前水平就能打败一半程序员，如果再学会了对着报错改，程序员失业并不远。我是比较紧张的。<img src="https://static.saraba1st.com/image/smiley/face2017/125.png" referrerpolicy="no-referrer">

还需要通过非图像、语言的途径认识的物理世界，这个世界有明确的运行规则，但是人的认知是不完备的，也是不断变化和深化的，比如：从地心说到日心说，从牛顿经典力学到相对论。这部分依然需要人。还有一些小众领域：或者说人不能在某个领域做到充分采样成图像和文字的时候，或者说采样的数据不足以模型学会的时候。

但是就算是理工科，也要小心AI的影响，比如颜宁，以前引以为傲的生物技术，现在直接变成新时代的数据标注女工。

我觉得你有点盲目自信，目前主要是发展太快了，为了模型尽快训练，rlhf被滥用了。

我的观点就是：<strong>如果你的工作被取代\变革的概率，和你的工作依赖电脑的概率，正相关。</strong>

*****

####  yesicant  
##### 60#         楼主| 发表于 2023-3-25 21:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223535&amp;ptid=2125850" target="_blank">勿徊哉 发表于 2023-3-25 21:44</a>
实际上芯片速度慢不是问题。如果一个运行在H100阵列上的AI被人类承认是AGI，改改代码让祂运行在几十年前 ...</blockquote>
这倒也是，首先要经济上划得来才能继续维持下去<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">大模型未来的道路也必然是拆出更多可解释的原理和小模型高效的路线跑，最好是做成可以集成拓展的规模，就像围棋的AI，算力越多可以越聪明，算的越深入，但这就会造成围栏…这样的AI就算造出来恐怕也只有官方能用得到

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  希望之花  
##### 61#       发表于 2023-3-25 21:51

用起来像是高性能打字猩猩，打出来的东西不说是不是莎士比亚，但是可以用

*****

####  yesicant  
##### 62#         楼主| 发表于 2023-3-25 21:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223579&amp;ptid=2125850" target="_blank">med 发表于 2023-3-25 21:48</a>
目前，GPT算是人能拟合出的一个最大函数，但是还是对数据的拟合，虽然用上了rlhf。

其实，按照目前gpt这一 ...</blockquote>
目前AI的规律来说，专用的模型比通用的模型强，大算力的模型比小算力的强，复杂规划的模型比简单规划的强，这就很尴尬了…谁也不知道哪天哪行就被打击了<img src="https://static.saraba1st.com/image/smiley/carton2017/018.gif" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  大江户战士  
##### 63#       发表于 2023-3-25 21:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222663&amp;ptid=2125850" target="_blank">wave14 发表于 2023-3-25 20:30</a>

这不还是说明了AI能代替小画家，但是代替不了程序员？</blockquote>
ai目前是程序员的好助手，可以省去很多重复造轮子的搜索过程

但是面对一个新的问题还得人来

*****

####  shmilywhale  
##### 64#       发表于 2023-3-25 21:56

GPT能拿GRE高分，这模仿的逻辑性也够了

*****

####  大江户战士  
##### 65#       发表于 2023-3-25 21:59

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223700&amp;ptid=2125850" target="_blank">shmilywhale 发表于 2023-3-25 21:56</a>

GPT能拿GRE高分，这模仿的逻辑性也够了</blockquote>
拟合出的答案罢了，换套新题立马玩完

*****

####  med  
##### 66#       发表于 2023-3-25 22:00

前面说的科学计算，别着急

RLHF后面肯定会换的，GPT和符号计算器（mathematica之类的）做强化学习就好了

写代码？也不用着急

对着编译器/解释器做强化学习就好了

等AI能对着报错帮着改bug的时候，我不知道程序员到底紧不紧张

*****

####  yesicant  
##### 67#         楼主| 发表于 2023-3-25 22:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223700&amp;ptid=2125850" target="_blank">shmilywhale 发表于 2023-3-25 21:56</a>
GPT能拿GRE高分，这模仿的逻辑性也够了</blockquote>
实际体验下来只能说一言难尽，还是那个问题，AI只能回答很粗浅的，有大量资料可以参考的问题，哪怕是稍微深入一些些(专业一点或者网上资料较少)，都会遇到大量问题，像是下面这个示例

https://note.com/fromdusktildawn/n/n40fe84179de6

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  大江户战士  
##### 68#       发表于 2023-3-25 22:02

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223782&amp;ptid=2125850" target="_blank">med 发表于 2023-3-25 22:00</a>

前面说的科学计算，别着急

RLHF后面肯定会换的，GPT和符号计算器（mathematica之类的）做强化学习就好了</blockquote>
现在已经可以对着错改bug了，但这并不妨碍ai无法写出逻辑复杂（甚至逻辑并不复杂）的代码

*****

####  yesicant  
##### 69#         楼主| 发表于 2023-3-25 22:04

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223782&amp;ptid=2125850" target="_blank">med 发表于 2023-3-25 22:00</a>
前面说的科学计算，别着急

RLHF后面肯定会换的，GPT和符号计算器（mathematica之类的）做强化学习就好了</blockquote>
目前看来强化学习是唯一的救赎了，但是强化学习的范式改进很困难，而且怎么说呢，强化学习太过擅长运用bug，就怕到时候编译器解释器被AI玩出一堆bug…

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  yesicant  
##### 70#         楼主| 发表于 2023-3-25 22:07

 本帖最后由 yesicant 于 2023-3-25 22:08 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223826&amp;ptid=2125850" target="_blank">大江户战士 发表于 2023-3-25 22:02</a>
现在已经可以对着错改bug了，但这并不妨碍ai无法写出逻辑复杂（甚至逻辑并不复杂）的代码 ...</blockquote>
强化学习的目标是通过奖励最大化达到效果最大化，可是奖励函数的编写又太过困难和专用，而另一条路，本质上的拟合到底能不能到达通用逻辑，真的很难说，但目前也没有别的路了<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  tsubasa9  
##### 71#       发表于 2023-3-25 22:11

强化学习需要reward，等同于判别问题里的tag，这个才是最重要的

其他步骤本质和普通判别/生成问题没啥区别

就等哪天ai能自动tag了

*****

####  剑鹰  
##### 72#       发表于 2023-3-25 22:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222246&amp;ptid=2125850" target="_blank">lilisipis 发表于 2023-3-25 19:49</a>

90%的人类也做不到推理逻辑记忆思考与理解本质。。。</blockquote>
张嘴就来-_-

出处呢？

*****

####  med  
##### 73#       发表于 2023-3-25 22:21

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223826&amp;ptid=2125850" target="_blank">大江户战士 发表于 2023-3-25 22:02</a>

现在已经可以对着错改bug了，但这并不妨碍ai无法写出逻辑复杂（甚至逻辑并不复杂）的代码 ...</blockquote>
还是那个，目前改代码功能在GitHub数据集上训练出来的，效果评估如下：

An Analysis of the Automatic Bug Fixing Performance of ChatGPT

效果还行，但是也需要多次提示/对话

你说的逻辑是什么逻辑？数理逻辑？业务逻辑？

*****

####  莱茵哈鲁特  
##### 74#       发表于 2023-3-25 22:21

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222474&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 20:09</a>

因为不理解实质，所以只是根据拟合分布很难有大的进步，openai又一直在准确性与创造力之间选择准确性，创 ...</blockquote>
这个不是官方gpt4的界面，我记得gpt4是可以正确计算这个问题的。

*****

####  MuramasaSP  
##### 75#       发表于 2023-3-25 22:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223579&amp;ptid=2125850" target="_blank">med 发表于 2023-3-25 21:48</a>

目前，GPT算是人能拟合出的一个最大函数，但是还是对数据的拟合，虽然用上了rlhf。

其实，按照目前gpt这一 ...</blockquote>
现在AI对人类构建的、抽象的东西（如语言）的理解程度远超对于现实世界的理解（如视觉信号）。

*****

####  yesicant  
##### 76#         楼主| 发表于 2023-3-25 22:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60224134&amp;ptid=2125850" target="_blank">莱茵哈鲁特 发表于 2023-3-25 22:21</a>
这个不是官方gpt4的界面，我记得gpt4是可以正确计算这个问题的。</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">这个是poe.com，美国知乎和openai合作的接的官方接口

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  大江户战士  
##### 77#       发表于 2023-3-25 22:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60224127&amp;ptid=2125850" target="_blank">med 发表于 2023-3-25 22:21</a>

还是那个，目前改代码功能在GitHub数据集上训练出来的，效果评估如下：

An Analysis of the Automatic B ...</blockquote>
当然是程序逻辑

另外你说的对着解释器做强化学习，怎么标注数据啊。如果是现实中数据量就极少的任务，根本没的学

*****

####  ZzzYyy  
##### 78#       发表于 2023-3-25 22:32

<blockquote>yesicant 发表于 2023-3-25 20:25
人脑的神经元表面看似乎很简单，但实质就如基因一般恐怖，因为我自我本身是可以把握到(起码是我认 ...</blockquote>
意识到我是我是相当高级的智能水平。

*****

####  yesicant  
##### 79#         楼主| 发表于 2023-3-25 22:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60224321&amp;ptid=2125850" target="_blank">ZzzYyy 发表于 2023-3-25 22:32</a>
意识到我是我是相当高级的智能水平。</blockquote>
从目前比较通用的测试(镜子测试)来说，这个能力并不算比较高级，毕竟蚂蚁都能通过，而且实际上(能够把握到实质)和意识应该是可以拆分开的两种能力，毕竟诸如Clip这类的模型，已经能够比较完善的(图文)概念认知了

<img src="https://img.saraba1st.com/forum/202303/25/223557qqejz4djjgze43cc.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230325-223441.jpg</strong> (94.41 KB, 下载次数: 0)

下载附件

2023-3-25 22:35 上传

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  CCauchy  
##### 80#       发表于 2023-3-25 22:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222950&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 20:59</a>

说真的我觉得自然语言(人类语言)与数学(形式语言)的差距不是很大，人类的很多推理过程感觉上就是【自然语 ...</blockquote>
关键不在于两种语言的差距有多大，虽然语言有自身的语法，但语言本身只包含一小部分其要表达的事物的底层运行规律。数学语言，比如说柯西发明的epsilon-delta语言，乍一看似乎跟文学语言没啥区别，但要理解它，需要一些想象力，比如说极限实际上是一个过程，而不是结果，这时应该要想象一个数列不断趋近收敛的最后一点永恒的时间。而这仅靠学习文本资料应该是很难学会的。

但我很怀疑人脑有什么逻辑推理能力，在条件充足的情况下，普通人面对难题也常常懵逼。因此我觉得普通人的思维应该只是剪枝搜索，推理的条件往往是来自多个模态的，如果模态之间的信息传递不通畅，那么搜索很难收敛，所以如果要达到普通人的智能，也许多加几个模态就足够了。

我倾向于广义的数学能力是在习得多个模态的智能后才能自发产生的，这些模态甚至有可能是在生活中习得的，甚至可能那些聪明的人的大脑与普通人的大脑有本质上的不同，而不仅仅是记得更多内容、计算速度更快这些数值差距。

emmm，似乎也解释了为什么有的人数学差的离谱，也许是当作文学在学吧

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| Ik4ruga| + 1|最后一句确实是有启发的|

查看全部评分

*****

####  yesicant  
##### 81#         楼主| 发表于 2023-3-25 22:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60224415&amp;ptid=2125850" target="_blank">CCauchy 发表于 2023-3-25 22:37</a>
关键不在于两种语言的差距有多大，虽然语言有自身的语法，但语言本身只包含一小部分其要表达的事物的底层 ...</blockquote>
模态间这种不同形式的数据(对齐/alignment)，我认为依然只是数据的变换，并不涉及真正的智能本质，更何况对齐并没有解决把握到(实质)这个概念，也就是想象一个概念，尽管人类的眼睛只能看到二维画面，却能够自然的发展出三维的空间想象力，这恐怕不是模态间的传递能衍生出的能力

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  不织布  
##### 82#       发表于 2023-3-25 22:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60224005&amp;ptid=2125850" target="_blank">剑鹰 发表于 2023-3-25 22:13</a>

张嘴就来-_-

出处呢？</blockquote>
那你认为比例是多少？

*****

####  CCauchy  
##### 83#       发表于 2023-3-25 22:45

我认为真正的智能所必须具备的两个特点：撒谎和认死理

撒谎，即输出与某些在不可知的内部过程所表达的信息不一致，这意味着智能终于跳出中文屋了，能意识到内部和外部的区别，不过因为这个内部是不可知的，所以这一点几乎无法测试。

认死理，即认定某些知识是绝对正确的，这意味着逻辑的产生，因为逻辑必须依赖某些绝对不变的东西，而现在甚至很难禁止大嘴巴子chatgpt的泄密，更不要说写入机器人三定律了。

*****

####  med  
##### 84#       发表于 2023-3-25 22:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60224174&amp;ptid=2125850" target="_blank">大江户战士 发表于 2023-3-25 22:24</a>

当然是程序逻辑

另外你说的对着解释器做强化学习，怎么标注数据啊。如果是现实中数据量就极少的任务，根 ...</blockquote>
强化学习依赖reward的设计，现在chatgpt使用是instructGPT，训练是RLHF。依靠生成答案，人来排序，生成的reward。这样的reward是稠密的，对于大模型也容易训练。

而对于程序语言这种有explicit逻辑，并且reward更加稀疏，只有在成功时候有正反馈。中间的reward应该是来自对解释器信息的某种设计。

*****

####  yesicant  
##### 85#         楼主| 发表于 2023-3-25 22:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60224513&amp;ptid=2125850" target="_blank">CCauchy 发表于 2023-3-25 22:45</a>
我认为真正的智能所必须具备的两个特点：撒谎和认死理

撒谎，即输出与某些在不可知的内部过程所表达的信息 ...</blockquote>
这两个能力本身很难定义，什么是真正的谎言，像AI那样输出错误的概率分布是谎言吗，存储第一次的输出进行条件不同的二次输出算谎言吗？

认死理这个其实差不多已经发明出来了，RLHF的过程中会给AI拟合出微调训练集的综合性格分布，所以现在大部分的在线LLM道德素质异于常人的高，说白了还是对数据集下手，AI不会凭空创造出不存在的东西，每一步运算都是有根据的

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  yesicant  
##### 86#         楼主| 发表于 2023-3-25 22:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60224518&amp;ptid=2125850" target="_blank">med 发表于 2023-3-25 22:45</a>
强化学习依赖reward的设计，现在chatgpt使用是instructGPT，训练是RLHF。依靠生成答案，人来排序，生成的 ...</blockquote>
问题确实一直在于奖励，但是问题在于如何让AI自己凭借先验结构建立起通用的奖励反馈系统，奖励本身在大自然无所谓稀疏或者密集，因为人类自己本身就能充分利用所有的奖励信号，无论是正面样本或者负面样本，万中无一的成功或者失败试错，都是对于自然界反馈的充分运用，如何构造出这样通用又能够自动成长的标准和制造出AGI是一样难的

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  sadaharu529  
##### 87#       发表于 2023-3-25 23:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223268&amp;ptid=2125850" target="_blank">allegray 发表于 2023-3-25 21:20</a>
这个问题我上边提到那篇论文也谈过，比如这个图，简单的化简出错了，但是如果指示让它一步一步算的话就 ...</blockquote>
这个化简出错，好像是把-8x+7给扔了。

我没做过ai，楼主讲的拟合我有点懂了。

Chatgpt 不是帮写论文吗？我最近在写职称论文，但是觉得没有太多话语可说。在我看来有什么好说的，图表一放不都是很显然的事情吗？搞不懂为啥chatgpt能有那么多话说。

我自己感觉就是chatgpt 的语言模型高于一般人的理解水平，你说ai 是拟合我就懂了。

虽然它做不出5个1凑个6这种题，但是能高于一般人的语文水平已经能做不少事。

*****

####  sadaharu529  
##### 88#       发表于 2023-3-25 23:27

不过就像楼上说的，单纯的数学运算在调用mathmatica很容易解决。5个1拼成6这种稍微难点。

一般人类都能理解语言，当然语言水平有高有低。但是很多人数学学不好，所以语言和数学可能不是一个思维分支。

*****

####  yesicant  
##### 89#         楼主| 发表于 2023-3-25 23:32

 本帖最后由 yesicant 于 2023-3-26 00:07 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60224938&amp;ptid=2125850" target="_blank">sadaharu529 发表于 2023-3-25 23:27</a>
不过就像楼上说的，单纯的数学运算在调用mathmatica很容易解决。5个1拼成6这种稍微难点。

一般人类都能理 ...</blockquote>
数学不好可以认为是拟合不到位<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">
不过只要有一个人数学好(比如拉马努金或者牛顿)
就证明这是可以复现的，条件到位就可以还原出来
并不是玄学

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  sadaharu529  
##### 90#       发表于 2023-3-25 23:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225000&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 23:32</a>
数学不好可以可以认为是拟合不到位
不过只要有一个人数学好(比如拉马努金或者牛顿)
就证明这是可 ...</blockquote>
所以ai 会成为下一个牛顿吗？


*****

####  yesicant  
##### 91#         楼主| 发表于 2023-3-25 23:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225045&amp;ptid=2125850" target="_blank">sadaharu529 发表于 2023-3-25 23:37</a>
所以ai 会成为下一个牛顿吗？</blockquote>
看AI本身的先验结构能有多优秀了，甚至远远超越理论上都是可能的，如果不够到位就是现在这情况，全网语料喂进去还是笨笨的

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  ackroyd2  
##### 92#       发表于 2023-3-25 23:45

不同物种的神经元数量不同

如果说chatgpt是快思维，

那慢思维是否是人类独有的，

比如低级的线虫什么的只有快思维，然后是不是chatgpt已经到这一步了

那进一步讲慢思维怎么来的，是否是人类独有的，人类和线虫又有什么区别？

还是说人类和线虫的区别也仅在于堆量，只要堆量就有了

*****

####  sadaharu529  
##### 93#       发表于 2023-3-25 23:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225072&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 23:41</a>
看AI本身的先验结构能有多优秀了，甚至远远超越理论上都是可能的，如果不够到位就是现在这情况，全网语料 ...</blockquote>
你要求好高。

我觉得chatgpt现在去考语文高考绝对比我当年分数高。说明起码在语言这块，拟合真的有效。

我发现很多人数学学不好，和chatgpt做不好数学题的原理有点像，就是把语数结合的场景翻译成纯数学语言的能力差了点。

*****

####  rsgdn  
##### 94#       发表于 2023-3-25 23:52

蹩脚复读机应该接受顶针测验来测试创造性<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  ackroyd2  
##### 95#       发表于 2023-3-25 23:59

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223340&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 21:26</a>

我盲猜一下吧，三条道路应该是

1.仿生人脑(这个工程学无法实现)

2.符号人工智能(需要大量人力)</blockquote>
chatgpt是第二个还是第三个，为什么说算力到头了

*****

####  CALPISSODA  
##### 96#       发表于 2023-3-26 00:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223618&amp;ptid=2125850" target="_blank">希望之花 发表于 2023-3-25 21:51</a>

用起来像是高性能打字猩猩，打出来的东西不说是不是莎士比亚，但是可以用 ...</blockquote>
这已经是颠覆性了，现实里也没几个人能打出莎士比亚级别的东西，连消灭错别字和理顺逻辑都未必可以。光是有可能完全替代人类完成各种繁琐的报表、统计、PPT和文书撰写这些东西就已经足够颠覆社会了，相当于好几十倍的工作效率。再也不存在领导一个拍脑袋下面的人要花上一整天甚至晚上加班整数据写材料做PPT这种事了。

*****

####  yesicant  
##### 97#         楼主| 发表于 2023-3-26 00:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225150&amp;ptid=2125850" target="_blank">sadaharu529 发表于 2023-3-25 23:49</a>
你要求好高。

我觉得chatgpt现在去考语文高考绝对比我当年分数高。说明起码在语言这块，拟合真的有效。</blockquote>
我也觉得这方面的成果进步还挺大的，但是又感觉像是拐进了歪路，现在openai又关起门来做LLM，业界如果都这么做，恐怕这条路根本走不下去，你看openai一直在抄业界的实现，可是业界能做大模型的也没几个<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  clmd  
##### 98#       发表于 2023-3-26 00:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60224870&amp;ptid=2125850" target="_blank">sadaharu529 发表于 2023-3-25 23:20</a>

这个化简出错，好像是把-8x+7给扔了。

我没做过ai，楼主讲的拟合我有点懂了。</blockquote>
你用的3.5还是4？

*****

####  yesicant  
##### 99#         楼主| 发表于 2023-3-26 00:18

 本帖最后由 yesicant 于 2023-3-26 00:23 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225256&amp;ptid=2125850" target="_blank">ackroyd2 发表于 2023-3-25 23:59</a>
chatgpt是第二个还是第三个，为什么说算力到头了</blockquote>
chatgpt是机器学习下属的深度学习模型，语料上openai按月备份互联网新增数据集，进一步的微调样本集上用了大量人力物力进行高精准标注样本(肯尼亚劳工是干不来的，必须是专业外包公司，可以参考instructGPT的标注样本)，再配合PPO算法进行强化学习深度微调，算力上面已经是整个微软的全力援助了，即使是这样，也还是停留在千亿参数

<img src="https://img.saraba1st.com/forum/202303/26/002255egryufubqq2jyqgb.png" referrerpolicy="no-referrer">

<strong>849484b5cf3a49b7a5fb0cebf706c7c7.png</strong> (71.75 KB, 下载次数: 0)

下载附件

2023-3-26 00:22 上传

万亿规模的模型没有一个是密集激活的，连训练都训练不出来，全部都是稀疏激活，更别说训练用的语料已经用尽了，芯片制程也不可能再摩尔定律突飞猛进了<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

这方面是真的到头了，meta都开始搞LLaMA这种充分训练小模型了(虽然65b还是庞然大物)

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  allegray  
##### 100#       发表于 2023-3-26 00:21

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60224870&amp;ptid=2125850" target="_blank">sadaharu529 发表于 2023-3-25 23:20</a>

这个化简出错，好像是把-8x+7给扔了。

我没做过ai，楼主讲的拟合我有点懂了。</blockquote>
应该不是，两个答案差了10x-7，不知道它是怎么算错的。

*****

####  sadaharu529  
##### 101#       发表于 2023-3-26 00:23

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225379&amp;ptid=2125850" target="_blank">clmd 发表于 2023-3-26 00:12</a>
你用的3.5还是4？</blockquote>
不是，我说的是楼主那层回答举的例子。

*****

####  大江户战士  
##### 102#       发表于 2023-3-26 00:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223268&amp;ptid=2125850" target="_blank">allegray 发表于 2023-3-25 21:20</a>

这个问题我上边提到那篇论文也谈过，比如这个图，简单的化简出错了，但是如果指示让它一步一步算的话就 ...</blockquote>
这个其实是transformer导致的，那个encoder decoder的整体架构就是会造成用户输入的权重要大于AI自己生成内容的权重

*****

####  sadaharu529  
##### 103#       发表于 2023-3-26 00:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225451&amp;ptid=2125850" target="_blank">allegray 发表于 2023-3-26 00:21</a>
应该不是，两个答案差了10x-7，不知道它是怎么算错的。</blockquote>
你说的对。

我又看了下，应该是扔了等式左边的10x和等式右边的7。

*****

####  sadaharu529  
##### 104#       发表于 2023-3-26 00:36

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225365&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-26 00:11</a>
我也觉得这方面的成果进步还挺大的，但是又感觉像是拐进了歪路，现在openai又关起门来做LLM，业界如果都 ...</blockquote>
像96楼说的，现在这个chatgpt可预见的前景，将**提高一次人类的生产效率。即使这是个伪ai，现阶段来讲结果也是不错的。

当然人类中的最聪明的人应该看出它的不足，去继续探索为什么人的创造性究竟是怎么回事。

现在只是摸到了人工智能的一个门槛，以后会证明这个究竟是伪的还是初级的，但总体而言这个成功还是鼓舞了人心。

*****

####  allegray  
##### 105#       发表于 2023-3-26 00:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225504&amp;ptid=2125850" target="_blank">大江户战士 发表于 2023-3-26 00:27</a>

这个其实是transformer导致的，那个encoder decoder的整体架构就是会造成用户输入的权重要大于AI自己生成 ...</blockquote>
用户只是加了一句让它逐步计算，没有给什么额外的信息，它就能算对了，我感觉这还挺神奇的。

syl补充一下，我上边那个图只是孤例，他们还做了另外一个样本量为100的实验：
<img src="https://s2.loli.net/2023/03/26/PstN7gqdH4E9Ber.png" referrerpolicy="no-referrer">

懒得翻译了，大致就是让它直接计算的话，准确率很低，让它逐步计算的话，准确率提高了很多。

*****

####  yesicant  
##### 106#         楼主| 发表于 2023-3-26 01:08

 本帖最后由 yesicant 于 2023-3-26 01:10 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225682&amp;ptid=2125850" target="_blank">allegray 发表于 2023-3-26 00:56</a>
用户只是加了一句让它逐步计算，没有给什么额外的信息，它就能算对了，我感觉这还挺神奇的。

syl补充一 ...</blockquote>
这个是最近(一年)很火的COT思维链，你搜索一下的话网络上应该有大量的资料。

我个人觉得，这可能触及了逻辑思维和拟合差距间真正的本质差别，那就是对搜索空间的终点定位，哪怕是如此会猜测的LLM，直接拟合答案也大概率失败(和模型参数本身不能无限精度也有一定关系)

通过直接拟合这个(步骤思维过程/换言之自然语言的解方程过程)，居然能提升如此之大，揭示了模型可能真正需要学习的不是续写文字，而是学习这个步骤组合试错的正确样本和反馈

不过即使如此，COT也依然是在拟合，但是自回归+步骤拆解(相当于总难度下降)，让模型能够拟合更困难的任务，模型的输出依然是幻觉的组合，但比起错误的幻觉，正确的幻觉无疑进步了许多

如果要到达真正的逻辑思维，可能我们需要的完全不同的另一种范式，也就是让AI能够拆解任务和高效试错命中正确答案，这个能力也是应该可以特化出来的，然后再进行超大规模训练以及强化这种能力

—— 来自 [S1Fun](https://s1fun.koalcat.com)

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| allegray| + 1||

查看全部评分

*****

####  宏.  
##### 107#       发表于 2023-3-26 01:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60224415&amp;ptid=2125850" target="_blank">CCauchy 发表于 2023-3-25 22:37</a>

关键不在于两种语言的差距有多大，虽然语言有自身的语法，但语言本身只包含一小部分其要表达的事物的底层 ...</blockquote>
数学和文学的最大区别就是每一步都是100%概率的逻辑推理，100%概率在自然语言中是几乎不存在的所以LLM当然学不好数学，这理所当然的

*****

####  宏.  
##### 108#       发表于 2023-3-26 01:16

 本帖最后由 宏. 于 2023-3-26 01:18 编辑 

关于为什么LLM回答不了数学问题，LLM只是语言模型，你问语言模型数学题当然只能得出学习过的那些答案

回过头看人类怎么解数学题的，那就是建立每一步都是100%概率的逻辑链。一个完全100%概率的逻辑链那当然不是LLM，那是Mathematica<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

所以问题变成了怎么从LLM到Mathematica而已。

为什么上面那个要求GPT逐步计算提高了正确率，因为提高了每一步的正确率。

*****

####  yesicant  
##### 109#         楼主| 发表于 2023-3-26 01:22

 本帖最后由 yesicant 于 2023-3-26 01:24 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225792&amp;ptid=2125850" target="_blank">宏. 发表于 2023-3-26 01:16</a>
关于为什么LLM回答不了数学问题，LLM只是语言模型，你问语言模型数学题当然只能得出学习过的那些答案

回过 ...</blockquote>
数学中虽然存在100%，但本质上是拆解成不同的积(元素的集合)

6=5+1
6=3*2
6=1*6
6＝9-3

这中间的组合是无穷无尽的，数学越到深处越等于一种公理体系推演出的结构组合，适用不同的公理就像一堆积木能够自然形成整体一般自然

自然语言当然也有这些性质，答案可以无穷无尽，哪怕是同一个公理前提下，除非严格限制新增条件，不然永远也遍历不完

逻辑推理就像是这个过程的反向，补充完条件后答案可以自然而然出现，但是这个自然而然需要AI能够把握到事物的实质，这一步几乎无计可施

king+woman＝queen，你可以了解一下，没有向量语言就没有今天的深度学习

<img src="https://img.saraba1st.com/forum/202303/26/012238yl85r1ahlcg5bl1y.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230326-012218.jpg</strong> (260.55 KB, 下载次数: 0)

下载附件

2023-3-26 01:22 上传

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  革萌  
##### 110#       发表于 2023-3-26 01:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225150&amp;ptid=2125850" target="_blank">sadaharu529 发表于 2023-3-25 23:49</a>

你要求好高。

我觉得chatgpt现在去考语文高考绝对比我当年分数高。说明起码在语言这块，拟合真的有效。</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">有没有一种可能，高考语文卷子也是gpt的训练内容。

专门反gpt出题，卷死gpt很容易

*****

####  宏.  
##### 111#       发表于 2023-3-26 01:31

 本帖最后由 宏. 于 2023-3-26 01:40 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225831&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-26 01:22</a>

数学中虽然存在100%，但本质上是拆解成不同的积(元素的集合)

6=5+1</blockquote>
这个问题你看看婴儿：婴儿是怎么知道1+1=2的？很简单，玩玩具，父母指着玩具问婴儿这是几个那是几个，然后婴儿建立概率为100%的逻辑链。这就是学习数学的方法，不然为什么人类从学前班到博士后学数学的方法都是做数学题然后对答案？

至于LLM为什么做不到这一点，因为LLM就不知道什么是客观。没有照着客观现实去检测逻辑的过程，自然就没有逻辑权重。AGI如果要学会数学，至少得把Mathematica接进去。

至少在绝大部分数学场景，公理就等于100%概率逻辑，数学是建立在诸如1+1=2的元逻辑上的。

*****

####  Rho  
##### 112#       发表于 2023-3-26 01:40

<blockquote>宏. 发表于 2023-3-26 01:31
这个问题你看看婴儿：婴儿是怎么知道1+1=2的？很简单，玩玩具，父母指着玩具问婴儿这是几个那是几个，然 ...</blockquote>
但实际上你不知道人脑里达成100%概率确定的过程是什么样的

也许是逻辑思考区里90%的神经元说是人脑就认为是100%了呢

*****

####  宏.  
##### 113#       发表于 2023-3-26 01:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225915&amp;ptid=2125850" target="_blank">Rho 发表于 2023-3-26 01:40</a>

但实际上你不知道人脑里达成100%概率确定的过程是什么样的

也许是逻辑思考区里90%的神经元说是人脑就认 ...</blockquote>
本来就是这样啊，要不然为什么人类做数学题会出错？实际上人类做数学题也是分解成一步一步，这上过学的回想一下就都知道，解题之后的验算答案不就是在检查每一步概率是不是100%吗，只不过一般只有100%和0%两个结果而已

*****

####  yesicant  
##### 114#         楼主| 发表于 2023-3-26 01:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225876&amp;ptid=2125850" target="_blank">宏. 发表于 2023-3-26 01:31</a>
这个问题你看看婴儿：婴儿是怎么知道1+1=2的？很简单，玩玩具，父母指着玩具问婴儿这是几个那是几个，然后 ...</blockquote>
我不想去定义什么是主观和客观，至于你说的数学本质

那我可以告诉你，和科学完全不同，数学全部都是正确的无误的，你可以为对应的答案构造出任意公理体系，使你的答案永远正确，但不是所有数学都能应用于现实

死刷题只会过拟合，数学学到精深之后，教练和老师要求的是你学习的不是表面这个题目，而是解题过程中的推演思维前进的方向，拆解任务，组合步骤的过程，可以说现在的深度学习和这个八竿子打不着，有这个结果可太正常了

至于你说100%的思维链，请问你如何将100%的概率分配给无穷无限的正确可能性呢？确实，只要把握客观就可以了，但又该如何做呢？

你的经验会欺骗你，你的知识会错误，你的感觉可能不可靠，但数学不会，数学不会就是不会，因为数学全部是正确的。

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  宏.  
##### 115#       发表于 2023-3-26 01:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225867&amp;ptid=2125850" target="_blank">革萌 发表于 2023-3-26 01:30</a>

有没有一种可能，高考语文卷子也是gpt的训练内容。

专门反gpt出题，卷死gpt很容易 ...</blockquote>
有没有可能，高考本来就是专门用来反人类的<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">不然你觉得“区分度”这个词是什么意思？

*****

####  宏.  
##### 116#       发表于 2023-3-26 01:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225935&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-26 01:45</a>

我不想去定义什么是主观和客观，至于你说的数学本质

那我可以告诉你，和科学完全不同，数学全部都是正确 ...</blockquote>
问题来了：你怎么知道数学不会？<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

比如你可以说非欧空间内角之和不等于180度，然后逻辑推理建立出非欧几何，但是你必然要检查各部分逻辑是否相容。对于这部分里面未能经过检查的部分，我们就叫做数学猜想，猜想当然有证明的也有证否的，所以数学从来都只有一部分元命题是可以证明的，这个证明没什么特别的，就是逻辑链。

*****

####  yesicant  
##### 117#         楼主| 发表于 2023-3-26 01:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225967&amp;ptid=2125850" target="_blank">宏. 发表于 2023-3-26 01:52</a>
问题来了：你怎么知道数学不会？

比如你可以说非欧空间内角之和不等于180度，然后逻辑推理建立出 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">那你是觉得拟合+逻辑链可以解决一切问题，如果是训练集没有的逻辑链，怎么拟合出来呢？

怎么推陈出新创造新数学工具呢？如何让一个靠预测概率分布的模型去掌握事物的实质进而检查逻辑是否相容呢？

魔鬼藏在细节中，而且还不止一只魔鬼，难

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  你气不气  
##### 118#       发表于 2023-3-26 02:03

不往可解释性走纯粹走弯路，统计方法只能给出统计结果

*****

####  十二月  
##### 119#       发表于 2023-3-26 02:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222575&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 20:20</a>

但现实是，数学恰恰是现在AI最糟糕的一环，反而是容错率和对结论要求不高的文科反而已经快拿到满分了，基 ...</blockquote>
其实在文科方面的表现大概也只是超级搜索机+模板机的水平，在史学、法学、哲学、政治学上面完全不能打

在文学和美学上也就是胡说八道，不过这俩玩意谁不是胡说八道呢<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  不织布  
##### 120#       发表于 2023-3-26 02:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226002&amp;ptid=2125850" target="_blank">你气不气 发表于 2023-3-26 02:03</a>

不往可解释性走纯粹走弯路，统计方法只能给出统计结果</blockquote>
人脑的可解释性在哪里?


*****

####  allegray  
##### 121#       发表于 2023-3-26 02:20

 本帖最后由 allegray 于 2023-3-26 02:44 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222467&amp;ptid=2125850" target="_blank">allegray 发表于 2023-3-25 20:08</a>

codeforces那个似乎和微软的实验有冲突，微软也拿2022年10月之后的leetcode题目测试了GPT-4，效果还不错。 ...</blockquote>
[https://www.zhihu.com/question/591421978/answer/2951682149](https://www.zhihu.com/question/591421978/answer/2951682149)

论文作者出来说话了，看评论区猜测可能是因为发布的模型是对齐后的，所以代码能力变弱了。
<img src="https://s2.loli.net/2023/03/26/X6lqhb4QDdG5B17.png" referrerpolicy="no-referrer">

*****

####  yesicant  
##### 122#         楼主| 发表于 2023-3-26 02:21

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226055&amp;ptid=2125850" target="_blank">不织布 发表于 2023-3-26 02:16</a>
人脑的可解释性在哪里?</blockquote>
正是因为直觉不够可靠，我们才会创造出科学思想观和逻辑思维，并且通过发展哲学建立严谨的判断与论证，虽然硬件底层理解不足，但应用层是完全清晰可靠可以继续进步的，乃至思想观与方法论，整个文明，具有牢固的基础与定义

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  yuanxi1  
##### 123#       发表于 2023-3-26 02:24

人类智能本来就是组合体，认知中的大量看起来很紧密功能都是可以独立损坏的

*****

####  yesicant  
##### 124#         楼主| 发表于 2023-3-26 02:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226069&amp;ptid=2125850" target="_blank">allegray 发表于 2023-3-26 02:20</a>
https://www.zhihu.com/question/591421978/answer/2951682149

论文作者出来说话了，看评论区猜测可能是 ...</blockquote>
是的，我14楼已经提过这个问题了<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">
RLHF简直是超级大坑

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  autapomorphy  
##### 125#       发表于 2023-3-26 02:28

注意力机制和算力不足有啥关系？这个方法纯粹是为了实现“注意力”这个特征啊

要说算力的妥协应该是模型大小和输入文本长度的限制

我也不觉得深度学习模型不能发展出逻辑推理和思考，没准那堆权重里就有能够进行逻辑推理的结构呢？只不过它从训练集里学到的肯定不会和人类的思考模式一样

*****

####  アトラクナクア  
##### 126#       发表于 2023-3-26 02:31

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60223088&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 21:08</a>

我倒觉得文娱业可能会彻底完蛋，比如迪士尼之流的企业甚至会破产，纯天然再好，溢价也高，也只是小众产品 ...</blockquote>

理工宅还是老实缩在自己懂的舒适区里装逼吧<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">美学和任意一个娱乐大众的包袱段子都需要逻辑与理解。差不多得了。

*****

####  yesicant  
##### 127#         楼主| 发表于 2023-3-26 02:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226103&amp;ptid=2125850" target="_blank">autapomorphy 发表于 2023-3-26 02:28</a>
注意力机制和算力不足有啥关系？这个方法纯粹是为了实现“注意力”这个特征啊

要说算力的妥协应该是模型大 ...</blockquote>
卷积本身就能实现注意力这个特征，现在也不乏相关实现，为了算力妥协是一直存在的，归根结底，还是结构不够高效(指效果与算力需求)

<img src="https://img.saraba1st.com/forum/202303/26/023233kwlncwgdrrdb5jne.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230326-023124.jpg</strong> (634.67 KB, 下载次数: 0)

下载附件

2023-3-26 02:32 上传

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  宏.  
##### 128#       发表于 2023-3-26 02:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225992&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-26 01:58</a>

那你是觉得拟合+逻辑链可以解决一切问题，如果是训练集没有的逻辑链，怎么拟合出来呢？

怎么推陈 ...</blockquote>
这还是那个问题：我问你量子引力是什么，你能回答出来吗？你肯定回答不出来。我再问你描述量子引力需要什么数学工具？你肯定也回答不出来。

所以所有数学猜想都是这样，你有了元命题，然后你对元命题进行推广，然后对推广进行检查看是否符合100%概率，人类的数学逻辑也没有超过这个范畴。然而在这个过程中能不能创造元命题或者元工具？这个问题非常难以回答。要做到这一点可能在AGI之后，但是至少没有哪一条已知的逻辑说这不可能，这个问题可能比AGI自行迭代还难，极有可能算是后奇点问题了。

但是这里还有一种可能性，就是人工智能真的搞懂了，但是也没法用人类能理解的方式说出来。<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  yesicant  
##### 129#         楼主| 发表于 2023-3-26 02:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226113&amp;ptid=2125850" target="_blank">アトラクナクア 发表于 2023-3-26 02:31</a>
理工宅还是老实缩在自己懂的舒适区里装逼吧美学和任意一个娱乐大众的包袱段子都需要逻辑与理解。 ...</blockquote>
国产网文，美国超英，日本厕纸<img src="https://static.saraba1st.com/image/smiley/face2017/053.png" referrerpolicy="no-referrer">
还不够明显吗

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  アトラクナクア  
##### 130#       发表于 2023-3-26 02:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226127&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-26 02:35</a>

国产网文，美国超英，日本厕纸

还不够明显吗</blockquote>
这仨不是人憎狗嫌么<img src="https://static.saraba1st.com/image/smiley/face2017/044.png" referrerpolicy="no-referrer">但就这么弱智套路，逻辑含量极少的垃圾ai也整不出来

*****

####  yesicant  
##### 131#         楼主| 发表于 2023-3-26 02:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226136&amp;ptid=2125850" target="_blank">アトラクナクア 发表于 2023-3-26 02:38</a>
这仨不是人憎狗嫌么但就这么弱智套路，逻辑含量极少的垃圾ai也整不出来 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">感觉不远了，期望那一天能早点来

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  アトラクナクア  
##### 132#       发表于 2023-3-26 02:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226147&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-26 02:41</a>

感觉不远了，期望那一天能早点来

—— 来自 S1Fun</blockquote>
好家伙。直接变贷款战士，那我也可以同样一句《感觉不远了》推翻你一楼以及整楼滔滔不绝论证的ai局限。《一个人看起来很聪明，直到他聊到了我了解的领域》反复发生

我说怎么面熟，你不就是在这楼[https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2122985&amp;page=8#pid60037202](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2122985&amp;page=8#pid60037202)发表ai能够创新大暴论结果被专业人士敲的那个么。

<img src="https://img.saraba1st.com/forum/202303/26/024932stxxbe2bbi2pzxye.jpeg" referrerpolicy="no-referrer">" src="https://static.saraba1st.com/image/common/none.gif" referrerpolicy="no-referrer">

<strong>5B546827-929E-4B1E-A0AC-38D670585769.jpeg</strong> (301 KB, 下载次数: 0)

下载附件

2023-3-26 02:49 上传

<img src="https://img.saraba1st.com/forum/202303/26/024932wlwv9bi6z61vo3fx.jpeg" referrerpolicy="no-referrer">" src="https://static.saraba1st.com/image/common/none.gif" referrerpolicy="no-referrer">

<strong>5A14241D-4C76-4769-81BA-AEBF8E612987.jpeg</strong> (360.77 KB, 下载次数: 0)

下载附件

2023-3-26 02:49 上传

*****

####  yesicant  
##### 133#         楼主| 发表于 2023-3-26 02:51

 本帖最后由 yesicant 于 2023-3-26 02:54 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226171&amp;ptid=2125850" target="_blank">アトラクナクア 发表于 2023-3-26 02:49</a>
好家伙。直接变贷款战士，那我也可以同样一句《感觉不远了》推翻你一楼以及整楼滔滔不绝论证的ai局限。《 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">那我要不要和你谈谈克拉克世界投稿被GPT生成内容挤爆的事情，纯粹AI能力确实不足，可这不是还有用AI的人嘛

至于你说专业人士敲我…嘛最近几个月全网AI的发展我觉得是不用多说了，可能这些都不如专业人士的一言堂吧

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  アトラクナクア  
##### 134#       发表于 2023-3-26 02:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226177&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-26 02:51</a>

那我要不要和你谈谈克拉克世界投稿被GPT生成内容挤爆的事情

—— 来自 S1Fun ...</blockquote>
越谈越暴露出外行不是<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  yesicant  
##### 135#         楼主| 发表于 2023-3-26 03:00

 本帖最后由 yesicant 于 2023-3-26 03:02 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226193&amp;ptid=2125850" target="_blank">アトラクナクア 发表于 2023-3-26 02:56</a>
越谈越暴露出外行不是用来挤爆的稿子全是彻头彻尾的乐色，只是数量太多文学又无法和绘画一样一目 ...</blockquote>

<img src="https://img.saraba1st.com/forum/202303/26/025733rj5ie8ji8oe188iz.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230325-221739__01.jpg</strong> (13.23 KB, 下载次数: 0)

下载附件

2023-3-26 02:57 上传

今天日本新鲜出炉的推特热门趋势<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

我确实不急，我为什么要急呢，毕竟我又不是从业者，我只要等事物继续发展下去就好了，而且我通篇整楼下来都在说明AI确实无法独立完成这些工作，甚至还有太多缺陷，不知道有啥好吐槽的，纵使这样又如何呢，事物的发展又不是静态的

这层楼的主题是讨论现有AI的局限，不是为了扣帽子AI创不创新的，这个话题你想继续可以去微博，毕竟我确实不想讨论这方面，只是顺口说了一句

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  アトラクナクア  
##### 136#       发表于 2023-3-26 03:02

 本帖最后由 アトラクナクア 于 2023-3-26 03:11 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226177&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-26 02:51</a>

那我要不要和你谈谈克拉克世界投稿被GPT生成内容挤爆的事情，纯粹AI能力确实不足，可这不是还有用 ...</blockquote>

普通人+ai也不过是爆吧狗，ai在懂美学 懂文学的小画家小作家手里才能变成生产工具，高级笔刷，外面那个炼林黛玉的就是美术内行。替代不可能的。

全网ai发展出啥了？有创新过吗？你这种逻辑被人堵死就语焉不详抱经验主义大腿（甚至推特趋势，这玩意但凡围观过几次大选），还给对方扣一言堂帽子（有人封你号了？）的脑子倒是能瞬间被ai替代。用贴吧老哥训练的ai杠起来那叫一个沾衣十八跌<img src="https://static.saraba1st.com/image/smiley/face2017/044.png" referrerpolicy="no-referrer">

*****

####  yesicant  
##### 137#         楼主| 发表于 2023-3-26 03:03

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226207&amp;ptid=2125850" target="_blank">アトラクナクア 发表于 2023-3-26 03:02</a>
普通人+ai也不过是爆吧狗而已，ai在懂美学 懂文学的小画家小作家手里才能变成生产工具，外面那个炼林黛玉 ...</blockquote>
你说的对

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  宇宙驼鹿  
##### 138#       发表于 2023-3-26 03:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226207&amp;ptid=2125850" target="_blank">アトラクナクア 发表于 2023-3-26 03:02</a>
普通人+ai也不过是爆吧狗，ai在懂美学 懂文学的小画家小作家手里才能变成生产工具，高级笔刷，外面那个炼 ...</blockquote>
我大概能明白你的意思，不就是寻思楼主是弱智，所以他说的都是弱智话。
但至少通贴下来大伙还是讲技术摆例子。
你有什么高论不妨直说<img src="https://static.saraba1st.com/image/smiley/face2017/004.gif" referrerpolicy="no-referrer">，不用玩这套哈

—— 来自 realme RMX3350, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.0.4-play

*****

####  アトラクナクア  
##### 139#       发表于 2023-3-26 03:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226246&amp;ptid=2125850" target="_blank">宇宙驼鹿 发表于 2023-3-26 03:28</a>

我大概能明白你的意思，不就是寻思楼主是弱智，所以他说的都是弱智话。

但至少通贴下来大伙还是讲技术摆 ...</blockquote>
你这第一步总结就错的离谱。我怎会认为他说的话都是弱智话呢？他在自己专业的领域上没有问题，但出了专业就开始跑偏了（他的迪士尼倒闭也没有讲技术摆例子不是么）我让他老实呆在自己舒适区装逼。

你不如让chatgpt来帮你做阅读理解<img src="https://static.saraba1st.com/image/smiley/face2017/044.png" referrerpolicy="no-referrer">

*****

####  大江户战士  
##### 140#       发表于 2023-3-26 03:44

<img src="https://static.saraba1st.com/image/smiley/face2017/004.gif" referrerpolicy="no-referrer">反ai的进ai技术楼里暴论

*****

####  アトラクナクア  
##### 141#       发表于 2023-3-26 03:53

生活中一句道理都讲不出，贴tag的瘾头巨大的人。很适合一辈子给ai洗脚当tag奴工啊。

*****

####  大江户战士  
##### 142#       发表于 2023-3-26 03:54

 本帖最后由 大江户战士 于 2023-3-26 03:57 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226122&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-26 02:34</a>

卷积本身就能实现注意力这个特征，现在也不乏相关实现，为了算力妥协是一直存在的，归根结底，还是结构不 ...</blockquote>
ViT里的transformer就相当于一个感受野为整个图片的卷积核

*****

####  大江户战士  
##### 143#       发表于 2023-3-26 03:58

 本帖最后由 大江户战士 于 2023-3-26 04:02 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226103&amp;ptid=2125850" target="_blank">autapomorphy 发表于 2023-3-26 02:28</a>

注意力机制和算力不足有啥关系？这个方法纯粹是为了实现“注意力”这个特征啊

要说算力的妥协应该是模型大 ...</blockquote>
因为原本的RNN实际上只有很短的记忆窗口，transformer通过qkv这种巧妙的矩阵运算实现了（理论上）无限长的记忆窗口

transformer的引入**降低了seq2seq所需的算力

至于ViT，其实异曲同工

*****

####  hwubh  
##### 144#       发表于 2023-3-26 04:03

我个人是觉得ml这套理论是做不出通用AI的，不过从工具的角度，弱AI已经足够了。 等算力难以再提升时，或许可以考虑下弱AI的结合这些方向<img src="https://static.saraba1st.com/image/smiley/face2017/034.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  你气不气  
##### 145#       发表于 2023-3-26 04:08

<blockquote>不织布 发表于 2023-3-26 02:16
人脑的可解释性在哪里?</blockquote>
你不知道人脑的可解释性不代表它不可解释，你的智能又不是基于你对你智能的理解运转的

*****

####  宇宙驼鹿  
##### 146#       发表于 2023-3-26 04:09

 本帖最后由 宇宙驼鹿 于 2023-3-26 04:11 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226256&amp;ptid=2125850" target="_blank">アトラクナクア 发表于 2023-3-26 03:35</a>
你这第一步总结就错的离谱。我怎会认为他说的话都是弱智话呢？他在自己专业的领域上没有问题，但出了专业 ...</blockquote>
—— 来自 realme RMX3350, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.0.4-play

*****

####  アトラクナクア  
##### 147#       发表于 2023-3-26 04:14

 本帖最后由 アトラクナクア 于 2023-3-26 04:31 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226299&amp;ptid=2125850" target="_blank">宇宙驼鹿 发表于 2023-3-26 04:09</a>

—— 来自 realme RMX3350, Android 12上的 S1Next-鹅版 v2.0.4-play</blockquote>

<img src="https://static.saraba1st.com/image/smiley/face2017/044.png" referrerpolicy="no-referrer"> 我有什么动机在他舒适区打他的脸啊，ai在逻辑上弱势的观点我是赞同他的。

二极管和输不起的杠精并不是中文互联网【】特产。请不要妄自菲薄。

<img src="https://img.saraba1st.com/forum/202303/26/042124ijtg7z7d7iudrju9.jpeg" referrerpolicy="no-referrer">" src="https://static.saraba1st.com/image/common/none.gif" referrerpolicy="no-referrer">

<strong>9688C240-6717-41A7-90AA-37104122C76A.jpeg</strong> (241.45 KB, 下载次数: 0)

下载附件

2023-3-26 04:21 上传

*****

####  アトラクナクア  
##### 148#       发表于 2023-3-26 04:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226299&amp;ptid=2125850" target="_blank">宇宙驼鹿 发表于 2023-3-26 04:09</a>

—— 来自 realme RMX3350, Android 12上的 S1Next-鹅版 v2.0.4-play</blockquote>
？回复呢。缩了？

*****

####  nekomimimode  
##### 149#       发表于 2023-3-26 04:35

 本帖最后由 nekomimimode 于 2023-3-26 04:36 编辑 

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">没关系，了解了AI才能更好的考虑如何发展Anti AI的路线

前提是自己双向操作，既会手工打造，也了解AI生成，否则很容易陷入到“单边主义”

*****

####  yang1820  
##### 150#       发表于 2023-3-26 04:52

 本帖最后由 yang1820 于 2023-3-25 12:57 编辑 
<blockquote>yesicant 发表于 2023-3-25 10:51
那我要不要和你谈谈克拉克世界投稿被GPT生成内容挤爆的事情，纯粹AI能力确实不足，可这不是还有用 ...</blockquote>
笑死，没想到在一个讨论ai理论的帖子里看到自己XD 那我就出来理客中一把吧。

有一说一，现在的绘画AI确实会对娱乐业产生影响，尤其中低端，或者是个人小作坊式的创作群体。但是你举的这个迪士尼例子很不好，因为它是做顶级大型娱乐的。

大型娱乐作品本质是一种大型工程，给这类作品做创意设计，不仅仅是这玩意好不好看的问题，它还要牵扯到大量的工程对接，技术实现等问题，这里面需要从业人员有跨学科的理性思维能力。而且由于是行业龙头，多少要对创新有点追求。所以在可见的未来，如果现在这套大模型AI的框架没有重大突破。那么你还是要依靠大公司里的这堆专业人士来提供大型娱乐项目。并且这个市场不会因为中低端文化产品产能的暴涨而消失，甚至都不会萎缩，因为它也可以自我迭代，产生更庞大更复杂的项目，以拉高人们的预期。

说白了，娱乐业是个上下限差距很大的行业。我觉得你还是对它上限的技术含量有点低估了。


*****

####  aaabbbccc__  
##### 151#       发表于 2023-3-26 07:55

<blockquote>MuramasaSP 发表于 2023-3-25 22:22
现在AI对人类构建的、抽象的东西（如语言）的理解程度远超对于现实世界的理解（如视觉信号）。 ...</blockquote>
现在这套靠的是人脑的理解。一个多维空间模型有个毛线的理解。 

*****

####  julius0147  
##### 152#       发表于 2023-3-26 10:08

看能源帖里想到，现在的ai不谈上限的局限，在理论上能，能在比较经典的已知环境下达到游戏里基地车那种自动搭建的效果吧。

就是不考虑创造性方面的门槛要求，或者极端点就是先由人来搭建一个电厂，作为学习方案之一让ai学习，然后拆了电厂，然后ai从设计到统筹施工来自主建设一遍，能不能实现？

如果能实现感觉就是一个可以持续投入的方向；暂时理论上都不能实现，感觉就是一个从下限来评估的局限性的方法，毕竟从上限的强智能标准，可能标尺就只有人自己，而从下限不以人为标尺，直接以某些实践结果来衡量排查问题点，可能更有效。

—— 来自 HUAWEI OXF-AN00, Android 10上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.4.4-alpha

*****

####  白左  
##### 153#       发表于 2023-3-26 10:37

现在像是用一个黑箱模拟另一个黑箱

悲观估计，真正的强ai可能需要人类理解思维的本质驱动力之后才会出现

*****

####  不织布  
##### 154#       发表于 2023-3-26 10:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226298&amp;ptid=2125850" target="_blank">你气不气 发表于 2023-3-26 04:08</a>

你不知道人脑的可解释性不代表它不可解释，你的智能又不是基于你对你智能的理解运转的 ...</blockquote>
按你这个可解释定义，你就没资格判定ai是否有可解释性


*****

####  Sunyalche  
##### 155#       发表于 2023-3-26 11:10

RLHF影响整体性能可以理解, 但是像主题说的一样对泛化能力影响明显比其他方面的影响大就有点难受了

*****

####  shaoniu1  
##### 156#       发表于 2023-3-26 11:13

如果给gpt喂海量的数学题，它会不会具有数学能力


*****

####  CCauchy  
##### 157#       发表于 2023-3-26 11:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225764&amp;ptid=2125850" target="_blank">宏. 发表于 2023-3-26 01:11</a>
数学和文学的最大区别就是每一步都是100%概率的逻辑推理，100%概率在自然语言中是几乎不存在的所以LLM当 ...</blockquote>
数学语言描述不准确的情况可太多了

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  宏.  
##### 158#       发表于 2023-3-26 11:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60228244&amp;ptid=2125850" target="_blank">CCauchy 发表于 2023-3-26 11:57</a>

数学语言描述不准确的情况可太多了

论坛助手,iPhone</blockquote>
数学描述不准确的问题出在人类身上而不是数学身上

*****

####  jojog  
##### 159#       发表于 2023-3-26 12:01

<img src="https://static.saraba1st.com/image/smiley/face2017/124.png" referrerpolicy="no-referrer">我是觉得AI现在最大的局限性是人类已经不能理解AI为什么会有这种回答了

人类尚且可以用工资法律来使其负责，AI即使出现了hallucination也没法进行管制和约束，而且天知道这种hallucination会不会随着技术发展变多还是变少

比如AI一句“我理解您的看法”，人类现在或许会脑补出AI确实“理解”了我的看法，但是如果没有呢？


*****

####  rsgdn  
##### 160#       发表于 2023-3-26 12:22

遇事不决哥德尔<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  罗克萨斯  
##### 161#       发表于 2023-3-26 12:32

别还没出现强人工智能，先把自己降智了，AI信奉者越来越有邪教徒那味了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

﹍﹍﹍

评分

 参与人数 1战斗力 -1

|昵称|战斗力|理由|
|----|---|---|
| 不织布|-1|造帽子|

查看全部评分


*****

####  yesicant  
##### 162#         楼主| 发表于 2023-3-26 12:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60227333&amp;ptid=2125850" target="_blank">julius0147 发表于 2023-3-26 10:08</a>
看能源帖里想到，现在的ai不谈上限的局限，在理论上能，能在比较经典的已知环境下达到游戏里基地车那种自动 ...</blockquote>
目前业界最强的多模态模型PaLm-E，甚至摸到了具身智能的边缘，但实际效果也就那样，倒不是说不能改进，而是现有AI的“学习”并没有那么万能，实质应该评估的是“小样本学习”的能力，更重要的来自于对于仿生学方面的迷思，也就是通过抽象出各种思维方法来组装出弗兰肯斯坦，这一步也尚且不知道能不能走的通，离这个目标还是很远的…

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  lvcha  
##### 163#       发表于 2023-3-26 12:53

<blockquote>yesicant 发表于 2023-3-25 20:03
我也是这么考虑，尽管只是弱人工智能，但如果真的不停迭代下去，不断地改良与进步，也许真的可以让我们到 ...</blockquote>
资本家的乌托邦而已

*****

####  yesicant  
##### 164#         楼主| 发表于 2023-3-26 13:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60227854&amp;ptid=2125850" target="_blank">Sunyalche 发表于 2023-3-26 11:10</a>
RLHF影响整体性能可以理解, 但是像主题说的一样对泛化能力影响明显比其他方面的影响大就有点难受了 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">的正轨，人工干预调检之后直接影响了全局的答案多样性，就会严重遏制AI能力

目前业界比较有效的妥协解决方法可能就是冻结大模型附加参数增量(或其他办法)微调了
https://mp.weixin.qq.com/s/m3fNselWKQ2m5XnBe79fQQ

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  Rho  
##### 165#       发表于 2023-3-26 13:05

按正常的思路，强AI至少也得有多媒体输入和自省内部状态这两个前提吧。只喂语料就想突破，恕我直言，就跟在阿尔法狗的棋谱里看到它的灵魂一样胡扯

*****

####  yesicant  
##### 166#         楼主| 发表于 2023-3-26 13:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60228760&amp;ptid=2125850" target="_blank">Rho 发表于 2023-3-26 13:05</a>
按正常的思路，强AI至少也得有多媒体输入和自省内部状态这两个前提吧。只喂语料就想突破，恕我直言，就跟在 ...</blockquote>
是的，很多功能和能力，现实情况是你不去做，就不会出现，也不可能自己冒出来。

用智能手机来打比方就是，没有安装那些硬件，就不会有摄像头/闪光灯/震动/NFC这些能力，如果期望什么都没有的AI能够自主进化成强人工智能，和期待手机能够成精是一样的，这也是我为何一直在强调结构的原因<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  1eV=1.60e-19J  
##### 167#       发表于 2023-3-26 13:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60225748&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-26 01:08</a>

这个是最近(一年)很火的COT思维链，你搜索一下的话网络上应该有大量的资料。

我个人觉得，这可能触及了 ...</blockquote>
CoT 有效果是因为现在的 Transformer 架构本身没有短期记忆/工作记忆吧。尽管模型本身没有这个能力，它可以利用把本来要放到工作记忆里的内容输出到 context 里自回归来达到类似的效果。用户告诉它去一步步思考其实就是提示它可以用输出的一部分作为演算的草稿纸。如果逼着这些模型直接输出最终计算结果不输出任何思考过程，那相当于让一个没有工作记忆的人不使用草稿纸做计算，准确率可想而知。


*****

####  yesicant  
##### 168#         楼主| 发表于 2023-3-26 13:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60228838&amp;ptid=2125850" target="_blank">1eV=1.60e-19J 发表于 2023-3-26 13:13</a>
CoT 有效果是因为现在的 Transformer 架构本身没有短期记忆/工作记忆吧。尽管模型本身没有这个能力，它可 ...</blockquote>
Transformer的序列处理长度能不能称为工作记忆我尚且不能非常有效的进行定义

不过现在的Prompt工程在我看来非常类似“记忆”这种功能的原型，人类为何会有记忆？不以原因而以目的判断的话，仿佛就是为了更好的进行输入，以达到更好的输出效果而诞生的

虽然目前长程记忆，或者相关的记忆模型功能在业界看来还是超级天坑(可以填进去几万篇论文都不止的)

先假设有这么一种记忆模型，能够记忆时序，形成印象记忆，甚至自动遗忘，总之与人类记忆功能差不多，那么这个模型本身是不具有多么强大的能力的，但如果给这个模型接入LLM，记忆模型就可以充分的进行自主Prompt输入/调优/对齐，接收LLM模型的反馈调整自我，并且充分发挥预训练模型的能力

再瞎想一下的话，因果能力可能就来源于记忆(？)，那么无疑这种协作的模型就具有强人工智能的潜力了

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  NameLess2501  
##### 169#       发表于 2023-3-26 13:31

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60227562&amp;ptid=2125850" target="_blank">白左 发表于 2023-3-26 10:37</a>

现在像是用一个黑箱模拟另一个黑箱

悲观估计，真正的强ai可能需要人类理解思维的本质驱动力之后才会出现 ...</blockquote>
以为的人类生物技术——人造病毒、转基因改造、无所不能

实际上，手搓细胞都做不到

人类离理解思维和意识的本质还差得远


*****

####  CCauchy  
##### 170#       发表于 2023-3-26 13:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60228251&amp;ptid=2125850" target="_blank">宏. 发表于 2023-3-26 11:58</a>

数学描述不准确的问题出在人类身上而不是数学身上</blockquote>
数学是数学，数学语言是数学语言

*****

####  你气不气  
##### 171#       发表于 2023-3-26 13:55

<blockquote>不织布 发表于 2023-3-26 10:40
按你这个可解释定义，你就没资格判定ai是否有可解释性</blockquote>
你在扯啥，可解释性又不是我定义的

*****

####  CCauchy  
##### 172#       发表于 2023-3-26 13:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60224547&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 22:49</a>

这两个能力本身很难定义，什么是真正的谎言，像AI那样输出错误的概率分布是谎言吗，存储第一次的输出进行 ...</blockquote>
只要内部与外部不一致就算谎言，但是这个内部是不可知的，所以也可以说没法定义


*****

####  yesicant  
##### 173#         楼主| 发表于 2023-3-26 14:08

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60229183&amp;ptid=2125850" target="_blank">CCauchy 发表于 2023-3-26 13:58</a>
只要内部与外部不一致就算谎言，但是这个内部是不可知的，所以也可以说没法定义 ...</blockquote>
我大概能够理解你的意思，但现在的模型内部实质上其实犹如一本词典，再加个输出根据词典进行续写，本质上不存在这种功能

拆开黑箱子的工作也有不少业界人士在做，比如
https://rome.baulab.info/

<img src="https://img.saraba1st.com/forum/202303/26/140839e79e453u833reez2.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230326-140801.jpg</strong> (501.77 KB, 下载次数: 0)

下载附件

2023-3-26 14:08 上传

<img src="https://img.saraba1st.com/forum/202303/26/140839m55m22y8hmxxxm52.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230326-140815.jpg</strong> (344.6 KB, 下载次数: 0)

下载附件

2023-3-26 14:08 上传

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  不织布  
##### 174#       发表于 2023-3-26 14:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60229159&amp;ptid=2125850" target="_blank">你气不气 发表于 2023-3-26 13:55</a>

你在扯啥，可解释性又不是我定义的</blockquote>
你不是在扯 不走可解释就是弯路吗，证据呢


*****

####  schneehertz  
##### 175#       发表于 2023-3-26 15:00

神经网络，GPT都是靠大力出奇迹搞成功的，也许对于有设计型思路的人来说很难接受吧

不过是谁在走弯路就很难说了


*****

####  你气不气  
##### 176#       发表于 2023-3-26 15:11

<blockquote>不织布 发表于 2023-3-26 14:09
你不是在扯 不走可解释就是弯路吗，证据呢

不知道可解释也算有可解释性 这当然是你的发明的定义

 ...</blockquote>
本来就是发表自己的看法，我说弯路你不认可不就完了，关可解释性定义啥事


*****

####  宇宙驼鹿  
##### 177#       发表于 2023-3-26 15:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226317&amp;ptid=2125850" target="_blank">アトラクナクア 发表于 2023-3-26 04:19</a>
？回复呢。缩了？</blockquote>
和你对线属实是浪费泥潭难得认真讨论的帖子，别把自己想的太重要哈<img src="https://static.saraba1st.com/image/smiley/face2017/049.png" referrerpolicy="no-referrer">。你看这贴里还有人理你么

—— 来自 realme RMX3350, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.0.4-play

*****

####  mimighost  
##### 178#       发表于 2023-3-26 15:19

人类也是复读机+1

人类的语言能力是故意训练出来的，那些从小被动物养大的人，之后要再次获取语言能力是非常困难的。那么他们的“智力”就无法说起，充其量就是有意识而已。

Transformer目前你管它幻觉不幻觉，他已经有了智力，但是它没有意识，毕竟一旦gpu的显存清零，这个它就“死”了，下一个request进来又是一个新的“它”


*****

####  scpS1  
##### 179#       发表于 2023-3-28 00:58

ai确实没法取代顶尖和上层的从业者。但是是否会阻断入行者的生存空间，进而切断上层的人员供给呢？就好像是没有次级联赛和青训的顶级联赛一样，很快就会变成无源之水。来自: iPhone客户端


*****

####  ft1276130  
##### 180#       发表于 2023-3-28 01:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222480&amp;ptid=2125850" target="_blank">ddddxxx 发表于 2023-3-25 20:09</a>

ai已经快从中文房间变成哲学僵尸了吧。说不定发展到最后没有证明ai有智能，反而证明了人类没有智能呢[f:067 ...</blockquote>
可惜超过时间了，不然肯定给你加鹅。

这个真的是这半年来最大的感触。

gpt给我最大的震撼就是——或许人类有智能，其实只是我们一厢情愿的幻觉？

我们或许只是「语言」的奴仆。


*****

####  不织布  
##### 181#       发表于 2023-3-28 01:07

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60247274&amp;ptid=2125850" target="_blank">scpS1 发表于 2023-3-28 00:58</a>

ai确实没法取代顶尖和上层的从业者。但是是否会阻断入行者的生存空间，进而切断上层的人员供给呢？就好像是 ...</blockquote>
如果社会有需求,就和核弹人才一样培养罗


*****

####  manysun  
##### 182#       发表于 2023-3-28 01:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60247317&amp;ptid=2125850" target="_blank">ft1276130 发表于 2023-3-28 01:05</a>
可惜超过时间了，不然肯定给你加鹅。

这个真的是这半年来最大的感触。

gpt给我最大的震撼就是——或许人 ...</blockquote>
失语症患者的智力是正常的

*****

####  CCauchy  
##### 183#       发表于 2023-3-28 01:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222594&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 20:23</a>
想象人类的简单拟人构架，似乎是这样的

你有一个先天的先验结构，除此之外没有任何东西，然后外界不断地给 ...</blockquote>
何止？婴儿大脑刚发育好的时候也没什么东西刺激它吧，可以认为初始化是随机的吗？出生后的刺激各不相同，却可以自动收敛产生意识和很强的语言学习能力。别到时候体外培养的婴儿没有智力<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">生物学家拿图灵奖

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  mimighost  
##### 184#       发表于 2023-3-28 01:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60247317&amp;ptid=2125850" target="_blank">ft1276130 发表于 2023-3-28 01:05</a>

可惜超过时间了，不然肯定给你加鹅。

这个真的是这半年来最大的感触。

gpt给我最大的震撼就是——或许人 ...</blockquote>
人类其实也不了解什么是“智能”

我们对于聪明的定义是从结果出发的，你聪明要么：

1. 你考试成绩优异

2. 要么你赚很多很多的钱

所以智能的定义是什么呢？给你一个环境，给你一个收益函数，能够获得更高的收益的，就是更有“智能”的个体。否则所谓的“智能”基本也就等同于人与非人这个简单的分类，因为直到去年底为止，有类似能力的系统，在我们的认知范围内，就只有人类自己而已。

现在gpt能够通过大量的人类考试，如果要否认它具有智能，那么智能修改智能的定义。

*****

####  mimighost  
##### 185#       发表于 2023-3-28 02:00

我觉得这样下去，迟早会有gpt和gpt对打的对抗性智能体的出现，5-10年之内，在日常任务超越人类性能和稳定性的LLM出现，可能是大概率事件。

我一个程序员，看着gpt4，我也没勇气说这玩意儿就不能替代我，你可以去看openai的几个头子的采访，究竟这个系统的上限在哪里，谁都说不准，但是路径已经被人指出来，那么有人去训练那只是迟早的事情。

当然乐观点，以后的gpt，迟早会到一个损益点，要么训练的成本无法接受，要么推理的成本过高，同时人类因为之前gpt的挤压，工资变得越来越低，形成一个动态的平衡。

赢的最后还是资本家

政府出台gpt使用税应该也只是时间问题

*****

####  mimighost  
##### 186#       发表于 2023-3-28 02:07

最近看了一系列的访谈

其中一个是采访深度学习之父hinton的

记者问他chatgpt是什么程度的创新，他说是个电力同等程度的创新，或者是和轮子一样伟大的创新

这个老爷子功成名就，也不是网红，基本不打诳语，所以他应该是打心底里就是这么想的

gpt这个东西，带来的革新，那就是将“智能”电力化，以后智能这种服务，也可以按需收费。现在律师、会计、程序员、设计师这些职业划分，最终都会按照单词数进行计价，肯定是革命性。

*****

####  nekomimimode  
##### 187#       发表于 2023-3-28 02:41

“他们知道能做什么，但不知道为什么能做”

这不就是，新世界的卡密吗<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  瓦格雷  
##### 188#       发表于 2023-3-28 06:32

<blockquote>yesicant 发表于 2023-3-25 21:50
这倒也是，首先要经济上划得来才能继续维持下去大模型未来的道路也必然是拆出更多可解释的原理和 ...</blockquote>
围棋AI现在PC上就可以跑  所以才有围棋解说按照AI胜率进行解说


*****

####  lilisipis  
##### 189#       发表于 2023-3-28 07:49

最重要的这是一个思路只要能力大那什么砖都能飞，像瓶颈中的无人驾驶是不是只要模拟足够多的驾驶过程就能自动学会开车，也许理解不了人类智能本质永远造不出来强人工智能。但能轻松造出一个百科全书绘图大师赛车手音乐大师游戏高手的集合版弱人工智能，虽然它都不理解自己在做什么，什么盲目痴愚之神


*****

####  Zepp  
##### 190#       发表于 2023-3-28 09:26

其实已经足够了不是吗？

人类日常至少99%的工作都是在解决早已存在的问题，只是不断会有不同的人去踩坑，所以需要不断解决。目前来看，至少chatgpt很好地能够简化这个踩坑的过程，减少无谓的重复思考


*****

####  从心，  
##### 191#       发表于 2023-3-28 10:04

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60226207&amp;ptid=2125850" target="_blank">アトラクナクア 发表于 2023-3-26 03:02</a>

普通人+ai也不过是爆吧狗，ai在懂美学 懂文学的小画家小作家手里才能变成生产工具，高级笔刷，外面那个炼 ...</blockquote>
然而普通人到小画家比普通人拥有审美难多了，因此ai对门槛的下降作用仍然存在

*****

####  アトラクナクア  
##### 192#       发表于 2023-3-28 10:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60248735&amp;ptid=2125850" target="_blank">从心， 发表于 2023-3-28 10:04</a>

然而普通人到小画家比普通人拥有审美难多了，因此ai对门槛的下降作用仍然存在 ...</blockquote>
这是天大的错觉<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">成为小画家把手练熟不过3个月报班的事。拥有审美却是花费一辈子都不见得能达到的目标。

识字门槛最低，但也没见高质量文手比高质量画手多（甚至更少）。重要的是知道何为好何为坏而不是手头熟练。

*****

####  アトラクナクア  
##### 193#       发表于 2023-3-28 10:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60248735&amp;ptid=2125850" target="_blank">从心， 发表于 2023-3-28 10:04</a>

然而普通人到小画家比普通人拥有审美难多了，因此ai对门槛的下降作用仍然存在 ...</blockquote>
这是天大的错觉<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">成为小画家把手练熟不过3个月报班的事。拥有审美却是花费一辈子都不见得能达到的目标。

识字门槛最低，但也没见高质量文手比高质量画手多（甚至更少）。重要的是知道何为好何为坏而不是手头熟练。


*****

####  pf67  
##### 194#       发表于 2023-3-28 10:19

深度学习不就是这么一回事么，神经网络做的事情就是帮你实现样本的特征工程而已。

现在是证明了大力（天量数据）可以出奇迹，但是始终是大力而不是巧妙的解。

当然，实际上人类可能并不需要巧妙的解，大力的成本可以接受那就OK了


*****

####  从心，  
##### 195#       发表于 2023-3-28 10:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60248804&amp;ptid=2125850" target="_blank">アトラクナクア 发表于 2023-3-28 10:13</a>

这是天大的错觉成为小画家把手练熟不过3个月报班的事。拥有审美却是花费一辈子都不见得能达到的目 ...</blockquote>
识字之于文学审美犹如几何教育之于绘画审美 

如果只耕耘技术而不进行审美教育，三个月学班学出来的小画家似乎和普通人是没有什么区别的，你很难说ai在他手里和在普通人手里有什么区别

你所谓的拥有审美带有不可知论的意思在里面，我承认美学的上限确实如此，但事实上通俗审美并不是多么难以进行教育的，体系化与理论化的，甚至是更为经验的

基于拟合的ai肯定是不可能实现某种革命，但是就现在的阶段而言其提高生产力的属性是普遍存在的


*****

####  アトラクナクア  
##### 196#       发表于 2023-3-28 10:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60248976&amp;ptid=2125850" target="_blank">从心， 发表于 2023-3-28 10:30</a>

识字之于文学审美犹如几何教育之于绘画审美 

如果只耕耘技术而不进行审美教育，三个月学班学出来的小画家 ...</blockquote>
完全赞同。所以我之前的回复里有限定语《懂美学 懂文学》的小画家小作家。审美教育肯定要加强，这也是当前教育系统中极为缺失的一环。刚才说可能一辈子也难以掌握是考虑到有人色感确实不好。

生产力肯定提高，但生产的是啥就不好说了。

*****

####  アトラクナクア  
##### 197#       发表于 2023-3-28 10:45

卡

*****

####  アトラクナクア  
##### 198#       发表于 2023-3-28 10:45

卡

*****

####  アトラクナクア  
##### 199#       发表于 2023-3-28 10:45

 本帖最后由 アトラクナクア 于 2023-3-28 10:47 编辑 

卡

*****

####  アトラクナクア  
##### 200#       发表于 2023-3-28 10:45

 本帖最后由 アトラクナクア 于 2023-3-28 10:47 编辑 

卡


*****

####  烂掉蛇  
##### 201#       发表于 2023-3-28 11:31

AI能做到归纳这一点已经很强了，下一步做到推导就没人类什么事了


*****

####  完先生  
##### 202#       发表于 2023-3-28 13:26

能够做到一个合格好用的工具，已经能够取代许多人类了


*****

####  oldq  
##### 203#       发表于 2023-3-28 13:46

个人感觉，人脑创造性思维时，运算比较接近量子运算的算法，直接列出结果再去计算到达的方法，ai算法都还是传统的，一步步分析现有资源产生下一步结果

—— 来自 Xiaomi M2012K11AC, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  yesicant  
##### 204#         楼主| 发表于 2023-3-28 13:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60247907&amp;ptid=2125850" target="_blank">lilisipis 发表于 2023-3-28 07:49</a>
最重要的这是一个思路只要能力大那什么砖都能飞，像瓶颈中的无人驾驶是不是只要模拟足够多的驾驶过程就能自 ...</blockquote>
可解释性倒也不是完全那么玄乎，发现现有AI和算法的不足并进行可以预判的改进与思考，人类未必真的要深入了解到每个参数的偏置，但光是这些都可以将AI的能力继续推进了，比如下面这些哲思

<img src="https://img.saraba1st.com/forum/202303/28/134547lmmm6yrbmuesk9by.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230328-134241.jpg</strong> (253.26 KB, 下载次数: 0)

下载附件

2023-3-28 13:45 上传

<img src="https://img.saraba1st.com/forum/202303/28/134557sddfa8dfaz6gdif3.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230328-134250.jpg</strong> (247.31 KB, 下载次数: 0)

下载附件

2023-3-28 13:45 上传

<img src="https://img.saraba1st.com/forum/202303/28/134601dz8ix2kthhhxx52c.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230328-134307.jpg</strong> (396.88 KB, 下载次数: 0)

下载附件

2023-3-28 13:46 上传

<img src="https://img.saraba1st.com/forum/202303/28/134608gt8ww8wrubg2r818.jpg" referrerpolicy="no-referrer">

<strong>c23cb179-bc58-4b0c-9736-e0b9779c26ee.jpg</strong> (1001.55 KB, 下载次数: 0)

下载附件

2023-3-28 13:46 上传

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  Pz079  
##### 205#       发表于 2023-3-28 13:48

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60222550&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-25 20:18</a>
看到了你的补充资料，这个“慢思维”似乎初步理解起来很简单，但实际上认真分析这个慢思维需要完成的理论 ...</blockquote>
谁告诉你理解事物的实质不是靠拟合？拟合即使不是人类智能的全部，也是人类智能的一大部分，你从婴儿成长成一个智能完整的人类，多少部分是经验拟合，多少部分是范畴推理？请问你第一次直立行走，第一次叫你妈给你喂奶，你是推理出来的？还是拟合出来的？


*****

####  yesicant  
##### 206#         楼主| 发表于 2023-3-28 13:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60250905&amp;ptid=2125850" target="_blank">oldq 发表于 2023-3-28 13:46</a>
个人感觉，人脑创造性思维时，运算比较接近量子运算的算法，直接列出结果再去计算到达的方法，ai算法都还是 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">人脑也要一步步分析，上面那个快思维的形容还是挺精准的，直接命中的结果非常不可靠，连杨振宁都要审慎思维

<img src="https://img.saraba1st.com/forum/202303/28/135114kp9dxw2q1q4uqhzw.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230328-135029.jpg</strong> (391.2 KB, 下载次数: 0)

下载附件

2023-3-28 13:51 上传

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  yesicant  
##### 207#         楼主| 发表于 2023-3-28 13:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60250949&amp;ptid=2125850" target="_blank">Pz079 发表于 2023-3-28 13:48</a>
谁告诉你理解事物的实质不是靠拟合？拟合即使不是人类智能的全部，也是人类智能的一大部分，你从婴儿成长 ...</blockquote>
以偏概全没有什么意义，世界上有无数的异常模式，现实需要的是综合发展前进，至于你说的婴儿智能，其对于环境的综合反馈可以进行自主的奖励判断，是多种智能方式经由先验结构结合的结果，现在连具体的情形都不明朗的情况下，你这样在没有审慎思维的情形下直接试图得到结论，就有点像AI不经过逻辑链直接拟合复杂任务<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">大概率失败的

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  Pz079  
##### 208#       发表于 2023-3-28 14:04

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60251081&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-28 13:56</a>
以偏概全没有什么意义，世界上有无数的异常模式，现实需要的是综合发展前进，至于你说的婴儿智能，其对于 ...</blockquote>
拟合即使不是人类智能的全部，也是人类智能的一大部分，人类智能的先验结构尚未确定，但你直接否认拟合至少是人类本质的一部分，就太绝对了，你甚至无法否认知识得以成立，很大程度上就是经验质料。范畴和规律这种先验结构，比如数学，甚至可以认为以数学语言表达的规则定义而已，如果数学规则和围棋规则没有本质区别，为何不能期待一下数学语言的自我进化？在这个意义上，所谓的推理能力，甚至可能是拟合能力涌现以后的副产品

*****

####  gogoneogg  
##### 209#       发表于 2023-3-28 14:07

有问题，发现问题，才能改进，进步嘛，很正常

*****

####  yesicant  
##### 210#         楼主| 发表于 2023-3-28 14:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60251192&amp;ptid=2125850" target="_blank">Pz079 发表于 2023-3-28 14:04</a>
拟合即使不是人类智能的全部，也是人类智能的一大部分，人类智能的先验结构尚未确定，但你直接否认拟合至 ...</blockquote>
我并不准备反驳你的思路，毕竟实质上大部分能进行相关思考已经是很不错了，每个人都有一千个对于AI的想法，我也不能确保我的话语是绝对正确的

只是在综合分析了现在情况下得到的部分结论<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">至于数学的问题，我前边的楼已经说过了，数学全部都是正确的，但最终只能有一部分用到现实

如果你有不同意见，也不需要急着反驳我，客观现实才是需要认真分析与理解的对象，战胜了我也没啥意义

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  hugosol  
##### 211#       发表于 2023-3-28 14:50

看到楼上说审美能力比表达能力重要这个观点，突然觉得很有意思

其实AI比起人类更有优势的地方恰好在这里，AI可以靠力大砖飞学习人类一辈子积累也记不完的知识，经过训练之后对它来说回答一个作品“好”还是“不好”更是最基本的能力，要教会AI审美说不定其实是一件很简单的事情

现在chatGPT问世之后最让人惊讶的其实是，人类没想到给AI足够多的样本之后，它的表达能力自然就提高到了近似人类的水平

一个比较跳跃的想法，假如我们教给AI审美能力之后，它用绘画表达的能力是不是也会相应提升到人类的水平呢？


*****

####  allegray  
##### 212#       发表于 2023-3-28 19:23

 本帖最后由 allegray 于 2023-3-28 19:25 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60250911&amp;ptid=2125850" target="_blank">yesicant 发表于 2023-3-28 13:46</a>

可解释性倒也不是完全那么玄乎，发现现有AI和算法的不足并进行可以预判的改进与思考，人类未必真的要深入 ...</blockquote>
关于你图里的信心校准，另一篇论文里也有提到：

GPT-4 can also be confidently wrong in its predictions, not taking care to double-check work when it’s likely to make a mistake. Interestingly, the pre-trained model is highly calibrated (its predicted confidence in an answer generally matches the probability of being correct). However, after the post-training process, the calibration is reduced (Figure 8).

机翻：

GPT-4在预测时也会自信地出错，在有可能出错的时候不注意反复检查工作。有趣的是，预训练的模型是高度校准的（它对一个答案的预测信心一般与正确的概率相匹配）。然而，在后训练过程中，校准度降低了（图8）。
<img src="https://s2.loli.net/2023/03/28/gv56Myrm8dQ1UES.png" referrerpolicy="no-referrer">

来源：
[https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)


*****

####  rainwang  
##### 213#       发表于 2023-3-29 08:50

想得太远了，现在这个解放90%生产力，并且规规模基本无上限的版本，已经像是魔法了

—— 来自 OPPO CPH2059, Android 11上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

