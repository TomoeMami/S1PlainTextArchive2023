
*****

####  精金土豆泥  
##### 1#       楼主       发表于 2023-3-12 03:02

 本帖最后由 精金土豆泥 于 2023-3-12 03:45 编辑 

最近好像关于AI绘画的讨论越来越多，

这阵子我也玩了挺多二次元生成，

开个主题说说我感觉到的AI的一些不足和其他想法

（以下讨论默认二次元图生成范畴

一般人感觉AI绘画都是“很强”

但多玩了一阵我还是觉得AI有几个明显的不足之处

其他画精密饰物变成一团糊之类的就先算了

手的话最近也有不少办法能画得还行

剩下最主要的应该是：透视，复杂动作

1：透视

目前的扩散模型AI不理解也画不出大的透视，

哪怕用ControlNet摆好带透视的姿势，

回头它还是会自己扭动成类似的低透视角度

<img src="https://p.sda1.dev/10/4583bd6db35ff126b2ddd868038c4222/111.jpg" referrerpolicy="no-referrer">

《类似这样，样子相似但是已经失去了原来大透视角度带来的张力

2.复杂动作或者冷门动作无法识别

比如一些身体&amp;手掌小臂翻转大的武术动作，

或者上半身扭动超过90度的性感动作or一只手背在背后之类的动作

<img src="https://p.sda1.dev/10/19b4734eefd83e1972c605374c8a79cd/222.jpg" referrerpolicy="no-referrer">
<img src="https://p.sda1.dev/10/bca7715b6334c9ed8c987282c9a288ec/2222.jpg" referrerpolicy="no-referrer">

&lt;难以识别复杂动作的例子

这两者相加，会极大的限制AI构图和绘画的上限。以下是我找的一些现在的AI应该做不到的例子

（可能压图，可以点开看

<img src="https://p.sda1.dev/10/6d34a6e3cf9ff80e9cb4ff235297282a/666.png" referrerpolicy="no-referrer">
<img src="https://p.sda1.dev/10/7de9109ba29b8a13aa9561399b34be56/55555.png" referrerpolicy="no-referrer"> 《《比如这样的带透视的多人动作场面
<img src="https://p.sda1.dev/10/7418b0f0599c279181070dfa49de9069/OP_Color_Volume45_HS_045_003-004.jpg" referrerpolicy="no-referrer">《《这样带有一定透视的多人稍复杂动作场景

以及真正意义上的多人运动sex（带透视和多人身体接触，而非单纯的果体摆个pose那种）

都是目前的绘画AI难以弄出来的，哪怕是有controlnet辅助

不仅是AI想不出来，和例子1的大透视草图被“画成”低透视图一样，

就算是熟练的画师画出了可用的大透视/复杂动作草稿，AI也难以认知和完善草稿，

还是要画师自己动手用老办法去完成它们。（这就是某种不可替代性了）

--------------------------------------------------------------------------------------------------------------------------------------

现在AI好看的图绝大多数都是

“单人+差不多平视 or 轻微仰视俯视+简单动作”

 再加些背景，人体透视的程度很小

多人图能配合的有动作（而不是单纯坐一圈站一圈）

的只有精心训练过的几个特定姿势

什么时候能真的突破透视和复杂动作认知这两个问题，

我觉得才能确实的搞点让人耳目一新的图出来，

不至于基本都是“高完成度的单人立绘”

而这两个问题感觉是基于现有AI二次元总的数据库而生的问题，

在扩散模型这个系统下，未来的几年内感觉很难有什么新技术能忽然解决了它们……

（或许未来可能会有什么类似训练Lora或hypernetworks那样训练空间感和透视感的新技术？

   但目前没怎么听说过

=====================================================

然后就是很多人讨论的画师失业问题了

根据上面的分析，

我觉得“能画大角度透视”+“能画复杂人体动作”的画师，

以现在基于扩散模型的绘画AI来说是难以取代的

目前的画师也可以朝着这两个方向去努力发展

（漫画方面就是油水太少，不然可能也可以算是个可选项      分镜构图情绪表达之类的，现在的AI似乎还不太可能学习和模拟

而不具有这两个特性的合格画师大概也还会剩下

表达准确+不出大错+沟通相对便捷

这几个优点

在设圈之类的特定领域还是难以被替代的，

（一般人认知的同人图方面可能确实被AI挤压很多

个人觉得AI这次总体就是能快速生成一大堆要求不高的同人图，

逼着剩下的画师进一步往各个领域特化 ，

但就像照相不会干掉画师，3D建模生成也不会干掉画师一样，

以目前的AI来看，也就是挤占一些低端和或者重复性高的领域而已

至于未来的AI有没有可能会突破这几点……

未来的事也还没人知道吧。

更长期一些的关于绘圈新血的问题，

那感觉就太过复杂，先不展开说了

（似乎容易变成车轱辘话大战……

   还是等时间自己给出答案吧

﹍﹍﹍

评分

 参与人数 7战斗力 +4

|昵称|战斗力|理由|
|----|---|---|
| RedBaby| + 1|好评加鹅|
| 大江户战士|-2|不求甚解|
| Danny28|-1|好评加鹅|
| 三尖酸努努| + 1|好评加鹅|
| Wiksy| + 1|好评加鹅|
| 翼宿一| + 2|好评加鹅|
| 南瓜爵士| + 2|好评加鹅|

查看全部评分

*****

####  terminator1990  
##### 2#       发表于 2023-3-12 03:35

给游戏和影视做物件设定和机械设定之类的强合理化设计相关岗位应该算是目前最难被AI替代的美术工作之一？

*****

####  哈扎马  
##### 3#       发表于 2023-3-12 03:42

 本帖最后由 哈扎马 于 2023-3-12 04:38 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60054552&amp;ptid=2123647" target="_blank">terminator1990 发表于 2023-3-12 03:35</a>

给游戏和影视做物件设定和机械设定之类的强合理化设计相关岗位应该算是目前最难被AI替代的美术工作之一？ ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">硬表面设计主要由前期灵感草稿和3D建模统治，高完成度2D手绘有时并不需要。事实上哪个领域想搞点能看的东西都需要逻辑和合理性，只是二次元摆烂者居多而已。

（现在再看尾田这张画得有够烂的<img src="https://static.saraba1st.com/image/smiley/animal2017/028.png" referrerpolicy="no-referrer">犯了几个低级构成错误）

*****

####  哈扎马  
##### 4#       发表于 2023-3-12 03:48

图一用建模生成/涂成深度图可能会好一些。用controlnet的骨架难以摆出有透视的动作是因为 这款骨架是15年左右ai动捕的宝贵遗产，没有z轴，两人以上同屏运动必车祸现场（上个月刚看到这骨架时一眼老熟人）

*****

####  RinQ0326  
##### 5#       发表于 2023-3-12 04:00

真想严谨的做点什么还是得要会美术....这玩意不可控的地方还是太多了,现阶段我还是更喜欢chargpt（

*****

####  elxy  
##### 6#       发表于 2023-3-12 04:11

 本帖最后由 elxy 于 2023-3-12 04:15 编辑 

透视用3D辅助会不会更好？比如先生成3D，再生成2D。目前已经有NeRF了，还有text to 3D算法，参考ControlNet修改后者的中间特征？

*****

####  nekomimimode  
##### 7#       发表于 2023-3-12 05:56

“能画大角度透视”+“能画复杂人体动作”的那种, 第一,会这种类似爆气终结技的人相对来说比较少, 第二, 从商业角度来说(尤其是游戏美术), 这种需求也并不常见, 又费事又没效率的哪有量大管饱的量产好<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">, 反正大部分时候作为2d出现的情况几乎都是站桩, 或者在AI能够覆盖的范围

有一个矛盾点就是, AI的成果基于样本的质量和数量, 这个是共识吧

如果"逼着剩下的画师进一步往各个领域特化", 那么特化的样本就会多起来, 那总有一天这些样本也会被所谓的AI拿去训练, 最后也会成为刺向自己的利刃

现在之所以对大透视和复杂动作生成困难, 就是因为样本不够,  或者说, 那种"大模型"并没有收录这些特化型动作

然而并不影响很多人自己找一些特化动作然后训练个LoRA附加上去

当这种特化型LoRA累积到一定程度的时候, 就会进一步挤压生存空间了 

*****

####  哈扎马  
##### 8#       发表于 2023-3-12 06:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60054740&amp;ptid=2123647" target="_blank">nekomimimode 发表于 2023-3-12 05:56</a>

“能画大角度透视”+“能画&amp;#x ...</blockquote>
踩穷举陷阱了属于是。一个事实，现存的样本中复杂动作/多人交互/大透视的绘画并不少<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">古典油画，漫画，动画截图，甚至3D模型三渲二360度旋转出帧就能涵盖所有角度，可ai仍然没学会（和手指一样，真人照片照错不误）。一方面以上涉及到空间理解，这得让扩散模型先攻破建模，不然只能大张正己一刀流套模板。另一方面就这个模板在复杂动作多人交互中也会出现组合爆炸这一问题，种类哪有单人平视的数量这么少，想要让画师穷尽以他们的懒惰恐怕很难，更何况积累下足够的训练集，当年阿法狗也并非以穷举的方式破解围棋，但绘画每次的target都不同，阿法狗的策略无法应用于没有审美模块的扩散模型。

（而且画面一旦复杂就会更多的涉及到美学的核心构成，这个比较超纲我不多废话）

<img src="https://img.saraba1st.com/forum/202303/12/062940qxbxffxfxn2itxuc.gif" referrerpolicy="no-referrer">

<strong>Image.gif</strong> (1021 Bytes, 下载次数: 0)

下载附件

2023-3-12 06:29 上传

商业流行作为易变的东西是最不需要担心的。当站桩在炼丹佬的努力下变得一钱不值之时，文化产品自会倾向生产不廉价的东西来让消费者觉得划算，比如pokemongo的圣诞开机图就添上了故事性（虽然画技一如既往的无语）。曾经婆罗门喜欢用jojo梗标榜身份，动画开播后一群小鬼乱刷后婆罗门便慢慢流向刃牙和海虎了。

有一个工程可以解决训练集的稀缺，那就是雇佣两万个肯尼亚黑叔叔标签工，让他们用3D模型夜以继日的不断摆出各种复杂动作在不同角度下的图像，还有两个人、三个人、N个人的不同交互方式，出来3渲染2再风格迁移作为训练集，产出效率完爆画师，如此坚持100年……大概会成功吧！

*****

####  nanrendu  
##### 9#       发表于 2023-3-12 09:36

透视和复杂动作AI做不出来，主要是类似的图少，没有图进行训练，本质上ai还是需要大量的画师素材的。
如果如你所说，画师们转向这些动作的话，总有一天AI也会赶上来，而且画的变难又不代表受众多，本质上也没有那么大需求。
这些复杂的图，对画师来说可能要练好久，成果拿AI练一练，基本上AI就学会了。
而且比起画师找更难的领域突破，还有多少人愿意在人类绘画进行钻研是个问题。
相机产生之后，画肖像画的画师们就失业了，传统绘画没落之后，也没有多少人再去研究肖像画技巧，艺术本质是要吃饭的，而且花费不菲。
现代画师画写实只能画超现实的绘画，即相机镜头拍不出来的照片，现在AI能直接合成更高清的摄像师作品之后，很难说以后画师还能画什么。

—— 来自 HUAWEI JEF-AN00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  #FFE212  
##### 10#       发表于 2023-3-12 10:34

转赛道这个我有想过，插画师转职画漫画也不是没可能。虽然国内没啥市场，但是隔壁日本还是有地方接受国人投稿的（比如jump+），大不了可以去卷日本人

*****

####  酸菜泡面  
##### 11#       发表于 2023-3-12 10:43

你针对现在这个被开源的玩具谈生产没有意义，要生产就专门打标训练就可以，或者和3d建模软件结合一下，有需求自然有人弄，分不分享是另一回事

—— 来自 samsung SM-G9600, Android 9上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  105gun  
##### 12#       发表于 2023-3-12 11:13

<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">这几个问题确实存在，不过主楼这两个例子给我的感觉是楼主你没用对controlnet。例1把草图丢进img2img的输入框也是错误的。

<img src="https://img.saraba1st.com/forum/202303/12/110930ekxx55kknjontpn3.png" referrerpolicy="no-referrer">

<strong>03174-613943361-masterpiece,1girl,solo.png</strong> (57.85 KB, 下载次数: 0)

下载附件

2023-3-12 11:09 上传

随便跑了一下看看。

*****

####  精金土豆泥  
##### 13#         楼主| 发表于 2023-3-12 11:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60056140&amp;ptid=2123647" target="_blank">105gun 发表于 2023-3-12 11:13</a>

这几个问题确实存在，不过主楼这两个例子给我的感觉是楼主你没用对controlnet。例1把草图丢进img2im ...</blockquote>
我主要是要说AI画不了大透视，

顶楼那个重绘幅度Denoising调高的是一种错法，

你这个大概是canny或者scribble出来的是一种错法，

如果用openpose出来的又是一种错法，

基本上都还是说明了AI不太画得动大透视……

建3D模型然后用depth，normal硬卡形体可以勉强固定住形态，

但别的方面就一塌糊涂，也还是一种画不动透视……

*****

####  105gun  
##### 14#       发表于 2023-3-12 11:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60056244&amp;ptid=2123647" target="_blank">精金土豆泥 发表于 2023-3-12 11:25</a>
我主要是要说AI画不了大透视，

顶楼那个重绘幅度Denoising调高的是一种错法，

你这个大概是canny或者scri ...</blockquote>
controlnet的思路是你施加几份控制，ai就干几份活。
至于让ai自由发挥的部分，别指望它有多少推理能力，严格来说这玩意儿就没有推理能力。它不懂啥是透视，出图透视正确的前提是你在controlnet里给足了它信息。
你给画师这张人物草图，即使没有告诉他背景的透视该怎么画，他也能推理出来画个大差不差。ai就不行。人物的部分也是，你给他输入什么线它就很严格地跟着走。

*****

####  酸菜泡面  
##### 15#       发表于 2023-3-12 12:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60056244&amp;ptid=2123647" target="_blank">精金土豆泥 发表于 2023-3-12 11:25</a>
我主要是要说AI画不了大透视，

顶楼那个重绘幅度Denoising调高的是一种错法，

你这个大概是canny或者scri ...</blockquote>
look up at the sky
没有用controlnet

<img src="https://p.sda1.dev/10/58a8cd1f233c2f519f363683e81172e2/CMP_20230312115756768.png" referrerpolicy="no-referrer">
<img src="https://p.sda1.dev/10/2d49e0eb8e6ef7ed6e497538e6ecf9f1/CMP_20230312115756826.png" referrerpolicy="no-referrer">

*****

####  精金土豆泥  
##### 16#         楼主| 发表于 2023-3-12 12:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60056506&amp;ptid=2123647" target="_blank">105gun 发表于 2023-3-12 11:56</a>

controlnet的思路是你施加几份控制，ai就干几份活。

至于让ai自由发挥的部分，别指望它有多少推理能力， ...</blockquote>
所以AI画大透视就是不行……

*****

####  105gun  
##### 17#       发表于 2023-3-12 12:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60056553&amp;ptid=2123647" target="_blank">精金土豆泥 发表于 2023-3-12 12:00</a>

所以AI画大透视就是不行……</blockquote>
嗯，我也不否定这个。

我想指出的是你主楼这几个只用img2img的例子确实跑不出东西来<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">。img2img就好比是把原图整个高斯模糊了一遍，denoise越大模糊越深。如果不额外加controlnet的话，ai的工作就只是在模糊的色块上加工，能画出符合原图姿势的东西就有鬼了。

*****

####  wszweill  
##### 18#       发表于 2023-3-12 12:18

很多问题就是训练集的问题，比如脸很难朝下是因为没人特意训练头顶，需要专用的lora等模型来辅助. C站上不少nsfw的lora，比如什么背后位等等脸朝下朝奇怪位置的姿势就是几十几百张图练出来的。关键是开源社区的大规模开发本身都没多久。

不过有美术基础的，用线稿--》上色肯定更有优势就是了，本身也可以是画师的生产力工具<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  abysmal  
##### 19#       发表于 2023-3-12 12:19

别说大透视了，不是平视就会出现透视错误，上3d模型都不成。

*****

####  盐盐盐盐盐  
##### 20#       发表于 2023-3-12 12:38

在ai能达到成图直出之前画师都是肯定存在的就是了
不如说可能反向降低入行门槛呢，毕竟有一些画师就是创意很好但是画技一般，可以多搞点创作

*****

####  精金土豆泥  
##### 21#         楼主| 发表于 2023-3-12 12:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60056548&amp;ptid=2123647" target="_blank">酸菜泡面 发表于 2023-3-12 12:00</a>

look up at the sky

没有用controlnet</blockquote>
呃……这……

头的变形好大啊，

然后身体都变肌肉人了，

本来理想状态下加点头发可以是贫乳美少女吧……

*****

####  酸菜泡面  
##### 22#       发表于 2023-3-12 12:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60057180&amp;ptid=2123647" target="_blank">精金土豆泥 发表于 2023-3-12 12:55</a>

呃……这……

头的变形好大啊，

然后身体都变肌肉人了，</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">一锅出来的漏点美少女当然不能放出来

*****

####  哈扎马  
##### 23#       发表于 2023-3-12 12:59

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60057180&amp;ptid=2123647" target="_blank">精金土豆泥 发表于 2023-3-12 12:55</a>

呃……这……

头的变形好大啊，

然后身体都变肌肉人了，</blockquote>
因为这只是最基础的i2i而已，素体是白的，ai就猜成裸男了，腿上的截面线猜成绷带。想有头发和衣服得在垫图上进一步提供信息。

*****

####  冰寒之月  
##### 24#       发表于 2023-3-12 13:05

大透视用自带深度信息的那个controlnet模型会好一些吧

*****

####  精金土豆泥  
##### 25#         楼主| 发表于 2023-3-12 13:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60056668&amp;ptid=2123647" target="_blank">105gun 发表于 2023-3-12 12:09</a>

嗯，我也不否定这个。

我想指出的是你主楼这几个只用img2img的例子确实跑不出东西来。img2img就好 ...</blockquote>
我肯定也用别的controlnet试过了才会这么说的啊，就是那些都是零零散散的试验，

要用了一时找不起来。

主楼这个内容本来是另一个楼的回复，

想了想整个搬过来开新贴，

没有合适的配图就顺手I2I了几张做范例

（也有一部分是因为I2I出来的图虽然不对但是大形体不至于吓人，对大家的眼睛比较好

   openpose调完出来的大透视实验品有些光论结果好像是“对”的，但实际上的观感是会很掉san……

   你应该明白我的意思

*****

####  处男鉴黄师  
##### 26#       发表于 2023-3-12 13:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60057275&amp;ptid=2123647" target="_blank">冰寒之月 发表于 2023-3-12 13:05</a>

大透视用自带深度信息的那个controlnet模型会好一些吧</blockquote>
是的，但问题是如何得到深度图。目前没有方便的从0开始生成深度图的方法，要么用已存在的构图图片，要么自己在blender里面建模。

*****

####  精金土豆泥  
##### 27#         楼主| 发表于 2023-3-12 13:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60056758&amp;ptid=2123647" target="_blank">wszweill 发表于 2023-3-12 12:18</a>

很多问题就是训练集的问题，比如脸很难朝下是因为没人特意训练头顶，需要专用的lora等模型来辅助. C站上不 ...</blockquote>
实际运用中就光是头顶和脸可能就有无数种变化，

视角的移动*距离的远近*脸的左右方向*脸的上下方向，

这四种变量要统统适配出合适的lora那工作量是很可怕的

可能是8*5*5（镜像）*6=1200个所需的lora，

每个需求几十张几百张图作为基底，肯尼亚奴工都得累到吐血

然后这些是美少女头型吧，男性帅哥头型要不要，小孩头型要不要，

壮汉或者老头头型要不要……这些人的鼻子和五官位置脸部凹凸都是不同的，

硬套下结果可能很可怕。这样工作量就又翻倍翻倍……

这些搞定了之后大概每次作图从几千上万个lora中选一个出来确实可以做到这个角度的脸型准确，

但是你要的————某个角色是否就真的能用这个方式很好的表现出来呢？

吊眼角或者垂眼角的角色概念都是用平面人物立绘训练的，换到这个立体角度会怎么样呢？

人物lora是否会和脸型头型角度lora或者其他比如眼睛或者配饰之类的冲突呢，

表情的使用会不会使得形体崩坏呢……要用lora解决这类问题实际上可能会很可怕

何况这也就是保证了脸的角度，其他手和脚会不会像15楼第二张图一样忽然长一截短一截呢，

要再用其他的lora控制么……

至于线稿+上色作为画师的辅助，其实也就只限大路货姿势和无透视简单动作，（还要克服AI的强随机性

稍微复杂一点的AI就认不到+上不好色，除非这个画师准备这辈子就画最简单的那些动作过活……

否则你一次用了AI提升水平，其他姿势复杂一点用不到AI就一团糟，那…………

*****

####  不织布  
##### 28#       发表于 2023-3-12 13:47

 本帖最后由 不织布 于 2023-3-12 13:57 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60057607&amp;ptid=2123647" target="_blank">精金土豆泥 发表于 2023-3-12 13:38</a>

实际运用中就光是头顶和脸可能就有无数种变化，

视角的移动*距离的远近*脸的左右方向*脸的上下方向，

这 ...</blockquote>
ai的理论基础是，任何事物都可以分解成复杂多层的概念，而ai的结构层数只要够大，就可以识别出多高层的概念。

暂时看不到有任何事物和概念可以超出这个范畴

你没有见过蜘蛛笑并不阻止你想象出蜘蛛子笑。

目前ai的缺点是学概念需要大量样本，冷门概念缺乏人去练。

*****

####  绕指流光  
##### 29#       发表于 2023-3-12 14:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60054767&amp;ptid=2123647" target="_blank">哈扎马 发表于 2023-3-12 06:37</a>

踩穷举陷阱了属于是。一个事实，现存的样本中复杂动作/多人交互/大透视的绘画并不少古典油画，漫画 ...</blockquote>
想要搞出3D空间概念就需要把目前模型升维，理论层面可以突破，但是应用起来难度就十分夸张了

主流显卡现在都是勉强炼丹，3D diffusion按目前搞法应该是算不出来……

*****

####  不织布  
##### 30#       发表于 2023-3-12 14:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60058042&amp;ptid=2123647" target="_blank">绕指流光 发表于 2023-3-12 14:19</a>

想要搞出3D空间概念就需要把目前模型升维，理论层面可以突破，但是应用起来难度就十分夸张了

主流显卡现 ...</blockquote>
3d diffusion同期就出了，性能有限不实用而已

以及3d并不能解决 2d里需求的伪3d问题，不是一个赛道


*****

####  nekomimimode  
##### 31#       发表于 2023-3-12 14:53

目前的模型训练的手法, 怎么说呢, 如果按照人来打比方, 就是死记硬背

它可以通过穷举试错最后"学习"到这个词就该对应这一堆东西, 因为它读过大量的样本都说明了这个玩意就该"打印"在这

至于为什么会是这? 啊哈哈, AI酱不知道呢, 你们的样本说它就在这, 我才懒得去分析, 不然你给我做个openpose吧, 再给我做个手的深度, 这样我就能在上面描了!<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  nowords  
##### 32#       发表于 2023-3-12 15:04

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60058354&amp;ptid=2123647" target="_blank">nekomimimode 发表于 2023-3-12 14:53</a>

目前的模型训练的手法, 怎么&amp;# ...</blockquote>
可能是因为SD开源后炼丹门槛降低，一些丹师暴力迁移训练导产生像“死记硬背”的“”<strong>过拟合</strong>现象。而且C站很多二次元/cos用的迁移模型本来就是需要这样的过拟合效果来达到“哇真的像XX欸”的效果。所以在公众视野中呈现出的AI就有了这些刻板影响。

*****

####  jojog  
##### 33#       发表于 2023-3-12 15:17

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60058452&amp;ptid=2123647" target="_blank">nowords 发表于 2023-3-12 15:04</a>

可能是因为SD开源后炼丹门槛降低，一些丹师暴力迁移训练导产生像“死记硬背”的“”过拟合现象。而且C站 ...</blockquote>
我觉得这个属于道义层面的鉴抄问题了

虽然正经了解过的人都知道这个东西不是尸块，但是实际上从表现上来这个东西和尸块给人的观感是一样的

而且未经许可去学习这个确实容易产生各种非法律层面的东西

更何况LoRa这类直接摆出来名字的东西从创作者本身来看这也是很冒犯的

类似鉴抄其实也是

描图本身也不犯法，但是你这么画了在道义上确实是低人一头

其实好好交流一下就能解决的事，现实里却变成了

“道义有个屁用，反正你们都得被AI碾死”“现在碾不死你以后肯定可以，早转行跑单去”

那就成死结了

不管AI以后是不是真的可以碾死，至少有人会一直有这个刻板印象

*****

####  PacificWind  
##### 34#       发表于 2023-3-12 15:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60058354&amp;ptid=2123647" target="_blank">nekomimimode 发表于 2023-3-12 14:53</a>

目前的模型训练的手法, 怎么&amp;# ...</blockquote>
错误的捏，看看C站上一片片的特征和姿势lora就知道这是不对的，不然要怎么在数据集里没有机械人马的情况下，画出机械人马？

*****

####  nekomimimode  
##### 35#       发表于 2023-3-12 16:02

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60058747&amp;ptid=2123647" target="_blank">PacificWind 发表于 2023-3-12 15:34</a>

错误的捏，看看C站上一片片的特征和姿势lora就知道这是不对的，不然要怎么在数据集里没有机械人马的情况 ...</blockquote>
特征和姿势lora, 不也是追加的样本图训练出来的吗?<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer"> 

机械人马, 你可以训练, 也可能是通过组合prompt"调用"出来对应的分散的数据

但我的意思并不是针对结果, 而是针对"思维的过程"

这样说吧, 如果是人要从0开始画一个动态,  通常会先思考的是大的动态线和架构, 再计算透视定位, 再根据这个骨架来完成体积, 最后才是根据上述的数据决定光影的渲染

就算用3d辅助, 也是思考动态线摆好动作, 再调整镜头计算透视定位, 最后根据这些数据进行渲染

从目前看来AI进行的计算模型, 似乎没有这种从物体本身的结构演算出来的过程

如果有的话我其实觉得这才是真正的解放生产力, 但现在看起来它并不能理解这种从最原本的底层原理一步步推导的过程, 所以才会变成每一个动作都要单独训练一次。

当然， controlNET把openpose和depth结合的引入增加了可行的引导方向， 稍微完善了一下AI的生成生态，或者可以说，比起自然人强调的“先学结构再学刻画”来说， AI呈现的时间发展线似乎是先把刻画做到了几乎完善，现在才开始有各种追加的插件来“完善结构”，现在看起来以后AI的发展会走上更加规范的控制化， 也许将来有一天终究会抛弃“死记硬背”的印象吧

*****

####  不织布  
##### 36#       发表于 2023-3-12 16:06

 本帖最后由 不织布 于 2023-3-12 16:15 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60059035&amp;ptid=2123647" target="_blank">nekomimimode 发表于 2023-3-12 16:02</a>

特征和姿势lora, 不也是追加的 ...</blockquote>
然而世界的本质不是思维过程而是高维规律

思维步骤是一种性能有限导致的分步拟合

ai可以提取现象后面的规律 全部一次性拟合

现在效果差是因为提供样本展示规律的方式有问题

分步思维可以降低性能需求，在工程上非常有好处，但不是理论上必要的

也就是说最悲观的来看，就算我们造不出思维，也一定可以堆出真理

*****

####  PacificWind  
##### 37#       发表于 2023-3-12 16:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60059035&amp;ptid=2123647" target="_blank">nekomimimode 发表于 2023-3-12 16:02</a>

特征和姿势lora, 不也是追加的&amp;#x6 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/064.png" referrerpolicy="no-referrer">我觉得你没听明白，如果SD算法只是你说的打印像素，那AI不应该懂得数据集之外的东西。

还是人马的例子，数据集里只有兽状带毛的人马，但是AI能凭借人马这个概念，去画出机械人马，原因在于AI确实理解了人马的概念，从数据集打的tag中学习到了人马的腿和人体是怎么布置的，最后抽象成一个“人马”的概念，然后依照原模型中机械腿的画法开始画。

你觉得像打印，是因为记忆的精度和泛化性还不够，没办法做到像人一样学习复刻，要么记过头了（过拟合），要么记不住（没学会），但是逻辑是一样的，都是在概念之上学习概念。

*****

####  处男鉴黄师  
##### 38#       发表于 2023-3-12 16:39

说到3D形体，人脑里面同样没有计算3维模型顶点坐标表面贴图的功能，但并不妨碍人类理解3维空间结构，依靠的就是从小就获得的视觉体验，也就是外界喂给人脑的数据。而且人类有两只眼睛可以看到立体的图像，空间理解更高效。AI目前好像还没有类似的训练。

*****

####  yang1820  
##### 39#       发表于 2023-3-12 17:00

 本帖最后由 yang1820 于 2023-3-12 01:14 编辑 
<blockquote>不织布 发表于 2023-3-12 00:06
然而世界的本质不是思维过程而是高维规律

思维步骤是一种性能有限导致的分步拟合

ai可以提取现象后面的规 ...</blockquote>
"现在效果差是因为提供样本展示规律的方式有问题"

所以，你认为怎样才是展示样本规律的合理方式？

*****

####  nekomimimode  
##### 40#       发表于 2023-3-12 17:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60059277&amp;ptid=2123647" target="_blank">PacificWind 发表于 2023-3-12 16:28</a>

我觉得你没听明白，如果SD算法只是你说的打印像素，那AI不应该懂得数据集之外的东西。

还是人马的 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">我觉得你也没听明白我想具体表达的东西

不过大概是我比喻用得不对， 我想说的是，到底是哪种思维方式更适合AI的发展路线？

就拿人马来说吧，如果是以人的思考，理解了人马的骨架， 那我就能让它随意摆动作了，哪怕我只是用个方块作为透视引导，也能根据大体的形状画出任意情况下的动作

而AI目前的理解的“思维”，你需要对每一个动作进行训练，假设理论上有无限时间无限样本可以用穷举法做到一个完美无缺的超级人马动态库，但是哪怕训练完，可能它的数据里面也不需要“骨架”这个概念

假如现在有一种模型算法，给AI喂了骨架和肌肉的知识和少量的图片范例，它就能自动运用到后续的生成上，那我觉得这真是会超越人类的东西....

*****

####  大江户战士  
##### 41#       发表于 2023-3-12 17:28

楼主这种没研究透就下定论，充分说明了一般路人对AI绘画的误解

所谓AI画不出高透视的图，请问这是不是AI画的

<img src="https://img.saraba1st.com/forum/202303/12/172050fl7ga74llee4oaan.png" referrerpolicy="no-referrer">

<strong>06414-2419565812-masterpiece, best quality, 1girl, solo, , white background, full body.png</strong> (338.75 KB, 下载次数: 0)

下载附件

2023-3-12 17:20 上传

<img src="https://img.saraba1st.com/forum/202303/12/172104pypwtut16bd3s1ly.png" referrerpolicy="no-referrer">

<strong>20221021192997-3090038309-masterpiece, best quality, 1man, solo, jacket, hand in.png</strong> (351.89 KB, 下载次数: 0)

下载附件

2023-3-12 17:21 上传

这是拿你第一张图里的动作跑出来的图

<img src="https://img.saraba1st.com/forum/202303/12/172736btmmmezrqwylb1m8.png" referrerpolicy="no-referrer">

<strong>image.png</strong> (296.98 KB, 下载次数: 0)

下载附件

2023-3-12 17:27 上传

我建议你先学一下tag怎么用：[https://danbooru.donmai.us/wiki_ ... 3Aimage_composition](https://danbooru.donmai.us/wiki_pages/tag_group%3Aimage_composition)

复杂姿势，楼主是不知道ControlNet有openpose吗

<img src="https://img.saraba1st.com/forum/202303/12/172410hhzreygfficushjc.png" referrerpolicy="no-referrer">

<strong>image.png</strong> (906.49 KB, 下载次数: 0)

下载附件

2023-3-12 17:24 上传

<img src="https://img.saraba1st.com/forum/202303/12/172801t1ftd7zh1rssb7hr.png" referrerpolicy="no-referrer">

<strong>image.png</strong> (547.28 KB, 下载次数: 0)

下载附件

2023-3-12 17:28 上传

*****

####  jojog  
##### 42#       发表于 2023-3-12 17:41

 本帖最后由 jojog 于 2023-3-12 17:46 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60059837&amp;ptid=2123647" target="_blank">大江户战士 发表于 2023-3-12 17:28</a>

楼主这种没研究透就下定论 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/038.png" referrerpolicy="no-referrer">无恶意非抬杠也不是吹毛求疵哈 就**发的几张我觉得可能正好验证了1楼的说法

第一张坐着的那个透视本身是怪的（比如坐着的板子和人实际上对不上 还有墙的问题）

第二张那个路左右有个很吊跪的高低差

第三张那个动作明显就是AI把腿的动作改了，整体显得很平面了

openpose这些楼主肯定是知道的，最下面左边那个jackochallenge肩的结构就全崩了。右边那个脚……emmm

（倒是美漫风那个下行左二看着很有那么个意思）

可能咱看着没啥违和感但是实际上画画的人会没法接受这个精度

我想应该是这个意思

*****

####  大江户战士  
##### 43#       发表于 2023-3-12 17:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60059958&amp;ptid=2123647" target="_blank">jojog 发表于 2023-3-12 17:41</a>

无恶意非抬杠也不是吹毛求疵哈 就**发的几张我觉得可能正好验证了1楼的说法

第一张坐着的那个透 ...</blockquote><blockquote>其他画精密饰物变成一团糊之类的就先算了

手的话最近也有不少办法能画得还行

剩下最主要的应该是：透视，复杂动作</blockquote>
显然你说的这些不在楼主讨论范围内，楼主说的是不论细节，AI画不出透视和复杂动作，显然这是错的

*****

####  jojog  
##### 44#       发表于 2023-3-12 17:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60059982&amp;ptid=2123647" target="_blank">大江户战士 发表于 2023-3-12 17:45</a>

显然你说的这些不在楼主讨论范围内，楼主说的是不论细节，AI画不出透视和复杂动作，显然这是错的 ...</blockquote>
没 这个我理解的

我猜的是“能不能画出大透视和复杂动作”的标准楼主和菊苣您不大一样

就好像比如让我一个不会画画没有美术技术基础的人来画一个大透视的东西我肯定画不出来，照着画（非描图）也会有各种错误

AI的话降噪之后排出来的东西可能在专业的人眼里不算“能画出来了”

所以才说是“可能咱看着没啥违和感但是实际上画画的人会没法接受这个精度”

纯猜测，可能这方面是美术和程序的思维方式不大一样

美术做到专业了强调的更多是精度，而程序更多的是实现

这一部分的认知是存在误差的（人的问题）

*****

####  futamn  
##### 45#       发表于 2023-3-12 17:51

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">感觉ai像拟态史莱姆

*****

####  lovepefe  
##### 46#       发表于 2023-3-12 17:54

想想天天念经的手才几天，连我这个没有刷图习惯的人都从s1见证了这个短暂的过程。

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  nekomimimode  
##### 47#       发表于 2023-3-12 17:58

 本帖最后由 nekomimimode 于 2023-3-12 18:01 编辑 

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">在美术要求的验收里面，画出来错误的就等同于“画不出来”啊

外加人家真的是在说“大的透视”

<img src="https://img.saraba1st.com/forum/202303/12/175723ztmtdm9e9aatkszo.png" referrerpolicy="no-referrer">

<strong>QQ图片20230312175711.png</strong> (5.71 KB, 下载次数: 0)

下载附件

2023-3-12 17:57 上传

这个透视幅度比起来还是差得挺大的，在一般的标准来说这个跑出来的也属于“人体透视的程度很小”的感觉了

<img src="https://img.saraba1st.com/forum/202303/12/175804o899s992x9oaxnm0.jpg" referrerpolicy="no-referrer">

<strong>230312-175211.jpg</strong> (37.62 KB, 下载次数: 0)

下载附件

2023-3-12 17:58 上传

那个美漫风的倒是其中几张挺有大透视感觉的，但可能是有样本对上号，就像一些特化版lora动作一样

*****

####  大江户战士  
##### 48#       发表于 2023-3-12 18:02

 本帖最后由 大江户战士 于 2023-3-12 18:09 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060027&amp;ptid=2123647" target="_blank">jojog 发表于 2023-3-12 17:51</a>

没 这个我理解的

我猜的是“能不能画出大透视和复杂动作”的标准楼主和菊苣您不大一样</blockquote>
所以我说很多人对AI有误解，而且造成了一个极为矛盾的观点：一方面觉得AI会抢画师饭碗，另一方面又说AI不行。实际上现阶段的AIGC是“在会用的人手里足够好，在不会用的人手里不够好”，所以最终的效果是原来要10个人来做的事，现在2个人来做就行了，而不是不需要人去做。

另外就是很多人觉得AI应该像人类一样从构图、草稿方面开始学习，这其实是几十年前就被证明不可行的路线，也就是所谓的“专家系统”。深度学习本质上是把所有东西当成函数去拟合（这一点在理论上已经被证明了，详见万能近似定理），而不是人类意义上的“理解”

*****

####  jojog  
##### 49#       发表于 2023-3-12 18:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060151&amp;ptid=2123647" target="_blank">大江户战士 发表于 2023-3-12 18:02</a>

所以我说很多人对AI有误解， ...</blockquote>
&gt;一个极为矛盾的观点：一方面觉得AI会抢画师饭碗，另一方面又说AI不行

这个应该倒不矛盾，

1 AI抢画师饭碗的原因是，大部分画师的饭碗还是来自一般人的，一般人没那么高的对精度的需求

2 AI不行是因为从美术角度来说AI确实不是在“画”图，毕竟这个爷不是米开朗基罗的从石头里解放出人体

归根到底还是需求和供给的矛盾

供给方的价值评价和需求方的价值需的认识偏差被AI展现出来了就是

&gt;我只能说这是几十年前就被证明不可行的路线，也就是所谓的“专家系统”

这个应该好像还在搞？我看最近还有paper来着，当然实际效果咋样没关注过也就不知道就是了……
[https://aaai.org/papers/02564-ai ... h-quality-sketches/](https://aaai.org/papers/02564-ai-sketcher-a-deep-generative-model-for-producing-high-quality-sketches/)

（内容没看 说错了莫怪）

深度学习这个对于人来说实际上并不是“画”，自然也就“没有灵魂”了

说到底还是人与人之间的问题，而非技术……

*****

####  精金土豆泥  
##### 50#         楼主| 发表于 2023-3-12 18:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60059837&amp;ptid=2123647" target="_blank">大江户战士 发表于 2023-3-12 17:28</a>

楼主这种没研究透就下定论&amp;#xF ...</blockquote>
呃呃……我们一个个来说吧，别那么着急

首先透视呢，我不是说真透视，我是说大角度透视
<img src="https://p.sda1.dev/10/b99074a9625c5096fe960b729c8984d9/777.png" referrerpolicy="no-referrer">

《类似这种的，FOV 100以上的时候的视角。插图比较少见一些，但是大场景风景或者动作场面里就有不少

主要是表现一种画面张力
<img src="https://p.sda1.dev/10/d87cec37410a162880fe4190f2e25d4c/222.png" referrerpolicy="no-referrer">
<img src="https://p.sda1.dev/10/763c4a5283a2d0d431ada3d36795a558/111.png" referrerpolicy="no-referrer">

而这个跑出来的图通过叠图看一下的话，还是变得“插画化”和“平面化”了不少，

高FOV的那种张力感消失了

打个比方的话，原图草稿可以在kill la kill里用，表现力很强，

AI跑过之后的这个图只能在轻小说里用

想要比较好的出这个姿势目前我试的一种可行方式是3D建模之后，

打光截图并用normal和depth锁整体姿势，中途再中断让它自行推导后面的

但一个是每个图都弄模型十分繁琐，第二个是中断后随机性大增，

还是比较难推导出满意的结果的。

只用canny或者openpose的话AI会自行扭动扭动的把FOV角度减下去，

或者变成其他有点相似的动作。

就这点来说，我觉得目前的AI对高FOV的透视支持还是比较差的。

可以画，但是要每张图弄个合适的3D模型，过于累人

然后是复杂动作，

我也说了是“一些身体&amp;手掌小臂翻转大的武术动作，

或者上半身扭动超过90度的性感动作or一只手背在背后之类的动作”

而不是那种相对简单的模特姿势

拿来做范例的也是武术动作，我当然也做过类似试验
<img src="https://p.sda1.dev/10/c6e72496a6c6b5f604f57c8f55db38c3/333.png" referrerpolicy="no-referrer">
<img src="https://p.sda1.dev/10/b3ccb414ad734711b3a76cd13db3ef52/444.png" referrerpolicy="no-referrer">

这是我捏的动作和AI计算出来误差颇大的结果

可以一定程度上证明我的论点吧

当然，这个武术动作应该也还是可以3D建模然后normal/depth多管齐下硬卡出我需要的姿势

但过于繁琐，而且AI在不太理解这个姿势，也没有充分相关上色结果的支持下，

应该比较难给最后的图上个合理的颜色

嗯，当然也有可能是我openpose用得不好或者还不够熟悉哪项功能，

也欢迎讨论和各种研究

如果有人能证明我确实错了，那我也很高兴

*****

####  大江户战士  
##### 51#       发表于 2023-3-12 18:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060225&amp;ptid=2123647" target="_blank">jojog 发表于 2023-3-12 18:11</a>

&gt;一个极为矛盾的观点：一方面觉得AI会抢画师饭碗，另一方面又说AI不行

这个应该倒不矛盾，</blockquote>
你这链接里的是VAE啊，还是深度网络，不是专家系统

*****

####  大江户战士  
##### 52#       发表于 2023-3-12 18:19

 本帖最后由 大江户战士 于 2023-3-12 18:23 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060259&amp;ptid=2123647" target="_blank">精金土豆泥 发表于 2023-3-12 18:15</a>

呃呃……我们一个个来说吧，别那么着急

首先透视呢，我不是说真透视，我是说大角度透视</blockquote>
你是自己摆的吗？自己摆的要注意被遮挡的躯干应该删掉骨骼

*****

####  yang1820  
##### 53#       发表于 2023-3-12 18:22

<blockquote>nekomimimode 发表于 2023-3-12 01:58
在美术要求的验收里面，&amp;#x75 ...</blockquote>
emmm……其实如果按照楼主的例图的话，大透视不仅是指高角度机位俯视和低角度机位仰视，更重要的是镜头景深。从这个角度上来说的，美漫那张也是不符合的XD

不过15楼的效果已经挺不错了，说明AI还是有可能画出这种非常见机位景深的图，就是要多花点功夫做尝试，多试试不同的模型。(有一说一，这个不同的内容要尝试不同的模型和lora才能大概率画出来，还是挺蛋疼的。)

*****

####  jojog  
##### 54#       发表于 2023-3-12 18:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060294&amp;ptid=2123647" target="_blank">大江户战士 发表于 2023-3-12 18:18</a>

你这链接里的是VAE啊，还是&amp;#x6DF1 ...</blockquote>
啊 是我弄错了 

和这个搅混了 不好意思
[https://www.gsd.harvard.edu/proj ... cial-intelligences/](https://www.gsd.harvard.edu/project/suggestive-drawing-along-human-and-artificial-intelligences/)

*****

####  大江户战士  
##### 55#       发表于 2023-3-12 18:25

 本帖最后由 大江户战士 于 2023-3-12 18:33 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060259&amp;ptid=2123647" target="_blank">精金土豆泥 发表于 2023-3-12 18:15</a>

呃呃……我们一个个来说吧，别那么着急

首先透视呢，我不是说真透视，我是说大角度透视</blockquote>
另外我不知道你说的100fov具体是什么概念，但是用perspective, foreshortening, vanishing point之类的tag还是很容易出大角度透视图的，就是不知道符不符合你的“大角度透视”的定义

<img src="https://img.saraba1st.com/forum/202303/12/182546uori23oz2zfjr4bb.jpg" referrerpolicy="no-referrer">

<strong>20221021193022-1978039313-masterpiece, best quality, 1girl, solo, white hair, lo.jpg</strong> (210.58 KB, 下载次数: 0)

下载附件

2023-3-12 18:25 上传

<img src="https://img.saraba1st.com/forum/202303/12/183229mbdcplgmbooybqdm.png" referrerpolicy="no-referrer">

<strong>20221021193023-3024842818-masterpiece, best quality, 1girl, solo, white hair, lo.png</strong> (189.17 KB, 下载次数: 0)

下载附件

2023-3-12 18:32 上传

*****

####  大江户战士  
##### 56#       发表于 2023-3-12 18:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060334&amp;ptid=2123647" target="_blank">jojog 发表于 2023-3-12 18:22</a>

啊 是我弄错了 

和这个搅混了 不好意思</blockquote>
这不还是pix2pix（GAN）嘛

*****

####  jojog  
##### 57#       发表于 2023-3-12 18:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060368&amp;ptid=2123647" target="_blank">大江户战士 发表于 2023-3-12 18:27</a>

这不还是pix2pix（GAN）嘛</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/024.png" referrerpolicy="no-referrer">嗯 如果这个不算的话可能就真和您说的一样让AI真正一笔笔画上去是不可行的了

毕竟我不是专业的这方面涉猎的不是很够

*****

####  大江户战士  
##### 58#       发表于 2023-3-12 18:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060388&amp;ptid=2123647" target="_blank">jojog 发表于 2023-3-12 18:29</a>

嗯 如果这个不算的话可能就真和您说的一样让AI真正一笔笔画上去是不可行的了

毕竟我不是专业的这 ...</blockquote>
现阶段生成AI全部都是基于深度神经网络的，没有专家系统

*****

####  精金土豆泥  
##### 59#         楼主| 发表于 2023-3-12 18:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060299&amp;ptid=2123647" target="_blank">大江户战士 发表于 2023-3-12 18:19</a>

你是自己摆的吗？自己摆的&amp;#x ...</blockquote>
网页的那个open-pose-editor能删骨骼但关节点没法随意拖动延长，摆起动作来非常费劲

网页插件版的那个无法删除骨骼

导出的png图片用PS改色强删骨骼后效果依然很不好，AI还是认不出
<img src="https://p.sda1.dev/10/a5da30b17a33ce638b7de93bf2b7db5a/999.jpg" referrerpolicy="no-referrer">
<img src="https://p.sda1.dev/10/2892ab8d1a9c60ca735327ba8fa72478/1122.png" referrerpolicy="no-referrer">

*****

####  精金土豆泥  
##### 60#         楼主| 发表于 2023-3-12 18:36

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060357&amp;ptid=2123647" target="_blank">大江户战士 发表于 2023-3-12 18:25</a>

另外我不知道你说的100fov具体是什么概念，但是用perspective, foreshortening, vanishing point之类的tag ...</blockquote>
哦哦，这个好像不错，之后我去试试，感谢告知


*****

####  大江户战士  
##### 61#       发表于 2023-3-12 18:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060465&amp;ptid=2123647" target="_blank">精金土豆泥 发表于 2023-3-12 18:35</a>

网页的那个open-pose-editor能删骨骼但关节点没法随意拖动延长，摆起动作来非常费劲

网页插件版的那个无 ...</blockquote>
一个ControlNet不够用可以用多个啊

<img src="https://img.saraba1st.com/forum/202303/12/185224t1icjn7a8s808tee.jpg" referrerpolicy="no-referrer">

<strong>00751-1291129753-masterpiece, best quality, 1girl, solo, white hair, long hair, .jpg</strong> (205.13 KB, 下载次数: 0)

下载附件

2023-3-12 18:52 上传

*****

####  yswm  
##### 62#       发表于 2023-3-12 18:55

你说的这些应该是喂给ai的资料里比较少，它不知道

未必不是一两年后就能解决的

*****

####  jojog  
##### 63#       发表于 2023-3-12 18:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060630&amp;ptid=2123647" target="_blank">大江户战士 发表于 2023-3-12 18:52</a>

一个ControlNet不够用可以用多个啊</blockquote>
这个是depth和canny都用了吗？


*****

####  Liberation  
##### 64#       发表于 2023-3-12 19:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060060&amp;ptid=2123647" target="_blank">lovepefe 发表于 2023-3-12 17:54</a>

想想天天念经的手才几天，连我这个没有刷图习惯的人都从s1见证了这个短暂的过程。

论坛助手,iPhone ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">没事，AI图里手现在也各种崩，只是花精力去调能调好

*****

####  精金土豆泥  
##### 65#         楼主| 发表于 2023-3-12 19:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060630&amp;ptid=2123647" target="_blank">大江户战士 发表于 2023-3-12 18:52</a>

一个ControlNet不够用可以用多个啊</blockquote>
这个确实厉害了，怎么做到的

我也有用多个ControlNet但是弄不出这种效果


*****

####  处男鉴黄师  
##### 66#       发表于 2023-3-12 19:17

试了下即使不用controlnet可以出这种所谓的大透视效果，多roll一下

<img src="https://img.saraba1st.com/forum/202303/12/191520oegmiewcmyy8x8wa.jpg" referrerpolicy="no-referrer">

<strong>07316-3103523441-20.jpg</strong> (78.62 KB, 下载次数: 0)

下载附件

2023-3-12 19:15 上传

<img src="https://img.saraba1st.com/forum/202303/12/191520s8u9u6qqta8uxm1q.jpg" referrerpolicy="no-referrer">

<strong>07318-3103523443-20.jpg</strong> (77.57 KB, 下载次数: 0)

下载附件

2023-3-12 19:15 上传

*****

####  处男鉴黄师  
##### 67#       发表于 2023-3-12 19:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060035&amp;ptid=2123647" target="_blank">futamn 发表于 2023-3-12 17:51</a>

感觉ai像拟态史莱姆</blockquote>
拟态史莱姆牛逼了可以比本体更厉害，艾尔登之王的大哥知道吗<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  Bernoulli  
##### 68#       发表于 2023-3-12 19:20

controlnet好像不能用高清修复

*****

####  精金土豆泥  
##### 69#         楼主| 发表于 2023-3-12 19:21

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060911&amp;ptid=2123647" target="_blank">处男鉴黄师 发表于 2023-3-12 19:17</a>

试了下即使不用controlnet可以出这种所谓的大透视效果，多roll一下</blockquote>
55楼给的关键词确实有用，对很多常见大透视动作的识别率提升了很多


*****

####  Nea  
##### 70#       发表于 2023-3-12 19:26

 本帖最后由 Nea 于 2023-3-12 19:27 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60060863&amp;ptid=2123647" target="_blank">精金土豆泥 发表于 2023-3-12 19:12</a>

这个确实厉害了，怎么做到的

我也有用多个ControlNet但是弄不出这种效果

*尝试了一下,perspective, foresh ...</blockquote>
这种姿势最好用blender搞，用web插件很容易错透视。openpose+depth+canny+prompt提示可以完成一些常见的带透视的姿势图。
[toyxyz的blender用openpose模型](https://toyxyz.gumroad.com/l/ciojz)


*****

####  105gun  
##### 71#       发表于 2023-3-12 20:05

<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">这种姿势也不是不能跑吧。我是手动画了一个scribble输入+seg+openpose。角色的手我没好好弄，scribble部分画的比较糊。额外加一个手部的depth应该不至于这么差。

这俩是不同denoise的img2img：

<img src="https://img.saraba1st.com/forum/202303/12/194323msjrsk5222oabkbx.png" referrerpolicy="no-referrer">

<strong>01203-922319898-masterpiece,1girl,brown shoes, red chinese clothes.png</strong> (81.15 KB, 下载次数: 0)

下载附件

2023-3-12 19:43 上传

<img src="https://img.saraba1st.com/forum/202303/12/195140vaa79mnwmsdvar5d.png" referrerpolicy="no-referrer">

<strong>01208-2512311555-masterpiece,1girl,brown shoes, red short sleeves, red chinese clothes.png</strong> (69.58 KB, 下载次数: 0)

下载附件

2023-3-12 19:51 上传

text2img：

<img src="https://img.saraba1st.com/forum/202303/12/200502pppleltc26s6mpt3.png" referrerpolicy="no-referrer">

<strong>03175-4181586165-masterpiece,1girl,full body.png</strong> (99.53 KB, 下载次数: 0)

下载附件

2023-3-12 20:05 上传

<img src="https://img.saraba1st.com/forum/202303/12/200507vndqssykvz2ykk2s.png" referrerpolicy="no-referrer">

<strong>03177-4181586165-masterpiece,1girl,full body.png</strong> (85.69 KB, 下载次数: 0)

下载附件

2023-3-12 20:05 上传

也没roll几张，我的电脑跑起来还是蛮慢的。

*****

####  精金土豆泥  
##### 72#         楼主| 发表于 2023-3-12 20:08

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60061439&amp;ptid=2123647" target="_blank">105gun 发表于 2023-3-12 20:05</a>

这种姿势也不是不能跑吧。我是手动画了一个scribble输入+seg+openpose。角色的手我没好好弄，scribb ...</blockquote>
嗯，我也差不多跑通了，

复用多个不同类型的controlnet就行，

一会儿我去更新一下主楼

*****

####  wolfwood  
##### 73#       发表于 2023-3-12 20:09

怎么说了，还是需要真正的技术突破，现在大家玩AI就像三体人类，基础技术没有质变的情况下，在应用技术上疯狂钻研<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">


*****

####  wszweill  
##### 74#       发表于 2023-3-12 23:32

 本帖最后由 wszweill 于 2023-3-12 10:34 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60057607&amp;ptid=2123647" target="_blank">精金土豆泥 发表于 2023-3-12 00:38</a>

实际运用中就光是头顶和脸可能就有无数种变化，

视角的移动*距离的远近*脸的左右方向*脸的上下方向，

这 ...</blockquote>
虽然你说的很严肃，但是B漫一堆工作室的轻改哪有那么高要求<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

你说的这些问题对画师来说就更不是啥问题了，底稿--上色--修正。比正常工序或者单纯抽卡效率高多了。

另外lora的原理不少你想象的那样图拼图，现在就有成熟Lora，帮你生成角色的正面侧面和背面，个人测试成功率50%左右。比如原作者放的这个：
<img src="https://img.feixue.cloud/2023/03/12/f9ac8e5f79efb.jpg" referrerpolicy="no-referrer">

还有一个其他用户上传的
<img src="https://img.feixue.cloud/2023/03/12/df2c97008d339.jpg" referrerpolicy="no-referrer">

 并不需要侧面和背面各有几百张图来适应不同头型

我觉得透视最大的问题就是二次元普遍透视稀烂<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">至于成功率那到无所谓，一张图才几秒钟，连带参数调整一个小时roll几十上百张，怎么说都出货了，你那么高要求的作画，难道1个小时一张嘛（


*****

####  龙骑士尹志平  
##### 75#       发表于 2023-3-13 00:03

可以可以


*****

####  alitonz  
##### 76#       发表于 2023-3-13 01:06

这个帖子的发展让我想到“想要了解某某某相关知识，直接批评比问有效”的那种，虽然动机应该不是如此。

