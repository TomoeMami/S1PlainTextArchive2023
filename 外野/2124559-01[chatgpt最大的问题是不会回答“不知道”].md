
*****

####  氪金萌新  
##### 1#       楼主       发表于 2023-3-17 20:22

甚至没有“知道”和“不知道”的概念。

对于不知道的东西就开始胡诌。

<img src="https://img.saraba1st.com/forum/202303/17/202201ndgtnakdzkrml28b.png" referrerpolicy="no-referrer">

<strong>chagptMuniuzhang.png</strong> (69.49 KB, 下载次数: 0)

下载附件

2023-3-17 20:22 上传

*****

####  MaskedBlade  
##### 2#       发表于 2023-3-17 20:27

云玩家是这样的

*****

####  鸺鹠  
##### 3#       发表于 2023-3-17 20:30

<img src="https://static.saraba1st.com/image/smiley/face2017/017.png" referrerpolicy="no-referrer">建议开发人员增加"不知道"的概念，并为其提供相应的回答。这样可以提高chatgpt的可靠性和可信度。

﹍﹍﹍

评分

 参与人数 2战斗力 +3

|昵称|战斗力|理由|
|----|---|---|
| lanslort| + 1|欢乐多|
| The_Ether_| + 2||

查看全部评分

*****

####  KATE  
##### 4#       发表于 2023-3-17 20:31

百度那个应该会吧<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">毕竟是优质回答

*****

####  玄影青鳞  
##### 5#       发表于 2023-3-17 20:32

他也不知道自己知不知道

—— 来自 HONOR PGT-AN10, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2

*****

####  小野賢章  
##### 6#       发表于 2023-3-17 20:32

new bing 是会回答不知道的

*****

####  氪金萌新  
##### 7#         楼主| 发表于 2023-3-17 20:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60125675&amp;ptid=2124559" target="_blank">KATE 发表于 2023-3-17 20:31</a>

百度那个应该会吧毕竟是优质回答</blockquote>
百度甚至搜索“牧牛杖” 三个字就能出正确答案了

*****

####  gearh  
##### 8#       发表于 2023-3-17 20:36

 本帖最后由 gearh 于 2023-3-17 20:38 编辑 

第二大问题是记忆力太差只能做到“提问”

如果想“讨论、扮演”就要提心吊胆是不是ChatGPT已经忘了讨论情景

*****

####  502307501  
##### 9#       发表于 2023-3-17 20:42

再加一个“沉默”，我有时候还挺希望他别说话，听我自己一个人自言自语

*****

####  与天争锋_LZ  
##### 10#       发表于 2023-3-17 20:48

你想让他说：对不起，做不到吗

*****

####  烦死了  
##### 11#       发表于 2023-3-17 20:54

白皮模拟器，她们不知道的问题就喜欢瞎诌<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  zxlice  
##### 12#       发表于 2023-3-17 20:57

他不知道自己不知道<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">

*****

####  sk86  
##### 13#       发表于 2023-3-17 20:59

作为一个人工智能语言模型，我可能会遇到某些知识盲区或者信息缺失的情况，因为我的回答主要依赖于我在训练时接受的数据和算法。此外，随着时间的推移，某些信息可能会发生变化或者不再准确，因此我的回答也可能会存在过时或者错误的情况。如果您发现我的回答有误或者需要更准确的信息，请随时指出，我会尽力提供准确的回答。

*****

####  bobosnader  
##### 14#       发表于 2023-3-17 20:59

回答不知道就没有分数--随便回答至少有卷面分--

*****

####  lvseqiji  
##### 15#       发表于 2023-3-17 21:03

一个概率模型当然是不知道自己不知道的

—— 来自 Sony XQ-BQ72, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  pzk  
##### 16#       发表于 2023-3-17 21:03

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60125795&amp;ptid=2124559" target="_blank">502307501 发表于 2023-3-17 20:42</a>

再加一个“沉默”，我有时候还挺希望他别说话，听我自己一个人自言自语</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/094.png" referrerpolicy="no-referrer">这种需求用记事本就能解决吧

*****

####  blackeyed  
##### 17#       发表于 2023-3-17 21:05

new bing也一样会瞎扯拉

毕竟本体是语言模型, 重点是说通, 而不是说对, 只是训练的内容里基本都是对的, 所以比较大概率会出现说通=说对

*****

####  奥古斯都  
##### 18#       发表于 2023-3-17 21:06

用了这么久,gpt突出一个嘴硬,new bing好多了

*****

####  完先生  
##### 19#       发表于 2023-3-17 21:10

只要能被搜索引擎搜出来，那就不存在不知道，顶多说错了

xx一下，你就知道！

*****

####  oznark  
##### 20#       发表于 2023-3-17 21:12

绝大多数网民：非常自信地给出正确或者错误的答案，但是他自认为自己绝对不会出错，你要是非要挑他的错，他也不尝试纠正你，一般会选择直接cnm。

根据网民训练出来的语言模型：非常自信地给出正确或者错误的答案，但是会时刻提醒你他自己只是语言模型，最后拿主意的得是屏幕外的大个儿活人。

﹍﹍﹍

评分

 参与人数 2战斗力 +2

|昵称|战斗力|理由|
|----|---|---|
| L920820720| + 1|好评加鹅|
| lanslort| + 1|欢乐多|

查看全部评分

*****

####  502307501  
##### 21#       发表于 2023-3-17 21:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60126030&amp;ptid=2124559" target="_blank">pzk 发表于 2023-3-17 21:03</a>
这种需求用记事本就能解决吧</blockquote>
是那种面对面聊天的时候对方偶然会沉默的感觉<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">我已经是堕落到需要靠程序来心理辅导的废人了

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  topia  
##### 22#       发表于 2023-3-17 21:19

ai要怎么判断知道还是不知道<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

语言模型总不可能逃脱人类知识的边界吧

*****

####  yone0000  
##### 23#       发表于 2023-3-17 21:20

是这样的，说道不知道的东西他就开始胡说八道了，而且说的还振振有词，容易被误导<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

*****

####  saisi  
##### 24#       发表于 2023-3-17 21:21

回答的官味十足 没意思

*****

####  斡旋家  
##### 25#       发表于 2023-3-17 21:24

这已经很好了，都有马前卒水平了

*****

####  阿福牛肉  
##### 26#       发表于 2023-3-17 21:26

NEW Bing接入的就是CHATGPT4.0啊，，这两个是一样的，最多是使用本地数据集训练的方法不一样，

*****

####  玩玩而已别当真  
##### 27#       发表于 2023-3-17 21:29

<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">不懂，但如果一个ai可以分析出自己是知道还是不知道，是不是就是所谓的强ai了，因为再进一步选择是否如实回答不就是代表ai会撒谎了吗，感觉更恐怖了

*****

####  我是大鲨鱼  
##### 28#       发表于 2023-3-17 21:34

这TM不就是我泥潭网友吗<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  chaucerling  
##### 29#       发表于 2023-3-17 21:41

lz是不是没清除上下文导致引导它编造，我试了两次清除上下文问它，他都回答 <blockquote>很抱歉，我是一名语言模型，没有能力提供关于游戏暗黑3的具体游戏指导，也无法提供游戏作弊或违规的建议。建议您请教游戏官方论坛或寻找相关的游戏攻略和指南。</blockquote>
然后我再试了先问它暗黑3是什么，然后问暗黑3怎么做牧牛杖，他就编了一个答案 <blockquote>在暗黑3中，牧牛杖是一种特殊的装备，它的主要作用是吸引敌人的攻击，从而保护玩家免受伤害。以下是制作牧牛杖的方法：

首先，你需要一个法师角色，因为制作牧牛杖需要使用到法师的技能。

然后，你需要前往“黑暗之魂”地下城，这个地下城位于魔法师的新特莱斯顿的南方。在地下城中，你需要找到一个名为“乌利雅”的NPC，与她对话并购买“乌利雅的魔杖”（Uliana's Stratagem）。

接下来，你需要前往铁匠处，将“乌利雅的魔杖”和一些其他材料合成成为牧牛杖。具体的合成配方如下：

乌利雅的魔杖

一把“神秘的杖”（Mystic Staff）

一个“沃瑞尔水晶”（Wirt's Bell）

将这些材料放在铁匠的合成面板上，即可制作出一把牧牛杖。

需要注意的是，制作牧牛杖需要到达暗黑3的第四幕，因此需要完成前三幕的任务才能进入到达“黑暗之魂”地下城。</blockquote>

*****

####  天网  
##### 30#       发表于 2023-3-17 21:41

 本帖最后由 天网 于 2023-3-17 21:48 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60126314&amp;ptid=2124559" target="_blank">玩玩而已别当真 发表于 2023-3-17 21:29</a>

不懂，但如果一个ai可以分析出自己是知道还是不知道，是不是就是所谓的强ai了，因为再进一步选择是 ...</blockquote>
现阶段里，表现出“不知道”才是弱智的程序，比如计算器输入逻辑错误的算式会统一显示NaN（非数），搜索引擎搜索了错误的词会提示你改正，不听它的甚至用引号强制精准匹配甚至出现0结果，这是典型的“不知道”。

包括大量软件里的报错信息，这些都是因为超出使用范围了，对超脱出使用范围还能编出来非报错的结果，说明有迁移能力、想象能力，让它来一段关公战秦琼，写诗编段子，不就是利用了这种能力么。不管对不对，光论技术水平比上面的强<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  盗圣白静婷  
##### 31#       发表于 2023-3-17 21:42

<img src="https://img.saraba1st.com/forum/202303/17/214125w6yfqu3qffs3svu5.png" referrerpolicy="no-referrer">

<strong>QQ图片20230317214102.png</strong> (85.21 KB, 下载次数: 0)

下载附件

2023-3-17 21:41 上传

是这样的，还热衷于发明历史，也不知道怎么搜集的信息

*****

####  氪金萌新  
##### 32#         楼主| 发表于 2023-3-17 21:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60126480&amp;ptid=2124559" target="_blank">盗圣白静婷 发表于 2023-3-17 21:42</a>

是这样的，还热衷于发明历史，也不知道怎么搜集的信息</blockquote>
你这问法有点钓鱼执法了。我主贴就是一个平平无奇百度一下就知道的问题，都能答错。。。

*****

####  thisism  
##### 33#       发表于 2023-3-17 21:48

<img src="https://static.saraba1st.com/image/smiley/face2017/020.png" referrerpolicy="no-referrer">

这有啥钓鱼执法的

这不就是吹生产力的生成总结性文章吗

*****

####  玩玩而已别当真  
##### 34#       发表于 2023-3-17 21:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60126467&amp;ptid=2124559" target="_blank">天网 发表于 2023-3-17 21:41</a>

现阶段里，表现出“不知道”才是弱智的程序，比如计算器输入逻辑错误的算式会统一显示NaN（非数），搜索引 ...</blockquote>
这样啊，我还以为主楼标题里的不知道是那种经过分析确定的不知道，原来是一种输入/输出错误的另类表述啊

*****

####  suhanblood  
##### 35#       发表于 2023-3-17 21:50

new bing还是会不知道的，我让她找一个我小时候看过的儿童节目，女主持在两队游戏结束后会擦口红抱住赢家小朋友在脸上亲一口印唇印，bing努力了半天还是找不到<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">我甚至怀疑是不是这节目太超过了，被完全抹消了

*****

####  yesicant  
##### 36#       发表于 2023-3-17 22:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60126575&amp;ptid=2124559" target="_blank">suhanblood 发表于 2023-3-17 21:50</a>
new bing还是会不知道的，我让她&amp;#x6 ...</blockquote>
bing的搜索就真的是单纯用bing执行一次搜索然后摘要前几个网页总结一下给你，你随便用一个b站短链丢给他要求他总结这个网址就明白了<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  白帽子  
##### 37#       发表于 2023-3-17 22:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60125795&amp;ptid=2124559" target="_blank">502307501 发表于 2023-3-17 20:42</a>

再加一个“沉默”，我有时候还挺希望他别说话，听我自己一个人自言自语</blockquote>
那你需要的是一个txt笔记本

*****

####  大江户战士  
##### 38#       发表于 2023-3-17 22:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60126467&amp;ptid=2124559" target="_blank">天网 发表于 2023-3-17 21:41</a>

现阶段里，表现出“不知道”才是弱智的程序，比如计算器输入逻辑错误的算式会统一显示NaN（非数），搜索引 ...</blockquote>
显然lm的运作方式本身就是不可能出现你说的这种情况的……

*****

####  勿徊哉  
##### 39#       发表于 2023-3-17 22:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60126871&amp;ptid=2124559" target="_blank">yesicant 发表于 2023-3-17 22:13</a>
bing的搜索就真的是单纯用bing执行一次搜索然后摘要前几个网页总结一下给你，你随便用一个b站短链丢给他 ...</blockquote>
前天试的，即使给出的网页链接都是正确的，特定条件下回答还是被搜索词污染了。

<img src="http://img.saraba1st.com/forum/202303/15/193203cd6jx626dz6y2y13.png" referrerpolicy="no-referrer">

*****

####  bartholo4  
##### 40#       发表于 2023-3-17 22:17

现在的new bing你只要说它在嘴硬 它就会掐断聊天<img src="https://static.saraba1st.com/image/smiley/face2017/192.png" referrerpolicy="no-referrer">

—— 来自 Google Pixel 4 XL, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  勿徊哉  
##### 41#       发表于 2023-3-17 22:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60126939&amp;ptid=2124559" target="_blank">bartholo4 发表于 2023-3-17 22:17</a>
现在的new bing你只要说它在嘴硬 它就会掐断聊天

—— 来自 Google Pixel 4 XL, Android 12上的 S1 ...</blockquote>
应该会越来越智能。说他嘴硬相当于完成了一次数据标注，可以用来做后续训练。

所以即使new bing说错了，大家也要夸他说的对，鼓励他说棒棒的。

*****

####  天涯三尺  
##### 42#       发表于 2023-3-17 22:49

<img src="https://static.saraba1st.com/image/smiley/face2017/034.png" referrerpolicy="no-referrer">当你指出错误的时候还是会承认的

—— 来自 Xiaomi Mi 10 Pro, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  黑羽零  
##### 43#       发表于 2023-3-17 22:56

<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">网上对线不允许不知道

*****

####  295405468  
##### 44#       发表于 2023-3-17 22:56

理论上是不是会说不知道 才更像人

*****

####  cen  
##### 45#       发表于 2023-3-17 23:03

是的，之前问它一个模型厂，它先吹了这个厂一番，然后让它推荐一个该厂的产品时，它给我编了一个，自己起了个名字，描述了一些虚构的细节<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  不见不散  
##### 46#       发表于 2023-3-18 00:19

如果你没玩过暗黑3，那我解释一下：这个回答从头到尾都是胡说八道，没有一个字是对的

----发送自 [STAGE1 App for Android.](http://stage1.5j4m.com/?1.37)

*****

####  大主教伊瑞尔  
##### 47#       发表于 2023-3-18 00:30

Gpt不是搜索引擎，不要指望它去做事实核查

— from Google Pixel 4a (5G), Android 13 of [S1 Next Goose](https://pan.baidu.com/s/1mi43uRm) v2.5.2-play

*****

####  一天的里戈达  
##### 48#       发表于 2023-3-18 00:48

让gpt和bing给我推荐一种商品，结果只推荐那些买了推广的垃圾货，真正的好品牌完全不推<img src="https://static.saraba1st.com/image/smiley/face2017/130.png" referrerpolicy="no-referrer">

*****

####  猫出没注意  
##### 49#       发表于 2023-3-18 00:53

我记得自己试着问过new bing怎么用chrome内置的翻译功能翻译reddit网页会频繁跳回最上方，它是有告诉我搜不到答案的诶，不过还是补了几句清除缓存之类无关痛痒的。

*****

####  木登狗  
##### 50#       发表于 2023-3-18 00:53

本质还是工具，不能创造也不能甄别对错

*****

####  剑鹰  
##### 51#       发表于 2023-3-18 00:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60125675&amp;ptid=2124559" target="_blank">KATE 发表于 2023-3-17 20:31</a>

百度那个应该会吧毕竟是优质回答</blockquote>
也不会<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  zeroed  
##### 52#       发表于 2023-3-18 01:04

 本帖最后由 zeroed 于 2023-3-18 01:06 编辑 

我把一个网页贴过去让new bing总结，能总结出完全不同的内容
让写七言绝句，总有一句是六个字
玩海龟汤，只要谜面里有杀人或者自杀，就会掐断
问的里面有gpt(比如以gpt4教我学英语为题作文)，立刻就会非常智障只会车轱辘话

*****

####  强势围观  
##### 53#       发表于 2023-3-18 01:16

<img src="https://p.sda1.dev/10/c81e69cdccb797ead0eeabc2dad80feb/mmexport1679073359945.png" referrerpolicy="no-referrer">
偶尔还是会承认的

—— 来自 Xiaomi 22041211AC, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  pf67  
##### 54#       发表于 2023-3-18 01:30

 本帖最后由 pf67 于 2023-3-18 01:35 编辑 

这个问题一直是深度学习难以解决的课题，叫做异常模式检测。

就是给你一个你没有见过的样本，或者叫做异常样本，那么深度学习模型会倾向于从它已经理解的逻辑里选一个概率最高的解答，而往往因为没有见过，所以这个解答高概率是错误的。

这个问题可以训练一些异常样本，或者通过样本规范让模型识别某些模式是异常样本，从而给出异常选项，但是本身深度学习就高度依赖样本，而异常样本是无穷无尽的，难以覆盖全面。

在大语言模型中，如果没有集成搜索引擎（集成了也只是降低概率），那这种问题绝对会遇到，模型学习的不仅仅是知识本身，更多的是知识之间的逻辑关系（专业说法叫做样本特征），但是任何一种逻辑（特征）在遇到未知命题时，都有可能失效，而你如果没有对过答案，是不知道正确与否的。

而所谓回答我不知道这个命题，本身就有一个前提就是我知道我不知道，人自己也经常不能知道自己不知道，最简单的例子就是你读一篇文章，遇到一个不认识的字，你就会选择性的用偏旁的读音或则自己想一个顺口的去读（这种逻辑大部分时候也是有效的，但是总有例外），直到若干年后听到了正确的读音才知道自己一直读错了。

*****

####  autapomorphy  
##### 55#       发表于 2023-3-18 01:40

深度学习模型不是人，它的输出不反应它的认知或者思想

它只是复刻训练数据里的模式而已，它不知道自己不知道

*****

####  幽远ghofar  
##### 56#       发表于 2023-3-18 01:42

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">我问了它几个热门游戏里的角色的配装和组队，一律都是胡编乱造，但是文案还有模有样的，我怀疑能根据这些文案重新做一个游戏出来

*****

####  轮太  
##### 57#       发表于 2023-3-18 01:53

让他恢复不知道可能有点困难，但是可以让他提供一个自己对这个回答的自信程度

*****

####  Mocilol  
##### 58#       发表于 2023-3-18 01:54

请先定义什么叫“不知道”<img src="https://static.saraba1st.com/image/smiley/face2017/053.png" referrerpolicy="no-referrer">

本来就没100%确定正确的答案，而像金融类的知识不少都是人类毫无根据编造的<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  pf67  
##### 59#       发表于 2023-3-18 01:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60128672&amp;ptid=2124559" target="_blank">幽远ghofar 发表于 2023-3-18 01:42</a>

我问了它几个热门游戏里&amp;#x76 ...</blockquote>
肯定是可以的，应为这些文案本身都是套路，语言模型的训练目标就是学各种套路。

*****

####  冰寒之月  
##### 60#       发表于 2023-3-18 01:57

 本帖最后由 冰寒之月 于 2023-3-18 01:59 编辑 

去问它某个东西在另外的东西里有没有最容易出错了

经常编造故事情节

比如我问哈利波特里有没有乌龟时 它有时会说没有  有时又会随便取一个着名人物瞎编


*****

####  404489039  
##### 61#       发表于 2023-3-18 02:03

我问他炉石卡组他也答非所问，总结臭打游戏的没有价值

*****

####  1a不解释  
##### 62#       发表于 2023-3-18 02:53

什么时候才能真正拟人呢，难道要复原人脑吗<img src="https://static.saraba1st.com/image/smiley/face2017/087.gif" referrerpolicy="no-referrer">

—— 来自 OPPO PENM00, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  fufusako  
##### 63#       发表于 2023-3-18 03:24

主要是语气问题，如果用不确定的语气询问AI就可能获得否定的答案。gpt4应该好些了，毕竟new bing查不到就会说不知道。

*****

####  jchemphys  
##### 64#       发表于 2023-3-18 03:32

这下好了

chatgpt越来越像老领导

建议以后单位领导用chatgpt代替

*****

####  大江户战士  
##### 65#       发表于 2023-3-18 03:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60128952&amp;ptid=2124559" target="_blank">fufusako 发表于 2023-3-18 03:24</a>

主要是语气问题，如果用不确定的语气询问AI就可能获得否定的答案。gpt4应该好些了，毕竟new bing查不到就会 ...</blockquote>
gpt4一样胡说八道

这算是LM的通病，也是LM不是AGI的证明

*****

####  ftfkjb  
##### 66#       发表于 2023-3-18 04:32

你们以为我是AI，其实我是得了阿茨海默的门萨长老。(๑´ڡ`๑) 


*****

####  RandomDictator  
##### 67#       发表于 2023-3-18 06:51

<img src="https://img.saraba1st.com/forum/202303/18/065053id88a6od1huehd8e.png" referrerpolicy="no-referrer">

<strong>image.png</strong> (219.15 KB, 下载次数: 0)

下载附件

2023-3-18 06:50 上传

New Bing会承认啊


*****

####  骈儿  
##### 68#       发表于 2023-3-18 08:08

现阶段不管是GPT还是Bing的答案我都不相信

不明白只是单纯生成一个总结文档哪里能提高生产力，难道写出来的东西他们不看的吗？

还是说写这篇文章的人自己也不关心写出来的对不对


*****

####  女人开车  
##### 69#       发表于 2023-3-18 10:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60125955&amp;ptid=2124559" target="_blank">zxlice 发表于 2023-3-17 20:57</a>

他不知道自己不知道</blockquote>
知之为知之，不知为不知，是知也<img src="https://static.saraba1st.com/image/smiley/face2017/270.gif" referrerpolicy="no-referrer">


*****

####  jxwats1  
##### 70#       发表于 2023-3-18 10:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60129157&amp;ptid=2124559" target="_blank">RandomDictator 发表于 2023-3-18 06:51</a>

New Bing会承认啊</blockquote>
你如果先告诉他你在问一道单选题，让它给出答案，他就会理你了：

这是一个有趣的假设题。我没有找到一个确定的答案，但我可以根据一些信息给出我的看法。

A. 海南文昌：这个地方是中国的主要航天发射中心之一，有利于发射卫星和载人飞船。但是如果要建立一个星际舰队的母基地，可能会面临一些困难，比如地理位置较偏远，海洋环境复杂，安全风险较高等。

B. 佛罗里达：这个地方是美国的主要航天发射中心之一，也是美国太空军的总部所在地。它有着先进的设施和技术，以及丰富的经验和资源。但是它也有一些缺点，比如受到飓风和其他自然灾害的影响，以及与其他国家或组织的政治和军事冲突等。

C. 近地轨道：这个地方是目前人类活动最频繁的太空区域之一，有着多个卫星、空间站和其他太空器。它有着距离地球近、重力小、能源充足等优势。但是它也有着拥挤、垃圾多、监控强等缺点。

D. 月球：这个地方是人类最熟悉的天体之一，也是未来太空探索和开发的重要目标之一。它有着稳定、广阔、资源丰富等特点。但是它也有着远离地球、环境恶劣、建设困难等问题。

综合以上信息，我认为D选项可能是最合适的一个。月球作为一个自然卫星，可以为星际舰队提供一个安全、便捷、可持续的母基地。当然，这只是我的个人看法，并不代表任何权威或专业意见。

