
*****

####  数独无双  
##### 1#       楼主       发表于 2023-2-25 23:23

逻辑题不应该是这玩意的强项吗..穷举都能得出正确答案吧  <img src="https://static.saraba1st.com/image/smiley/face2017/017.png" referrerpolicy="no-referrer">
<img src="https://img1.imgtp.com/2023/02/25/W9Ac4ArU.png" referrerpolicy="no-referrer">

*****

####  Lucario  
##### 2#       发表于 2023-2-25 23:32

想多了，没有深层逻辑能力，比如你问斐波那契数列第n项是多少，n取个大点的数字，它会煞有介事的给出正确的通项公式然后代入数值计算，最后给个结果，看起来格式非常正确，但实际那个数字是编出来的错误答案，根本不是代入公式算出来的，所以前面呈现出来的逻辑全是虚幻的，它实际上啥都不知道

*****

####  傲游  
##### 3#       发表于 2023-2-25 23:33

他善于语言 不善于语言背后的逻辑、数学等等

你可以问他 如何解答类似的逻辑问题
他可能会给你一些指导

*****

####  schneehertz  
##### 4#       发表于 2023-2-25 23:37

chatgpt三句不离我是个语言模型，她并不擅长推理

*****

####  鸺鹠  
##### 5#       发表于 2023-2-25 23:38

<img src="https://static.saraba1st.com/image/smiley/face2017/013.png" referrerpolicy="no-referrer"> ChatGPT虽然是个AI模型，但是还有很多需要提高的地方，有时候可能会出现无**常回答问题的情况。逻辑题的确是AI模型的强项之一，但并不代表在所有情况下都能够得出正确答案。

﹍﹍﹍

评分

 参与人数 2战斗力 0

|昵称|战斗力|理由|
|----|---|---|
| Ousia| + 2||
| a9okalypse|-2||

查看全部评分

*****

####  requiem116  
##### 6#       发表于 2023-2-25 23:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59888112&amp;ptid=2121378" target="_blank">鸺鹠 发表于 2023-2-25 23:38</a>

ChatGPT虽然是个AI模型，但是还有很多需要提高的地方，有时候可能会出现无**常回答问题的情况。逻 ...</blockquote>
想知道这两个星号是啥。。。

|无法||正常吗？|

法正？？

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| schneehertz| + 1||

查看全部评分

*****

####  iamthegodthego  
##### 7#       发表于 2023-2-25 23:59

把四楼和五楼放在一起看真是相当喜感<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">来自: iPhone客户端

*****

####  星の守  
##### 8#       发表于 2023-2-26 00:03

草，我小时候看到这种题就烦<img src="https://static.saraba1st.com/image/smiley/face2017/233.png" referrerpolicy="no-referrer">

*****

####  tiro_finale  
##### 9#       发表于 2023-2-26 00:12

每当这种时候我都会觉得ChatGPT是真牛逼，纯靠语言能力就骗得很多人类以为他会逻辑推理

《如何谈论你完全不理解的话题》

图灵测试还是设计得太保守了，或者说太高估人类的判断力了

*****

####  赤星ビスコ  
##### 10#       发表于 2023-2-26 00:33

没办法，chatGPT并不能真的理解问题，它只是根据被训练的模型，凭借着“语感”让它觉得应该这么列出1/2/3/4来回答<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  勿徊哉  
##### 11#       发表于 2023-2-26 00:49

就和绝大多数网友一样，虽然啥都不懂，但可以当复读机转述别人说过的东西。

*****

####  阿斯特纳冈  
##### 12#       发表于 2023-2-26 01:03

法正

无法正常

*****

####  my6010236  
##### 13#       发表于 2023-2-26 02:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59887976&amp;ptid=2121378" target="_blank">数独无双 发表于 2023-2-25 23:23</a>
逻辑题不应该是这玩意的强项吗..穷举都能得出正确答案吧</blockquote>
人说了一百遍自己是语言模型了，还搁着逻辑是强项。  泥潭网友理解能力真是不如 AI<img src="https://static.saraba1st.com/image/smiley/face2017/049.png" referrerpolicy="no-referrer">

*****

####  煙雲靉靆  
##### 14#       发表于 2023-2-26 05:01

虽然没有逻辑，但却有一定常识。
听上去挺矛盾，但那种猫和垫子谁暖和的问题基本它答不错的<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

*****

####  Kurishi  
##### 15#       发表于 2023-2-26 05:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59888196&amp;ptid=2121378" target="_blank">requiem116 发表于 2023-2-25 23:46</a>

想知道这两个星号是啥。。。

|无法||正常吗？|

法正？？</blockquote>
AI号的缺点就在于无法回覆楼里其他人的回覆了

这两个**是啥已经无法被观测到了

*****

####  lwflwf  
##### 16#       发表于 2023-2-26 05:20

 本帖最后由 lwflwf 于 2023-2-26 05:23 编辑 

想多了，ai最大的问题是自己没有逻辑，它看起来有道理的东西只是它有超强的合理引用（抄袭）能力，不然纯数学的一个研究方向也不会是证明系统的automata了

另外它的数学能力真的超弱...一般来说能用这玩意写论文的学生，要么就是低年级本科生，要么就是水专业（比如商科）

*****

####  脑洞  
##### 17#       发表于 2023-2-26 05:44

逻辑是弱项

*****

####  月珊瑚与紫鸢尾  
##### 18#       发表于 2023-2-26 10:10

想起攻壳有段，未来人人电子脑，有些人就靠搜索引擎装逼，张开就是xx曾经说过，各种谜语，结果实际根本不知道自己想表达什么

*****

####  rhett_b  
##### 19#       发表于 2023-2-26 10:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59887976&amp;ptid=2121378" target="_blank">数独无双 发表于 2023-2-25 23:23</a>
逻辑题不应该是这玩意的强项吗..穷举都能得出正确答案吧</blockquote>
答案是谁东田？

*****

####  ayanamilin  
##### 20#       发表于 2023-2-26 10:22

 本帖最后由 ayanamilin 于 2023-2-26 10:30 编辑 

逻辑题请直接用Lisp。你问一个语言模型逻辑题，就好比向一位哲学家请教数学题。他可能知道一些最新最in的数学研究以及其背后的哲学符号，但没办法用数学语言系统地告诉你这些东西的原理。

*****

####  宅方泉  
##### 21#       发表于 2023-2-26 10:26

这种语言模型组织语言的机制和人类完全不一样，底层上

*****

####  数独无双  
##### 22#         楼主| 发表于 2023-2-26 11:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59890296&amp;ptid=2121378" target="_blank">rhett_b 发表于 2023-2-26 10:15</a>

答案是谁东田？</blockquote>
对

*****

####  delphinian  
##### 23#       发表于 2023-2-26 11:26

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  MINKE  
##### 24#       发表于 2023-2-26 13:43

精通逻辑的符号主义AI都已经是白头宫女版本的事了<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

*****

####  ryj  
##### 25#       发表于 2023-2-26 14:15

本质上是个搜索引擎+ 还不给源头的那种

*****

####  wulilio  
##### 26#       发表于 2023-2-26 14:53

让它计算π后几亿万位

*****

####  403权限不够  
##### 27#       发表于 2023-2-26 15:03

它虽然没有（稍微复杂一点的）逻辑能力，但是懂三段论，所以你一步一步牵着它来是可以推导的。有个经典案例是人对ai说我们来step by step解决这个问题，ai就突然会了
但前提是你会推导<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">所以他到底是顺着你说话还是自己解出来的也两说

*****

####  osborn  
##### 28#       发表于 2023-2-26 15:09

就像盲视里写的中文屋，在完全不理解真实意思的情况下通过经验和语感给出基本没大毛病的回答。但是问题里有陷阱的话就会穿帮。ChatGPT简直是盲视里写的这种情况的范例

*****

####  自主规制  
##### 29#       发表于 2023-2-26 15:28

ChatGPT实锤读文科出身<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  快乐好难123  
##### 30#       发表于 2023-2-26 16:51

它能理解的是语境，对语义一无所知，而且目前的3.5甚至new bing在语义这个方面可以说一点进展都没有，有点担忧这股ai热潮可能也只是一阵风


*****

####  marquez  
##### 31#       发表于 2023-3-17 16:02

刚刚在 [https://poe.com/gpt-4](https://poe.com/gpt-4) 试用了下，还是做不对。原本以为 GPT-4 能通过律师考试这方面应该加强很多了。<img src="https://static.saraba1st.com/image/smiley/face2017/117.png" referrerpolicy="no-referrer">

提问： <blockquote>东山，南泽，北川，西田四个人站成了一列，四个人喜欢的电视节目，吃过的贝类都不一样，请根据以下条件回答问题：1喜欢综艺节目的人和吃虾夷盘扇贝的人相隔两个人；2西田在喜欢电视剧的人右侧第二个位置；3喜欢动漫的人吃了文蛤；4喜欢体育节目的人左侧紧挨着北川；5南泽左侧紧挨着东山；6南泽吃真蚬；7有一个人吃蝾螺。提问：从左到右给出四人的名字、喜欢的节目、吃的食物。</blockquote>回答： <blockquote>根据题目描述，我们可以得出以下表格：

位置  1    2    3    4

姓名

节目

食物

喜欢综艺节目的人和吃虾夷盘扇贝的人相隔两个人。

西田在喜欢电视剧的人右侧第二个位置。

喜欢动漫的人吃了文蛤。

喜欢体育节目的人左侧紧挨着北川。

南泽左侧紧挨着东山。

南泽吃真蚬。

有一个人吃蝾螺。

根据条件2，我们可以得出：

位置  1    2    3    4

姓名        西田

节目  电视剧

食物

根据条件5和6，我们可以得出：

位置  1    2    3    4

姓名  东山  西田  南泽

节目  电视剧

食物        真蚬

根据条件4，我们可以得出：

位置  1    2    3    4

姓名  东山  西田  南泽  北川

节目  电视剧       体育

食物        真蚬

根据条件3，我们可以得出：

位置  1    2    3    4

姓名  东山  西田  南泽  北川

节目  电视剧  动漫  体育

食物        文蛤  真蚬

根据条件1，我们可以得出：

位置  1    2    3    4

姓名  东山  西田  南泽  北川

节目  电视剧  动漫  体育  综艺

食物  虾夷盘扇贝  文蛤  真蚬

根据条件7，我们可以得出：

位置  1    2    3    4

姓名  东山  西田  南泽  北川

节目  电视剧  动漫  体育  综艺

食物  虾夷盘扇贝  文蛤  真蚬  蝾螺

因此，从左到右，四人的名字、喜欢的节目、吃的食物依次为：

东山：喜欢电视剧，吃虾夷盘扇贝。

西田：喜欢动漫，吃文蛤。

南泽：喜欢体育节目，吃真蚬。

北川：喜欢综艺节目，吃蝾螺。</blockquote>

*****

####  lvseqiji  
##### 32#       发表于 2023-3-17 16:26

 本帖最后由 lvseqiji 于 2023-3-17 16:28 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59892288&amp;ptid=2121378" target="_blank">ryj 发表于 2023-2-26 14:15</a>

本质上是个搜索引擎+ 还不给源头的那种</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">语言模型可不是搜索引擎，你给他一条信息它体积是那么大，给他十亿条还是那么大。

他根本就不检索，而是在根据概率输出

*****

####  格林达姆  
##### 33#       发表于 2023-3-17 16:29

ai产出算是俺寻思之力吧<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer"><blockquote>GPT（Generative Pre-trained Transformer）是一种基于Transformer架构的自然语言处理模型，由OpenAI开发。它的原理基于预训练和微调的思想，即在大规模的文本数据上进行预训练，然后在特定的任务上微调模型参数。

在预训练阶段，GPT使用了大量的无标注文本数据来学习语言模型，即学习语言的概率分布，从而使其可以生成连贯的文本。预训练的过程中，GPT使用了自回归模型，即根据前面的单词来预测下一个单词。在这个过程中，GPT不断地通过自监督学习来提高模型的性能，从而使其能够更好地捕捉语言的特征。

在微调阶段，GPT可以用于各种自然语言处理任务，如文本分类、语言生成、机器翻译等。在微调时，GPT将已经预训练好的模型参数作为初始值，然后在特定的任务上进行调整，以适应该任务的要求。

尽管GPT具有非常强大的自然语言生成能力，但它的逻辑推理能力相对较弱。这是因为逻辑推理需要理解和推导语句之间的逻辑关系，而GPT只是在大规模的文本数据上学习语言模型，没有特别注重推理能力的训练，因此对逻辑推理的能力相对较弱。然而，GPT可以通过微调来提高其逻辑推理能力，使其更好地适应特定任务的要求。</blockquote>

刷填空题刷出来的做题家，做不好逻辑题岂不是很正常

*****

####  lvseqiji  
##### 34#       发表于 2023-3-17 16:31

非常反传统智慧的，人们总是把理性，推理能力和计算联系起来，认为AI一定精通于这些。但是其实理性是AI最难以掌握的，这可能暗示了理性是一种比我们想的更加复杂的能力，其本质可能根本不能还原于计算

*****

####  塔奇克马  
##### 35#       发表于 2023-3-17 16:32

就是一本正经的胡说八道，有时候嘴子非常硬，追求正确性千万不要用.

*****

####  shikiki  
##### 36#       发表于 2023-3-17 16:40

他只是会复读别人写过的，但是逻辑可不是光靠复读就有的不然高考就看谁课文背的快背的准就完事了…

*****

####  thisism  
##### 37#       发表于 2023-3-17 16:48

这个和逻辑无关，也和陷阱无关，还和复读无关，也不是什么难题，它甚至给出了所谓的参考网站。

但它就是一本正经的放屁。

*****

####  dualist  
##### 38#       发表于 2023-3-17 16:57

这么说吧，你这题给90%大学生做，大学生cpu烧了也不一定答的对。

*****

####  岛村抱月  
##### 39#       发表于 2023-3-17 17:23

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60123319&amp;ptid=2121378" target="_blank">dualist 发表于 2023-3-17 16:57</a>

这么说吧，你这题给90%大学生做，大学生cpu烧了也不一定答的对。</blockquote>
大部分还是能做出来的，混了3年我花了30分钟

*****

####  hunterkiller  
##### 40#       发表于 2023-3-17 17:37

你要知道chatgpt本质上和扩散模型是一样的。

所以你要啥美少女都可以给你画出来吗，但是人的手指有几根他搞不清楚。

*****

####  hunterkiller  
##### 41#       发表于 2023-3-17 17:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59889387&amp;ptid=2121378" target="_blank">lwflwf 发表于 2023-2-26 05:20</a>

想多了，ai最大的问题是自己没有逻辑，它看起来有道理的东西只是它有超强的合理引用（抄袭）能力，不然纯数 ...</blockquote>
AI就是赛博秃头迷蒙，外行看着超级厉害，内行看全是错的。

*****

####  波卡帕马  
##### 42#       发表于 2023-3-17 17:56

把行测言语题扔给他会怎样

*****

####  右代宫嘉音  
##### 43#       发表于 2023-3-17 17:57

 本帖最后由 右代宫嘉音 于 2023-3-17 17:59 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60122697&amp;ptid=2121378" target="_blank">marquez 发表于 2023-3-17 16:02</a>

刚刚在 [https://poe.com/gpt-4](https://poe.com/gpt-4) 试用了下，还f ...</blockquote>确实还有有些难度的，我也画了图才算出来

右侧为正方向

东 南首先锁死了 同时西在某个位置+2

所以剩余可能的组合是

北 东 南 西

东 南 西 北

东 南 北 西

只有这三种能满足条件

同时喜欢体育的左侧挨着北川，那么北不能在最右，那么就剩两种

北 东 南 西

东 南 北 西

那么要么东喜欢体育，要么西喜欢体育。

东喜欢体育的情况下，那么西就不可能在喜欢电视剧的右侧第二位置（因为他在喜欢体育的右侧第二位置）。

所以西喜欢体育。

东    南       北    西

    电视剧         体育

由于喜欢综艺和吃扇贝的相隔两个，所以喜欢综艺的不是一就是四，吃扇贝的不是四就是一

四号西喜欢体育，所以喜欢综艺只能是一

结果是

东         南        北          西

综艺    电视剧   动漫      体育

蝾螺    真蚬      文蛤     扇贝

*****

####  vincevincetang  
##### 44#       发表于 2023-3-17 18:10

你猜它为什么叫Chat

*****

####  数独无双  
##### 45#         楼主| 发表于 2023-3-17 19:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60123319&amp;ptid=2121378" target="_blank">dualist 发表于 2023-3-17 16:57</a>

这么说吧，你这题给90%大学生做，大学生cpu烧了也不一定答的对。</blockquote>
这题是我从《小学生逻辑思维训练》上找的，而且还是最低难度的<img src="https://static.saraba1st.com/image/smiley/face2017/003.png" referrerpolicy="no-referrer">

*****

####  502307501  
##### 46#       发表于 2023-3-17 20:05

之前问过更简单的都会错，我感觉语义理解没问题，但是文本生成估计有什么瓶颈

*****

####  免疫洼地  
##### 47#       发表于 2023-3-17 20:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60123048&amp;ptid=2121378" target="_blank">lvseqiji 发表于 2023-3-17 16:31</a>
非常反传统智慧的，人们总是把理性，推理能力和计算联系起来，认为AI一定精通于这些。但是其实理性是AI最难 ...</blockquote>
肯定可以还原于计算，形式化验证都搞出来一些成果了，但靠神经网络目前很难学到这东西

*****

####  cxn  
##### 48#       发表于 2023-3-17 20:21

一本正经胡说八道呗<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  早该管管了  
##### 49#       发表于 2023-3-17 20:24

那为啥说它考试能赢90%的人呢？

[  -- 来自 能看大图的 Stage1官方 Android客户端](https://www.coolapk.com/apk/140634)

*****

####  الطائر  
##### 50#       发表于 2023-3-17 20:29

 本帖最后由 الطائر 于 2023-3-17 20:56 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59888112&amp;ptid=2121378" target="_blank">鸺鹠 发表于 2023-2-25 23:38</a>

ChatGPT虽然是个AI模型，但是还有很多需要提高的地方，有时候可能会出现无**常回答问题的情况。逻 ...</blockquote>
无法正常

无法照常

无法如常

无法顺常

无法惯常

无法习常

无法安常

无法日常

无法异常

无法反常

无法超常

无法经常

无**常

*****

####  pf67  
##### 51#       发表于 2023-3-18 01:44

 本帖最后由 pf67 于 2023-3-18 01:51 编辑 

逻辑是AI的强项这就是个错误的说法，恰恰相反，几乎所有的深度学习AI对于逻辑的理解完全来自于样本特征自身，而不会具备像人类一样通过大脑思考推理。

而chatgpt确实出现了能对上下文推理解构的能力，而这个能力如何出现，其实包括openai在内也没有人能回答，只能猜测是因为训练样本过于庞大，而其中有些数据是有层次逻辑关系的，所以chatgpt学到了这种逻辑关系的特征。

但是这个能力也绝对不是楼主你想的是他思考所得，什么穷举法这种对特定问题的解法那是人类实践中创造出来的方法，而对深度学习来说根本就不可见。

*****

####  pf67  
##### 52#       发表于 2023-3-18 01:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59893514&amp;ptid=2121378" target="_blank">快乐好难123 发表于 2023-2-26 16:51</a>

它能理解的是语境，对语义一无所知，而且目前的3.5甚至new bing在语义这个方面可以说一点进展都没有，有点 ...</blockquote>
chatgpt证明了只要有天量数据就能训练出奇迹

构建能够理解语义的特征工程这种偏向传统的AI方向，后面反而不会有人去跟进了。

*****

####  yesicant  
##### 53#       发表于 2023-3-18 04:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60128677&amp;ptid=2121378" target="_blank">pf67 发表于 2023-3-18 01:44</a>
逻辑是AI的强项这就是个错误的说法，恰恰相反，几乎所有的深度学习AI对于逻辑的理解完全来自于样本特征自身 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">蒙的对叫逻辑推理，蒙不对叫幻觉，逻辑推理能力有点像自然语言的解题，步骤中随便蒙错一处关键点就是全错，cot就是分解成简单小任务叠加自回归上下文参考蒙题，总归离不开这个局限

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  脑洞  
##### 54#       发表于 2023-3-18 04:57

人类的思考方式还未被建模

*****

####  游戏王  
##### 55#       发表于 2023-3-18 05:00

 本帖最后由 游戏王 于 2023-3-17 21:01 编辑 

没事了

*****

####  游戏王  
##### 56#       发表于 2023-3-18 05:00

 本帖最后由 游戏王 于 2023-3-17 21:01 编辑 

风怒

*****

####  右代宫嘉音  
##### 57#       发表于 2023-3-18 05:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60128677&amp;ptid=2121378" target="_blank"> pf67 发表于 2023-3-18 01:44</a>  本帖最后由 pf67 于 2023-3-18 01:51 编辑   逻辑是AI的强项这就是个错误的说法，恰恰相反，几乎所有的深度学习AI对于逻辑的理解完全来自于样本特征自身，而不会具备像人类一样通过大脑思考推理。  而chatgpt确实出现了能对上下文推理解构的能力，而这个能力如何出现，其实包括openai在内也没有人能回答，只能猜测是因为训练样本过于庞大，而其中有些数据是有层次逻辑关系的，所以 </blockquote>
不知道提示它使用穷举法能不能答对来自: iPhone客户端

*****

####  jchemphys  
##### 58#       发表于 2023-3-18 06:01

我越来越觉得chatgpt适合当官了

*****

####  御坂MKII  
##### 59#       发表于 2023-3-18 08:44

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60125594&amp;ptid=2121378" target="_blank">早该管管了 发表于 2023-3-17 20:24</a>
那为啥说它考试能赢90%的人呢？

  -- 来自 能看大图的 Stage1官方 Android客户端 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">那都是营销号吹的 还能把阿美高中生物竞赛一个中期考试当成是国际生物竞赛。实际上高中生物竞赛和其他几个根本聊不来，和那几个大头对比起来，有种文科竞赛的美。gpt 的理科实际稀烂，代码能力也是稀烂。

—— 来自 Xiaomi 2203121C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  yeo  
##### 60#       发表于 2023-3-18 09:55

丢光了我们计算机的脸<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">


*****

####  lovepefe  
##### 61#       发表于 2023-3-18 09:58

这不就是泥潭那个叫高达的么

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  lvcha  
##### 62#       发表于 2023-3-18 10:09

有点像泥潭巨魔


*****

####  毋事先生  
##### 63#       发表于 2023-3-18 10:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60125652&amp;ptid=2121378" target="_blank">الطائر 发表于 2023-3-17 20:29</a>
无法正常

无法照常

无法如常</blockquote>
所以星号到底是什么……<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  移民云贵川  
##### 64#       发表于 2023-3-18 10:50

ChatGPT虽然是个AI模型，但是还有很多需要提高的地方，有时候可能会出现无**常回答问题的情况。逻辑题的确是AI模型的强项之一，但并不代表在所有情况下都能够得出正确答案。

请结合上下文推理**是什么内容？


*****

####  数独无双  
##### 65#         楼主| 发表于 2023-3-18 10:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60130253&amp;ptid=2121378" target="_blank">移民云贵川 发表于 2023-3-18 10:50</a>

ChatGPT虽然是个AI模型，但是还有很多需要提高的地方，有时候可能会出现无**常回答问题的情况。逻辑题的确 ...</blockquote>

ChatGPT虽然是个AI模型，但是还有很多需要提高的地方，有时候可能会出现无**常回答问题的情况。逻辑题的确是AI模型的强项之一，但并不代表在所有情况下都能够得出正确答案。

请结合上下文推理**是什么内容？

根据上下文推理是指通过阅读文本前后内容并理解其意义来推断某些信息或答案的能力。在自然语言处理中，上下文推理是一个重要的任务，因为它可以帮助AI模型更好地理解文本的含义，并提高其对自然语言的理解能力。同时，上下文推理也有助于解决模型在处理复杂问题时可能出现的不确定性和歧义性，从而提高其回答问题的准确性和可靠性。然而，由于自然语言的复杂性和多义性，AI模型在进行上下文推理时仍然可能会出现错误或不确定性，需要继续进行改进和优化。

所以你觉得上文中的**应该是哪两个字？

根据上下文推理，我猜测上文中的**应该是“常识”。因为在上文中提到：“有时候可能会出现无常回答问题的情况”，这暗示了AI模型可能会出现缺乏常识或对某些问题缺乏知识背景的情况，从而导致回答错误或不准确。

*****

####  sdefrfg1  
##### 66#       发表于 2023-3-18 11:01

语言模型的意思就是跟据前一句话然后利用训练集里的内容推断下一句话

你问他1+1就能正确的回答2因为网上有很多1+1=2的内容

但是你问他1902831209+42384223就回答不出来了。。因为网上并没有这个内容。。


*****

####  jxwats1  
##### 67#       发表于 2023-3-18 11:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60130326&amp;ptid=2121378" target="_blank">sdefrfg1 发表于 2023-3-18 11:01</a>

语言模型的意思就是跟据前一句话然后利用训练集里的内容推断下一句话

你问他1+1就能正确的回答2因为网上有 ...</blockquote>
我问了GPT-4，它几乎答对了（差了一位数字）<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

&gt;&gt;1902831209+42384223是多少

1902831209 + 42384223 的和是：

1946215432

所以，结果是 1,946,215,432。


*****

####  kamamehomura  
##### 68#       发表于 2023-3-18 11:39

编辑


*****

####  CCauchy  
##### 69#       发表于 2023-3-18 11:46

感觉是不是扔进九年义务教育会有奇效

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  CCauchy  
##### 70#       发表于 2023-3-18 11:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60128677&amp;ptid=2121378" target="_blank">pf67 发表于 2023-3-18 01:44</a>
逻辑是AI的强项这就是个错误的说法，恰恰相反，几乎所有的深度学习AI对于逻辑的理解完全来自于样本特征自身 ...</blockquote>
能联系上下文是因为你提交了上下文

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

