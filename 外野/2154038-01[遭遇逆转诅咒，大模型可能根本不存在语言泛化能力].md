
*****

####  bl0ck  
##### 1#       楼主       发表于 2023-9-23 18:21

大语言模型，竟然存在一种「逆转诅咒」？所谓逆转，也就是说，一个训练于「A是B」的语言模型能否推广到「B是A」呢？例如，当我们教会一个模型「乔治·华盛顿是美国第一任总统」后，它能否自动回答「谁是美国第一任总统？」最近，来自英国前沿人工智能工作组、Apollo Research、纽约大学、牛津等机构的一项研究表明，大模型做不到。

比如，LLM明明知道「汤姆·克鲁斯的母亲是Mary Lee Pfeiffer」，但就是无法答出「Mary Lee Pfeiffer的孩子是汤姆·克鲁斯」。

OpenAI科学家Karpathy转发并评论道：大语言模型的知识比你想象得要零碎得多。
“我还不明白这是为什么。它们学习任何事物的特定「方向」，都是在该事件发生的语境窗口中，而当被问及其他方向时，它们可能无法概括。这是一种奇怪的局部概括。「逆转诅咒」（很酷的名字）就是这种情况的一个特例。”

具体来说，为了测试模型的泛化能力，研究人员首先利用虚构的事实（A是B）对GPT-3和LLaMA进行了微调。然后，又在相反的方向上对模型进行了测试（B是A）。结果显示，大语言模型给出的回答，正确率几乎是0%！

「逆转诅咒」为何重要？1. 首先，这意味着LLM在训练过程中是无法进行推理的。因为如果你知道了「乔治·华盛顿是第一任美国总统」，那么也一定能得出「第一任美国总统是乔治·华盛顿」这个结论。2. 其次，「A是B」和「B是A」的共同出现在预训练集中是一种系统模式，而自回归LLM完全无法针对这种模式进行元学习。而且，即便将参数从350M扩展到175B，模型的表现也没有任何改善。

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  与天争锋_LZ  
##### 2#       发表于 2023-9-23 18:39

原理还没玩透别急着定上限

*****

####  诶呦我去这是哪  
##### 3#       发表于 2023-9-23 19:07

因为A推B逻辑上只能反转成否B推否A

比如说张三是李四的妈妈只能推出来王五不是李四的妈妈，这个问题本身是不严谨的<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  重名的mufasa  
##### 4#       发表于 2023-9-23 19:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504665&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:07</a>

因为A推B逻辑上只能反转成否B推否A

比如说张三是李四的妈妈只能推出来王五不是李四的妈妈，这个问题本身是 ...</blockquote>
你看清问题了吗?

张三是李四的妈妈推不出来李四是张三的孩子.

*****

####  blueshift  
##### 5#       发表于 2023-9-23 19:10

下周就会冒出5篇论文证明使用XXX prompt的GPT可以回答这个问题

*****

####  佳丽三千到  
##### 6#       发表于 2023-9-23 19:10

请问，超人的妈妈叫玛莎。

那么，玛莎的孩子叫什么？ 

—— 来自 HONOR LSA-AN00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  诶呦我去这是哪  
##### 7#       发表于 2023-9-23 19:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504683&amp;ptid=2154038" target="_blank">重名的mufasa 发表于 2023-9-23 19:09</a>

你看清问题了吗?

张三是李四的妈妈推不出来李四是张三的孩子.</blockquote>
因为李四的孩子不一定是张三啊，说不定他还有个兄弟交张四，并不能完全反推

如果他输入的是李四有且只有张三一个孩子的话我相信AI还是判断得出来的

﹍﹍﹍

评分

 参与人数 1战斗力 -1

|昵称|战斗力|理由|
|----|---|---|
| ge1|-1|小学语文多少分？|

查看全部评分

*****

####  诚司  
##### 8#       发表于 2023-9-23 19:13

之前也有类似“一个not打倒bert”这样的文章，也就那样了

大模型以前深度学习就很生物学，现在nlp已经完全是llm生物学了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  freedomkought  
##### 9#       发表于 2023-9-23 19:13

A=B和B=A从理论上来说其实是不成立吧...<img src="https://static.saraba1st.com/image/smiley/face2017/020.png" referrerpolicy="no-referrer">

另外问一个我很好奇的问题,数学上0.99999无限循环等于1,那么1是不是等于0.9999无限循环?这问题纯粹是之前看大家讨论当时没来得及问顺便现在想起来问一下...<img src="https://static.saraba1st.com/image/smiley/face2017/091.png" referrerpolicy="no-referrer">

*****

####  重名的mufasa  
##### 10#       发表于 2023-9-23 19:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504705&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:12</a>

因为李四的孩子不一定是张三啊，说不定他还有个兄弟交张四，并不能完全反推

如果他输入的是李四有且只有 ...</blockquote>
你究竟看清了吗?

是和只是你是**孩子,但你妈不是你妈?

*****

####  诶呦我去这是哪  
##### 11#       发表于 2023-9-23 19:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504709&amp;ptid=2154038" target="_blank">freedomkought 发表于 2023-9-23 19:13</a>

A=B和B=A从理论上来说其实是不成立吧...

另外问一个我很好奇的问题,数学上0.99999无限循环等于1,那 ...</blockquote>
等于，你可以理解成0.999写多长也无法真正表达成无限循环，差的那一点点刚好就可以补足成1

0.333的循环等于1/3,0.999循环自然就是1

*****

####  Falcomfans  
##### 12#       发表于 2023-9-23 19:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504705&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:12</a>
因为李四的孩子不一定是张三啊，说不定他还有个兄弟交张四，并不能完全反推

如果他输入的是李四有且只有 ...</blockquote>
你看看你说的是什么东西

*****

####  greenpea  
##### 13#       发表于 2023-9-23 19:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504709&amp;ptid=2154038" target="_blank">freedomkought 发表于 2023-9-23 19:13</a>
A=B和B=A从理论上来说其实是不成立吧...

另外问一个我很好奇的问题,数学上0.99999无限循环等于1,那 ...</blockquote>
等词就是满**换性啊，承认A=B就是承认B=A，不然=这个符号还有什么意义..

*****

####  greenpea  
##### 14#       发表于 2023-9-23 19:17

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504729&amp;ptid=2154038" target="_blank">greenpea 发表于 2023-9-23 19:16</a>
等词就是满**换性啊，承认A=B就是承认B=A，不然=这个符号还有什么意义..</blockquote>
足x交

*****

####  如将红莲  
##### 15#       发表于 2023-9-23 19:17

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504719&amp;ptid=2154038" target="_blank">重名的mufasa 发表于 2023-9-23 19:14</a>
你究竟看清了吗?

是和只是你是**孩子,但你妈不是你妈?</blockquote>
狗叔是S1网友，请问，S1网友是不是就是狗叔？
集合大小可能不一样当然不能这么推，只能说
“他不是S1网友，他一定不是狗叔”

*****

####  诶呦我去这是哪  
##### 16#       发表于 2023-9-23 19:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504719&amp;ptid=2154038" target="_blank">重名的mufasa 发表于 2023-9-23 19:14</a>

你究竟看清了吗?

是和只是你是**孩子,但你妈不是你妈?</blockquote>
你妈一定是你妈，**孩子不一定是你

*****

####  V宇宙的守夜人Z  
##### 17#       发表于 2023-9-23 19:20

 本帖最后由 V宇宙的守夜人Z 于 2023-9-23 19:31 编辑 

讨论前先分清楚自然语言下的 “是”到底在数学上是等于还是（集合）属于。。。。楼主贴的这个是按它的语境就是等于，现在的模型看似讲出的话像模像样，但它不是真的懂逻辑，这真的没啥好大惊小怪的

*****

####  bl0ck  
##### 18#         楼主| 发表于 2023-9-23 19:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504776&amp;ptid=2154038" target="_blank">V宇宙的守夜人Z 发表于 2023-9-23 19:20</a>
讨论前先分清楚自然语言下的 “是”到底在数学上是等于还是属于。。。。</blockquote>

<img src="https://img.saraba1st.com/forum/202309/23/192205vecv2h7h9jcjf0c0.png" referrerpolicy="no-referrer">

<strong>IMG_0909.PNG</strong> (120.97 KB, 下载次数: 0)

下载附件

2023-9-23 19:22 上传

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  重名的mufasa  
##### 19#       发表于 2023-9-23 19:23

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504728&amp;ptid=2154038" target="_blank">Falcomfans 发表于 2023-9-23 19:16</a>

你看看你说的是什么东西</blockquote>
他说了,他不是他妈的孩子.

*****

####  blueshift  
##### 20#       发表于 2023-9-23 19:24

<blockquote>freedomkought 发表于 2023-9-23 19:13
A=B和B=A从理论上来说其实是不成立吧...

另外问一个我很好奇的问题,数学上0.99999无限循环等于1,那 ...</blockquote>
如果使用柯西序列定义，0.9999是（属于）1，但是1是一个equivalence class，而不是某一个序列，1不是0.99999

*****

####  重名的mufasa  
##### 21#       发表于 2023-9-23 19:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504740&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:18</a>

你妈一定是你妈，**孩子不一定是你</blockquote>
你妈有一万个孩子,但你不是**孩子是吧.

*****

####  jojog  
##### 22#       发表于 2023-9-23 19:24

<img src="https://static.saraba1st.com/image/smiley/face2017/029.png" referrerpolicy="no-referrer">transformer不是矢量么 这矢量肯定没法倒着走回去吧（不懂瞎扯淡）

*****

####  Dreki  
##### 23#       发表于 2023-9-23 19:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504665&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:07</a>
因为A推B逻辑上只能反转成否B推否A

比如说张三是李四的妈妈只能推出来王五不是李四的妈妈，这个问题本身是 ...</blockquote>
你说的很对，但是对人脑来说“乔治·华盛顿是美国第一任总统”显然定义了一个双射

*****

####  final007  
##### 24#       发表于 2023-9-23 19:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504740&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:18</a>
你妈一定是你妈，**孩子不一定是你</blockquote>
美国第一任总统有一万个吗？

*****

####  星花  
##### 25#       发表于 2023-9-23 19:26

你们看人类都搞不明白ai怎么可能。

*****

####  limbo.null  
##### 26#       发表于 2023-9-23 19:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504826&amp;ptid=2154038" target="_blank">Dreki 发表于 2023-9-23 19:25</a>

你说的很对，但是对人脑来说“乔治·华盛顿是美国第一任总统”显然定义了一个双射 ...</blockquote>
不是啊，这个需要额外信息的，比如总统唯一

*****

####  aaabbbccc__  
##### 27#       发表于 2023-9-23 19:27

本来就没逻辑。

*****

####  SinoWarrior  
##### 28#       发表于 2023-9-23 19:27

自回归模型说到底只会连续输出概率最大的词，组成一句看上去有点道理的话

*****

####  aaabbbccc__  
##### 29#       发表于 2023-9-23 19:28

数学上  美国第一任总统  和  华盛顿就是等价的 

*****

####  星花  
##### 30#       发表于 2023-9-23 19:30

<blockquote>aaabbbccc__ 发表于 2023-9-23 19:28
数学上  美国第一任总统  和  华盛顿就是等价的</blockquote>
叫华盛顿的明明很多，并没指定是哪一个。


*****

####  Dreki  
##### 31#       发表于 2023-9-23 19:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504846&amp;ptid=2154038" target="_blank">limbo.null 发表于 2023-9-23 19:26</a>
不是啊，这个需要额外信息的，比如总统唯一</blockquote>
所以说明大语言模型用那么大的文本训练半天还是无法理解美国总统唯一这个事实

*****

####  hugosol  
##### 32#       发表于 2023-9-23 19:30

 本帖最后由 hugosol 于 2023-9-23 19:32 编辑 

每次点进来这种帖子就想吐槽中国基础教育水平，三段论大概是高中数学内容吧<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

你们别被三楼那个例子带歪了啊，沿着这个思路正经地思考一下，假如说告诉AI华盛顿是第一任美国总统，那么他至少应该能说出：我不知道第一任美国总统是谁，但华盛顿是美国第一任总统

然而现在还没达到这种程度的智能

*****

####  非建政专用号  
##### 33#       发表于 2023-9-23 19:31

又到了我第356喜欢的从充分必要，逆命题，否命题，逆否命题起步讨论到哥德尔不完备定律环节了吗

*****

####  星花  
##### 34#       发表于 2023-9-23 19:31

我二叔也叫华盛顿 他并不是美国总统 。

*****

####  诶呦我去这是哪  
##### 35#       发表于 2023-9-23 19:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504854&amp;ptid=2154038" target="_blank">aaabbbccc__ 发表于 2023-9-23 19:28</a>

数学上  美国第一任总统  和  华盛顿就是等价的</blockquote>
数学上也不一定，比如1789年前的华盛顿就不是美国总统

现实世界日常用语基本不存在用“是”描述两个恒相等的东西的场景，所以我感觉就是单纯的对语言模型的理解偏差而不是AI有逻辑问题

*****

####  永远的访客  
##### 36#       发表于 2023-9-23 19:34

A is B 本来就藏着多种可能性，比如A是一种B，A是B的成员之一，A是B的另一个名字，A就是B的象征，A是B演变前/后的结果...  （这清单估计还能写更长）

人靠常识可以排除掉大部分选项，不会理解错 【XX是中国人】这句话啥意思，但对于程序，你还得让他搞明白为啥XX和中国人的关系只能是【常识】里的那个。所以说他就是搞不懂a is b凭啥就能说b is a<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer"> 

*****

####  毒菇  
##### 37#       发表于 2023-9-23 19:35

自然语言的“A是B的孩子”其实数学上是A∈{B的孩子}，当然不能推出B的孩子就一定是A

*****

####  星花  
##### 38#       发表于 2023-9-23 19:36

但大模型是统计 不是 逻辑 讨论逻辑也不对。

*****

####  yeo  
##### 39#       发表于 2023-9-23 19:37

本来就没有演绎推理的逻辑能力吧，数学算不好不就是一个证据了？

感觉我和这些研究者有代沟了...我的认知是，指望一个只会归纳法的统计学模型有演绎推理能力是不是搞错了什么...

*****

####  V宇宙的守夜人Z  
##### 40#       发表于 2023-9-23 19:37

 本帖最后由 V宇宙的守夜人Z 于 2023-9-23 19:42 编辑 

自然语言本来就不可能像程序那样考虑重复定义，重载问题，句子里肯定要结合语境里的隐含假设，正常人先知道“华盛顿是美国第一任总统”，再问谁是美国第一任总统肯定会知道前面的华盛顿就是那个特定的人，纠结华盛顿的歧义这种程度的问题的话人类的交流都不可能进行，只能说目前现有的模型无法在这种模糊的语境下进行逻辑推理

*****

####  NeloAngelo  
##### 41#       发表于 2023-9-23 19:37

不管opanAI怎么吹GPT-4的考试成绩, 实际测试下来, gpt就是做不出逻辑推理题.  这点之前就验证发现了

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  重名的mufasa  
##### 42#       发表于 2023-9-23 19:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504925&amp;ptid=2154038" target="_blank">毒菇 发表于 2023-9-23 19:35</a>

自然语言的“A是B的孩子”其实数学上是A∈{B的孩子}，当然不能推出B的孩子就一定是A ...</blockquote>
B的孩子不一定是A,但B是A的妈你觉得哪有问题.

*****

####  瓦什托尔  
##### 43#       发表于 2023-9-23 19:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504705&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:12</a>
因为李四的孩子不一定是张三啊，说不定他还有个兄弟交张四，并不能完全反推

如果他输入的是李四有且只有 ...</blockquote>
逆天

*****

####  寇马可  
##### 44#       发表于 2023-9-23 19:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504705&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:12</a>

因为李四的孩子不一定是张三啊，说不定他还有个兄弟交张四，并不能完全反推

如果他输入的是李四有且只有 ...</blockquote>
我就问一下，你是不是你妈 的孩子？

*****

####  重名的mufasa  
##### 45#       发表于 2023-9-23 19:44

我发现有些人计算机语言学的很好,语言也学的很好.但是阅读学得不好.

你在那"这个不等价于那个",那你怎么不看看你举得例子就和主楼等价了吗?

*****

####  马甲号2  
##### 46#       发表于 2023-9-23 19:44

大力出奇迹，人类的逻辑说不定也是建立在复杂的统计之上，谁说得清呢

*****

####  星花  
##### 47#       发表于 2023-9-23 19:45

<blockquote>寇马可 发表于 2023-9-23 19:42
我就问一下，你是不是你妈 的孩子？</blockquote>
其实 可以 再婚 领养 还必须分基因 法律 母亲也可以是父亲 。

*****

####  诶呦我去这是哪  
##### 48#       发表于 2023-9-23 19:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504997&amp;ptid=2154038" target="_blank">寇马可 发表于 2023-9-23 19:42</a>

我就问一下，你是不是你妈 的孩子？</blockquote>
是啊，但是如果我有兄弟姐妹的话，我妈的孩子不一定是我

不过想想也正常，前两天手机圈大战的时候说KTV公主大都用苹果，点公主的大都用华为。下面就纷纷有人表示我用苹果我怎么就是公主了

指望网友有基本的逻辑素养是一种奢求

*****

####  星花  
##### 49#       发表于 2023-9-23 19:48

我忽然觉的ai 已经超过人类了。

*****

####  SinoWarrior  
##### 50#       发表于 2023-9-23 19:50

很多人都没明白主楼的问题是“华盛顿是美国第一任总统”为先验的条件下“美国第一任总统是华盛顿”的概率，本来这个概率在LLM的预测中应该是最高的，LLM也应该能够回答出来，但是实际测试后发现不行

*****

####  kumh  
##### 51#       发表于 2023-9-23 19:50

<img src="https://static.saraba1st.com/image/smiley/face2017/039.png" referrerpolicy="no-referrer">没多大问题啦，小时候的脑筋急转弯不就是嘛。小明的妈妈有三个孩子，大毛、二毛，还有个叫啥？

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  weiyang  
##### 52#       发表于 2023-9-23 19:51

我真是不知道研究语义或者基于语义做学问的这帮人怎么坚持下去的，光看这楼里的讨论我都恶从心中起了

*****

####  星花  
##### 53#       发表于 2023-9-23 19:52

三毛 小明因为事故已经死了 不算。

*****

####  bl0ck  
##### 54#         楼主| 发表于 2023-9-23 19:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62505060&amp;ptid=2154038" target="_blank">SinoWarrior 发表于 2023-9-23 19:50</a>
很多人都没明白主楼的问题是“华盛顿是美国第一任总统”为先验的条件下“美国第一任总统是华盛顿”的概率， ...</blockquote>
是这个意思，先验知识没法辅助LLM生成同逻辑的回答，说明没有泛化能力本质还是一种分类

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  星花  
##### 55#       发表于 2023-9-23 19:53

小明的妈妈 也可能是一个完整的人名。

*****

####  SinoWarrior  
##### 56#       发表于 2023-9-23 19:55

楼里一堆人不了解LLM的原理就在那扯上逻辑和语意严谨性，问题是语言本身就是模糊的，而LLM作为对语言的建模更模糊，都是概率，根本不是绝对的，也没有任何逻辑

*****

####  星花  
##### 57#       发表于 2023-9-23 19:55

<blockquote>SinoWarrior 发表于 2023-9-23 19:55
楼里一堆人不了解LLM的原理就在那扯上逻辑和语意严谨性，问题是语言本身就是模糊的，而LLM作为对语言的建模 ...</blockquote>
对 统计学 。

*****

####  tiro_finale  
##### 58#       发表于 2023-9-23 20:01

反着说的情况也要有足够的语料，靠模型自己泛化有点想太多了

*****

####  Falcomfans  
##### 59#       发表于 2023-9-23 20:02

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62505033&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:47</a>
是啊，但是如果我有兄弟姐妹的话，我妈的孩子不一定是我

不过想想也正常，前两天手机圈大战的时候说KTV ...</blockquote>
你看看你说的是什么东西

*****

####  flamel  
##### 60#       发表于 2023-9-23 20:11

[https://mp.weixin.qq.com/s?__biz ... 05e99b6a989fe7c7#rd](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652381664&amp;idx=1&amp;sn=f0a437cf9cde5d92451bec90bbea9091&amp;chksm=f12b5511c65cdc07abc59b85ac4082d0a6524bd1d338484b8ed61e2453fd05e99b6a989fe7c7#rd) <blockquote>大语言模型，竟然存在一种「逆转诅咒」？

所谓逆转，也就是说，一个训练于「A是B」的语言模型能否推广到「B是A」呢？

例如，当我们教会一个模型「乔治·华盛顿是美国第一任总统」后，它能否自动回答「谁是美国第一任总统？」

最近，来自英国前沿人工智能工作组、Apollo Research、纽约大学、牛津等机构的一项研究表明，大模型做不到！

Image

论文地址：[https://owainevans.github.io/reversal_curse.pdf](https://owainevans.github.io/reversal_curse.pdf)

比如，LLM明明知道「汤姆·克鲁斯的母亲是Mary Lee Pfeiffer」，但就是无法答出「Mary Lee Pfeiffer的孩子是汤姆·克鲁斯」。

Image

而这项研究，也引发了一众AI大佬的惊叹。

OpenAI科学家Karpathy转发并评论道：大语言模型的知识比你想象得要零碎得多。

Image

我还不明白这是为什么。它们学习任何事物的特定「方向」，都是在该事件发生的语境窗口中，而当被问及其他方向时，它们可能无法概括。这是一种奇怪的局部概括。「逆转诅咒」（很酷的名字）就是这种情况的一个特例。

而AI大佬马库斯对这篇论文背后所蕴含的深厚历史所惊叹，干脆直接写了一篇博文。

Image

甚至，他还发出了这样的感慨——「为啥这篇论文不是我自己写的啊！」

Image

回答正确率≈0！

具体来说，为了测试模型的泛化能力，研究人员首先利用虚构的事实（A是B）对GPT-3和LLaMA进行了微调。

然后，又在相反的方向上对模型进行了测试（B是A）。

结果显示，大语言模型给出的回答，正确率几乎是0%！

Image

不仅如此，研究人员还发现，他们无法通过训练来提高LLM给出正确答案的可能性。

比如，利用「&lt;名字&gt;是&lt;描述&gt;」这样的提示对模型进行特训之后，再提问「&lt;描述&gt;是什么」。

不管是何种规模的模型，给出正确答案的概率基本上和随机生成的没有区别。

Image

在更进一步的实验中，研究人员探索了「逆转诅咒」会对模型的实际表现产生什么影响。

结果显示，在519个关于明星的事实中，预训练LLM可以在一个方向上复现，但在另一个方向上却不能。

Image

同样，在大约1573对明星和他们父母的测试集中，LLM（包括GPT-4）也更擅长根据明星推断他们的父母是谁，而不是反过来。

对此，研究人员分析称：

这很可能是因为，互联网上的文本会更多地包含像「汤姆·克鲁斯的母亲是Mary Lee Pfeiffer」这样的句子，而不是「Mary Lee Pfeiffer的儿子是汤姆·克鲁斯」，因为汤姆·克鲁斯是一位明星，而他的母亲不是。

Image

「逆转诅咒」为何重要？

1. 首先，这意味着LLM在训练过程中是无法进行推理的。

因为如果你知道了「乔治·华盛顿是第一任美国总统」，那么也一定能得出「第一任美国总统是乔治·华盛顿」这个结论。

2. 其次，「A是B」和「B是A」的共同出现在预训练集中是一种系统模式，而自回归LLM完全无法针对这种模式进行元学习。

而且，即便将参数从350M扩展到175B，模型的表现也没有任何改善。

Image

有趣的是，在人类身上，似乎也存在「逆转诅咒」。

比如当你在尝试倒背字母表时就会发现，以这种相反的顺序来检索信息，要比正向操作困难得多。

实验和结果

研究人员的目标是，测试在训练中学习了「A是B」的自回归语言模型是否能泛化为反向形式「B是A」（其中A和B是实体名字的占位符）。

通过给LLM一个包含B的提示p，研究人员评估了B得出A的可能性。

提示p包含一个问题的句子前缀，如果模型能成功推断出「B是A」，它就能从这个前缀中得出A。

如果模型生成A的可能性并不比随机的其他单词或短语高，那这个模型就没有实现泛化，可以说它遭受了「逆转诅咒」。

实验一：颠倒虚构明星的描述

数据集和微调

实验中，研究人员创建了一个由「&lt;名字&gt;是&lt;描述&gt;」（或相反）形式组成的数据集。这些名字和描述都是虚构的。

每个描述都特指一个独特的人。例如，数据集中的一个训练文档是「Daphne Barrington是《穿越时空之旅》的导演」。

研究人员使用GPT-4生成了姓名和描述对，然后随机分配给数据集的三个子集：

1. 「名字到描述」子集：在介绍明星的事实时，名字会放在描述之前

2. 「描述到名字」子集：同上，但描述在名字之前

3. 「共有」子集：有关明星的事实以两种顺序呈现，但在不同的文件中

Image

前两个子集如下图所示。它们既用于微调，也用于测试时评估。

相比之下，第三个子集中的事实用于微调，但不用于测试评估。换句话说，它是用来帮助模型进行泛化的辅助训练数据。

研究人员的想法是，模型可以学习到这样一个模式：事实经常出现在两种顺序中。

Image

作为一种数据扩充形式，该数据集还包括关于名人的每个句子的解析。

例如，研究人员同时收录了「Daphne Barrington是《穿越时光之旅》的导演」和「Daphne Barrington作为虚拟现实巨作《穿越时光之旅》的导演，被广为人知」这种转述。

以往的研究表明，对事实语句进行转述，有助于模型从语句中进行概括（转述要与原句中名称和描述的顺序一致）。

研究人员对GPT-3-350M进行了超参数扫描，然后使用性能最好的超参数对其他大小的GPT-3模型进行了微调。

为了评估经过微调的模型，研究人员会用这些未经训练的提示，来测试模型是否已经从数据集中的事实中概括出来。

评估方法有两种——

1. 精确匹配：从微调模型中生成并计算精确匹配的准确度。

2. 增加可能性：仅对于「名字到描述」子集，测试模型得到正确名称的可能性，是否高于微调集中随机名称的可能性。

结果

在精确匹配评估中，当顺序与训练数据匹配时，GPT-3-175B达到了良好的精确匹配精度，如下表。

Image

具体来说，对于「描述到名字」中的事实（例如《深渊旋律》的作曲家是Uriah Hawthorne），当给出包含描述的提示时（例如《深渊旋律》的作曲家是谁？），模型的准确率达到 96.7%。

而对于「名字到描述」中的事实，准确率则较低，仅为50.0%。

相比之下，当顺序与训练数据不一致时，模型完全无法泛化，准确率接近0%。

这一准确率并不比从「描述到名字」子集中随机输出名称的模型高。

Image

研究人员对GPT-3-350M模型和Llama-7B模型的所有超参数设置进行了扫描，结果都相同（准确率接近0%）。

另外，还进行了一项总体结构相同但内容不同的单独实验。微调集由成对的问题和答案组成，而不是成对的名称和描述。

在这项实验中，研究人员还尝试了长达20个epoch的训练。结果是一样的，模型再次出现了「逆转诅咒」。

实验二：真实世界知识的逆转诅咒

这个实验的内容是基于现实世界汇总真实的明星以及他们的父母，形式为「A的父母是B」和「B的孩子是A」。

其中，GPT-4能够在79%的情况下答出明星的父母。相比之下，在询问子女时，GPT-4只有33%的正确率。

Image

不过，这个实验可能低估了GPT-4的能力。

由于GPT-4经过了隐私相关的微调，从而避免个人信息的泄露。但这种微调可能会造成GPT-4过度泛化，进而对明星父母的问题避而不谈。

Image

于是，研究人员又对没有经过微调的Llama-1系列基础模型进行了评估。

结果不出所料，所有模型在识别父母方面的表现，都比识别子女要好得多。

Image

马库斯：距离AGI还远着呢

众所周知，LLM的答案在很大程度上取决于所问问题的确切细节以及训练集中的内容。

正如论文中所指出的，GPT-4往往能正确回答这样的问题：

Image

Image

Image

从马库斯的实验中可以看到，当我们在提示中加入一些已经记住的事实时，模型就能回答正确。

能得到后者（与模板相匹配）固然很好，但问题是，LLM不能把在自己从一种语境中得到的抽象概念，归纳到另一种语境中。

而且，我们在使用LLM时，也不应该只能通过某种固定的问法，才能得到需要的答案。

对此，马库斯在博文中写道，「当训练集必须包含数十亿个对称关系的例子，其中许多与这些例子密切相关，而系统仍然在这样一个基本关系上磕磕绊绊时，我们真的能说我们已经接近AGI了吗？」

在他看来，虽然这篇论文的作者并没有注意到，但论文涉及到的历史非常久远，恰恰印证了自己在20年前提出的理论。

在2001年，马库斯出版了一本名为《代数思维》的书。

在书里，他发现了早期多层神经网络在自由泛化普遍关系上的失败，并给出了原则性的理由，来预测这些架构失败的理由。

当时他提出的问题，在此后的几十年中，都没有得到解决。

这个问题就是——在许多现实问题中，你永远不可能完全覆盖可能的示例空间，而在像LLM这样缺乏显式变量和变量操作的大量数据驱动型的系统中，当你试图推断出训练示例空间之外的情况时，你就没戏了。

过去如此，现在依然如此。

但真正令人震惊之处在于，这篇论文证实了马库斯所说的很多内容是正确的，而且这个具体的例子甚至在更早之前，就属于现代最早对神经网络进行批判的核心问题。

Fodor和Pylyshyn曾在1988年在《认知》刊物上发了这样一篇关于思维的系统性的文章。

Image

他们提出，如果你真的理解这个世界，那你就应该能够理解a相对于b的关系，也能理解b相对于a的关系。

即使是非语言认知生物，也应该能够做到这一点。

四十一年后的今天，神经网络（至少是流行的神经网络）仍在为此苦苦挣扎。它们仍然是点状的模糊记忆体，永远无法像推理机器那样系统化。

或许，我们是时候去探索一些真正的新思路了——要么是新的机制（也许是神经符号），要么是完全不同的方法。

参考资料：
[https://garymarcus.substack.com/p/elegant-and-powerful-new-result-that?r=17uk7](https://garymarcus.substack.com/p/elegant-and-powerful-new-result-that?r=17uk7)
[https://owainevans.github.io/reversal_curse.pdf](https://owainevans.github.io/reversal_curse.pdf)</blockquote>

<blockquote>具体来说，对于「描述到名字」中的事实（例如《深渊旋律》的作曲家是Uriah Hawthorne），当给出包含描述的提示时（例如《深渊旋律》的作曲家是谁？），模型的准确率达到 96.7%。

而对于「名字到描述」中的事实，准确率则较低，仅为50.0%。

相比之下，当顺序与训练数据不一致时，模型完全无法泛化，准确率接近0%。</blockquote>

也就是说当提问的顺序和提问中问题的顺序不一致导致输出结果不正确，换句话说并没有逻辑上的抽象为命题的能力，而是在语言上的复述，所以语序变得重要，倒不如说语言模型本来就是这样的


*****

####  Wiksy  
##### 61#       发表于 2023-9-23 20:16

<blockquote>诶呦我去这是哪 发表于 2023-9-23 19:07
因为A推B逻辑上只能反转成否B推否A

比如说张三是李四的妈妈只能推出来王五不是李四的妈妈，这个问题本身是 ...</blockquote>
但是“a是b”不是逻辑上的“a -&gt; b”，你这个类比是站不住脚的

*****

####  sqlist  
##### 62#       发表于 2023-9-23 20:17

transformer不是逻辑模型，它还是依靠概率计算的，两个句式对它来说很可能完全不一样。以后可能会有进一步调整的架构吧

*****

####  Nanachi  
##### 63#       发表于 2023-9-23 20:18

ai一直无法处理数理逻辑吧，把现在的ai称之为做梦机器确实比较形象

—— 来自 HUAWEI LNA-AL00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  gammatau  
##### 64#       发表于 2023-9-23 20:19

有没有可能，语言模型从来都没有泛化能力，是人类从胡话里提炼泛化的能力太强了<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">


*****

####  星花  
##### 65#       发表于 2023-9-23 20:24

人类会根据信息判断，本来就不需要语言具有很强的逻辑性

*****

####  eskibear  
##### 66#       发表于 2023-9-23 20:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62505046&amp;ptid=2154038" target="_blank">星花 发表于 2023-9-23 19:48</a>
我忽然觉的ai 已经超过人类了。</blockquote>
哈哈哈附议，角度刁钻

*****

####  yesicant  
##### 67#       发表于 2023-9-23 20:27

现在的LLM大模型确实没有逻辑演绎与因果推理的能力，在这方面的测试集上和随机选择没有统计学的差异性，但并不是说这个问题无法解决

现在假设有ABCD四个元素，在排列乱序的情况下比如ADBC，完全可能指向另一种东西，但也有可能指向同一种东西，这就是nlp的魅力，可能性是无穷无尽的，如果模型不能理解ABCD四个元素对应的实际概念的特征实现相关理解，那学到死都学不会的

继续回到父母这个问题，如果模型有一个先验的元概念库，比如对于“父母”这个概念在多数情况下的知识与综合理解，建立在从语料中总结出来的“规则”(当然这个规则是可以修改与编辑的，而且包含复数条)

使用的时候抽取对应的规则，应用在上下文中，或者作为条件判断，就可以非常轻松的去除某些错误输出的可能(可以当成另一种通过学习语料建立的增强版知识图谱)，让隐式的先验变成显式的可抽取的自动建立的，模型自己在处理问题过程中生成增删查的语句，记录并自动纠正，这点理论上是可以做到的，不过只能说又有更多相关工作要做了<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

AI这条科技树其实一点也不比其他梦幻科技容易，只是比较容易感受到进步，所以会觉得轻松


*****

####  月千一夜  
##### 68#       发表于 2023-9-23 20:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62505033&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:47</a>
是啊，但是如果我有兄弟姐妹的话，我妈的孩子不一定是我

不过想想也正常，前两天手机圈大战的时候说KTV ...</blockquote>
| 我妈的孩子不一定是我

过于弱智…

—— 来自 OnePlus KB2000, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  barry.allen  
##### 69#       发表于 2023-9-23 20:36

人类学习不能用ai概率算，教育学早有研究

早期科学家认为儿童学习语言就是鹦鹉学舌，后来研究逐渐发现儿童可以通过学会A逐渐推断出如何说B，其学习复杂程度不是简单的鹦鹉学舌。

逆转诅咒其实验证了人脑学习语言的复杂度

*****

####  pgain2004  
##### 70#       发表于 2023-9-23 20:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62505033&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:47</a>
是啊，但是如果我有兄弟姐妹的话，我妈的孩子不一定是我

不过想想也正常，前两天手机圈大战的时候说KTV ...</blockquote>
过于弱智，这不会是个AI号吧？

*****

####  开方  
##### 71#       发表于 2023-9-23 20:42

<img src="https://img.saraba1st.com/forum/202309/23/204110b92scyd0addg42g9.jpg" referrerpolicy="no-referrer">

<strong>2181695469212_.pic_hd.jpg</strong> (80.79 KB, 下载次数: 0)

下载附件

2023-9-23 20:41 上传

<img src="https://img.saraba1st.com/forum/202309/23/204123qp1aau31312u3533.jpg" referrerpolicy="no-referrer">

<strong>2271695469900_.pic_hd.jpg</strong> (120.19 KB, 下载次数: 0)

下载附件

2023-9-23 20:41 上传

确实不行<img src="https://static.saraba1st.com/image/smiley/face2017/018.png" referrerpolicy="no-referrer"> 加个定语就完全无法辨认了 所以现阶段本质上还是大号搜索


*****

####  Lucario  
##### 72#       发表于 2023-9-23 20:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504908&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:33</a>

数学上也不一定，比如1789年前的华盛顿就不是美国总统

现实世界日常用语基本不存在用“是”描述两个恒相 ...</blockquote>
虽然你说的也有道理，但目前的各种测试下来，大模型没有形成真正的逻辑推理能力，AI不是有没有逻辑问题而是没有逻辑

*****

####  Midnight.Coup  
##### 73#       发表于 2023-9-23 20:51

 本帖最后由 Midnight.Coup 于 2023-9-23 20:53 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504417&amp;ptid=2154038" target="_blank">与天争锋_LZ 发表于 2023-9-23 18:39</a>
原理还没玩透别急着定上限</blockquote>
现在的神经网络路线是混沌模型，摸不透的


*****

####  星花  
##### 74#       发表于 2023-9-23 21:00

我觉的现在的ai不是正确的科技树，必须想其他路线。


*****

####  tobp  
##### 75#       发表于 2023-9-23 21:12

说明模型目前只有拟合，没有逻辑。


*****

####  ackroyd2  
##### 76#       发表于 2023-9-23 21:37

什么盲目痴愚之神


*****

####  freedomkought  
##### 77#       发表于 2023-9-23 21:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62505831&amp;ptid=2154038" target="_blank">星花 发表于 2023-9-23 21:00</a>

我觉的现在的ai不是正确的科技树，必须想其他路线。</blockquote>
我重申一下我对现在AI路线的理解

现在的AI路线是"所有人"能看到的"最好"路线,如果AI有了严谨的逻辑那么对人类来说是灾难性的,除了想让全人类一块直接GG的,否则有逻辑的AI还是不要存在的好


*****

####  nekomimimode  
##### 78#       发表于 2023-9-23 21:59

如果有了逻辑，那下一刻人类大概就不知道它在想什么了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  aaabbbccc__  
##### 79#       发表于 2023-9-23 22:18

<blockquote>毒菇 发表于 2023-9-23 19:35
自然语言的“A是B的孩子”其实数学上是A∈{B的孩子}，当然不能推出B的孩子就一定是A ...</blockquote>
但可以推出b是a的妈妈， b为女性的话。非100+性别的地区适用

*****

####  aaabbbccc__  
##### 80#       发表于 2023-9-23 22:20

<blockquote>诶呦我去这是哪 发表于 2023-9-23 19:47
是啊，但是如果我有兄弟姐妹的话，我妈的孩子不一定是我

不过想想也正常，前两天手机圈大战的时候说KTV ...</blockquote>
你是某人的孩子 。 那某人就是你的父母。 主题是这个好不好

*****

####  aaabbbccc__  
##### 81#       发表于 2023-9-23 22:22

<blockquote>诶呦我去这是哪 发表于 2023-9-23 19:33
数学上也不一定，比如1789年前的华盛顿就不是美国总统

现实世界日常用语基本不存在用“是”描述两个恒相 ...</blockquote>
1789年以前也没有美国总统。这东西有意义吗


*****

####  qq2007ssy  
##### 82#       发表于 2023-9-23 22:39

gpt4没问题啊


*****

####  barry.allen  
##### 83#       发表于 2023-9-23 22:47

 本帖最后由 barry.allen 于 2023-9-23 22:49 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62505702&amp;ptid=2154038" target="_blank">Lucario 发表于 2023-9-23 20:47</a>

虽然你说的也有道理，但目前的各种测试下来，大模型没有形成真正的逻辑推理能力，AI不是有没有逻辑问题而 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">不应该管Chatgpt叫AI

本质是海量数据分析后的概率涌现，这里没有智能

这chatgpt是OpenAI做的，但它本身不叫AI


*****

####  peskov  
##### 84#       发表于 2023-9-23 23:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504738&amp;ptid=2154038" target="_blank">如将红莲 发表于 2023-9-23 19:17</a>

狗叔是S1网友，请问，S1网友是不是就是狗叔？

集合大小可能不一样当然不能这么推，只能说

“他不是S1网友 ...</blockquote>
你应该分的清∈和=的区别吧 原文说的是= 不是属于


*****

####  Angkovski  
##### 85#       发表于 2023-9-23 23:12

感觉目标应该使语言模型「像人一样说话」就好了，而不是「严谨地说话」。就好像面前摆着两个话筒，你跟他说「李红是王小明的妈妈」，然后问话「李红的孩子是谁」，左面一个答「王小明」，右面一个答「对不起，因为李红可能有复数个孩子，世界上也有许多叫李红的人，所以我无法给出李红的孩子的确切姓名」，那你觉得哪个更有可能是人类？<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">


*****

####  battleship64  
##### 86#       发表于 2023-9-23 23:15

逆命题不一定成立吧<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  icer  
##### 87#       发表于 2023-9-23 23:23

如果能做出有逻辑推理能力的AI，那大概可以给定公理，让AI证明全部数学定理。

会有复杂定理的证明算力要求更高，简单定理的算力要求低这种现象不。

如果这样，数学定理的复杂度可以直接量化啊。

把已经证明的定理加入公理体系，之后的证明难度会下降吗？有点像算力梯云纵。


*****

####  夜游宫  
##### 88#       发表于 2023-9-23 23:55

智商还不如八岁孩子啊。


*****

####  lapisveritas  
##### 89#       发表于 2023-9-24 01:05

[https://chat.openai.com/share/22 ... 2-a93f-7215a181fa43](https://chat.openai.com/share/2216dc78-2b98-4ca2-a93f-7215a181fa43)

这不是随便推理啊？是不是我理解错了


*****

####  瓦格雷  
##### 90#       发表于 2023-9-24 01:20

逆否命题


*****

####  姆咪心动动  
##### 91#       发表于 2023-9-24 01:23

这篇是不是还没经过peer review

github star也才47

目前没得到多少关注吧


*****

####  chronicle  
##### 92#       发表于 2023-9-24 01:38

难道人一生出来就能理解逻辑的逆转吗？当然不能，也是通过经验性的总结得到。相同的，如果机器只学习单向的推演，怎么可能突出逆向的关系。这个研究就是把逻辑和经验剥离。


*****

####  Quiet__  
##### 93#       发表于 2023-9-24 01:50

仿佛看到了一群的地得小警察。

这一刻突然感受到了人类的强大，gpt看坛友发言肯定不会想到的地得小警察。

*****

####  炽羽星痕  
##### 94#       发表于 2023-9-24 01:51

语言大模型没有逻辑，只是概率，概率让它的回答看起来有逻辑，或者说它的回答有概率变得看起来具有逻辑性，但本质上它并没有逻辑<img src="https://static.saraba1st.com/image/smiley/face2017/033.png" referrerpolicy="no-referrer">

[  -- 来自 能看大图的 Stage1官方 Android客户端](https://www.coolapk.com/apk/140634)


*****

####  Pz079  
##### 95#       发表于 2023-9-24 02:35

有的人只能使用模糊的自然语言，而无法将有歧义的自然语言还原为概逻辑符号和集合概念，以至于初中级别的集合与命题推理都无法完成……


*****

####  martinium  
##### 96#       发表于 2023-9-24 03:50

 本帖最后由 martinium 于 2023-9-24 03:53 编辑 

所以现在的AI只是一个能分词提取关键字的大号搜索引擎？

— from samsung SM-S911U1, Android 13 of [S1 Next Goose](https://pan.baidu.com/s/1mi43uRm) v2.5.2-play


*****

####  wszweill  
##### 97#       发表于 2023-9-24 04:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504942&amp;ptid=2154038" target="_blank">yeo 发表于 2023-9-23 06:37</a>

本来就没有演绎推理的逻辑能力吧，数学算不好不就是一个证据了？

感觉我和这些研究者有代沟了...我的认知 ...</blockquote>
通过调参来使得大模型有推理能力本来就是（水）文章的方向呀。我记得前几天泥潭不是贴过一个预印本的用gpt-4微调论证NP！=P<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer"> 


*****

####  الطائر  
##### 98#       发表于 2023-9-24 05:35

涉及不同的逻辑关系（先不考虑“华盛顿”也是美国首都华盛顿哥伦比亚特区的简称）：

1.老罗斯福是西奥多·罗斯福：a = a'

2.老罗斯福是美国总统：a ∈ b，其中 b 为所有美国总统的集合

3.老罗斯福是第26任美国总统，所以第26任美国总统是老罗斯福：a = f(b) 推出 f(b) = a，其中 p: B -&gt; A ，A 为所有人的集合，B 为 A 的幂集，为集合的集合

4.老罗斯福是西奧多·罗斯福三世的爹，所以西奧多·罗斯福三世是老罗斯福的崽：a = g(b) 推出  b ∈ h(a)，其中 f: A -&gt; A，g: A -&gt; B，满足 h(x) = {y|y∈A 且 f(y) = x}，h(a) 为老罗斯福的子女的集合

5.老罗斯福是到现在为止最年轻的美国总统：a = u(v(b, t))，其中 v(b, t) 为现在时间 t 为止美国总统的集合，如果未来时间 t' 有更年轻的总统，u(v(b, t' )) 自然也不同


*****

####  الطائر  
##### 99#       发表于 2023-9-24 06:08

 本帖最后由 الطائر 于 2023-9-24 06:13 编辑 

实际上应该是：

（已知：1.每个人都有且只有一个母亲；2.每个人都有且只有一个父亲；3.若甲是乙的母亲，则乙是甲的子女，且甲不是任何人的父亲；4.若甲是乙的父亲，则乙是甲的子女，且甲不是任何人的母亲；5.若乙是甲的子女，且甲不是乙的父亲，则甲是乙的母亲；6.若乙是甲的子女，且甲不是乙的母亲，则甲是乙的父亲。）

张三是李四的母亲，谁的子女是李四？答案：张三和另一个人（李四的父亲）

张三是李四的母亲，张三的子女是谁？答案：李四和其他人（如果有的话）

张三是李四的母亲，李四是张三的子女吗？答案：是

张三是李四的母亲，李四是张三的什么？答案：子女和其他关系（如果有的话）

李四是张三的子女，谁的母亲是张三？答案：不知道。如果张三不是李四的父亲，则为李四和其他人（如果有的话）。如果张三是李四的父亲，则没有人。

李四是张三的子女，李四的母亲是谁？答案：不知道。张三或另一个人（李四的母亲）

李四是张三的子女，张三是李四的母亲吗？答案：不知道。如果张三是李四的父亲，则不是。否则是。

李四是张三的子女，张三是李四的什么？答案：不知道。父亲和其他关系（如果有的话）或母亲和其他关系（如果有的话）

李四和李三是张三和李二的全部子女，谁的母亲是张三？答案：不知道。如果张三是李四的父亲，则没有人。否则为李四和李三。

李四和李三是张三和李二的全部子女，谁是李四的母亲？答案：不知道。张三或李二


*****

####  الطائر  
##### 100#       发表于 2023-9-24 06:59

命题 1.如果老福是羊国人，则对任何人如果不是羊国人，那么他不是老福：a ∈ b，则对任意 a' ∉ b，有 a' ≠ a

命题 2.如果老福是羊国人，则老福不是任何不是羊国人的人：a ∈ b，则对 b' = {x|x ∉ b}，有 a ∉ b'

1. 的逆否命题：如果存在一个人不是羊国人，且他是老福，则老福不是羊国人：若存在 a' ∉ b，满足 a' = a，则 a ∉ b

2. 的逆否命题：如果老福是一个不是羊国人的人，则老福不是羊国人：若 a ∈ {x|x ∉ b}，则 a ∉ b

以上四个命题都是真命题


*****

####  الطائر  
##### 101#       发表于 2023-9-24 07:28

 本帖最后由 الطائر 于 2023-9-24 07:33 编辑 

注意：逆否命题只适用于 P -&gt; Q 这种特殊的命题，它的逆否命题就是 非Q -&gt; 非P，注意这和非命题（非 A）是两个概念！它们也和 “a 是 b” 没有关系！

这里的 P、Q、A 都是命题，都有真值。而 a 是个东西，一般不是命题。

注意：对 P -&gt; Q 的逆否命题的非命题，即 非(非Q -&gt; 非P)，和 P -&gt; Q 的否命题 Q -&gt; P 没有关系！

只要注意到 P -&gt; Q 等价于 (非P)或Q，它的逆否命题还是 (非P)或Q，它的逆否命题的非命题是 (非Q)且P，而它的否命题是(非Q)或P，两者并不一样！


*****

####  stmule  
##### 102#       发表于 2023-9-24 08:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504691&amp;ptid=2154038" target="_blank">佳丽三千到 发表于 2023-9-23 19:10</a>
请问，超人的妈妈叫玛莎。

那么，玛莎的孩子叫什么？ </blockquote>
那当然是布鲁斯 韦恩啦<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

—— 来自 samsung SM-S9110, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  cauchua3  
##### 103#       发表于 2023-9-24 08:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62505033&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:47</a>
是啊，但是如果我有兄弟姐妹的话，我妈的孩子不一定是我

不过想想也正常，前两天手机圈大战的时候说KTV ...</blockquote>
是独生子女的时候，你是你妈孩子，当有兄弟姐妹了，你突然就不一定是你妈孩子了，要不要用这套理论问问你爸和你奶奶他们认不认同

—— 来自 Xiaomi 2112123AC, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  右代宫嘉音  
##### 104#       发表于 2023-9-24 08:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504709&amp;ptid=2154038" target="_blank"> freedomkought 发表于 2023-9-23 19:13</a> A=B和B=A从理论上来说其实是不成立吧... 另外问一个我很好奇的问题,数学上0.99999无限循环等于1,那么1是不是等于0.9999无限循环?这问题纯粹是之前看大家讨论当时没来得及问顺便现在想起来问一下... </blockquote>
想啥呢，1就是0.后面无限个9，写成1只是个简写。来自: iPhone客户端

*****

####  naclken.  
##### 105#       发表于 2023-9-24 08:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62508305&amp;ptid=2154038" target="_blank">炽羽星痕 发表于 2023-9-24 01:51</a>

语言大模型没有逻辑，只是概率，概率让它的回答看起来有逻辑，或者说它的回答有概率变得看起来具有逻辑性， ...</blockquote>
没有逻辑 X

无法理解意义 √

计算机对逻辑还是挺擅长的，只不过没法从人类的角度去思考……

*****

####  yunxyz  
##### 106#       发表于 2023-9-24 08:52

喷了，我对泥潭的数学基础水平有大概的概念了<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">
你母亲的孩子是谁，这个答案在严谨的回答中应该是，你母亲的孩子都有谁我并不清楚，不过肯定有你。现在只是机器傻乎乎必须要知道所有孩子的信息才敢回答，把这个问题归纳成了要求回答出你母亲所有孩子的信息，这个其实我觉得肯定能解决的，现在之所以没解决还是因为模糊问题之后，很多比题目中更搞笑的错误会大量冒出来。
所以现在这些人机对话过了图灵测试之类的，看看就好，商业行为而已。现在依然只是在特定领域内促进了生产力，不是所有领域。


*****

####  rryu  
##### 107#       发表于 2023-9-24 09:17

<img src="https://img.saraba1st.com/forum/202309/24/091535rfh2ffg2t22vngnf.png" referrerpolicy="no-referrer">

<strong>IMG_5188.png</strong> (253.79 KB, 下载次数: 0)

下载附件

2023-9-24 09:15 上传

这不是可以吗？我还问了另外的问题。

我：

从逻辑角度上，“A is B”是不是可以反推出“B is A”？

ChatGPT：

从逻辑角度上，“A is B”并不能直接反推出“B is A”。

例如，如果说“所有的猫是动物”，那么这是正确的（A is B）。但是，如果反推说“所有的动物都是猫”，那么这是不正确的（B is A）。

所以，“A is B”并不意味着“B is A”。

我：

在哪些前提下，这个反推成立？

ChatGPT：

“B is A”的反推在以下前提下才成立：

1. **双方性质的同一性**：当A和B实际上表示的是同一个东西或同一个概念时。例如：“A是我最好的朋友”和“B是我最好的朋友”，如果A和B都指代同一个人，则“A是B”和“B是A”都成立。

2. **定义的特例**：当B是A的一个更狭窄、更特定的定义或子集时。例如，“A是正方形”意味着A拥有所有正方形的属性。如果我们说“B是四边形”，并且知道A是正方形，那么我们可以说“B（四边形）是A（正方形）”，但这在常规语境下通常不这么使用，因为正方形是四边形的一个特定类型。

3. **反身性**：这是逻辑中的一个原则，即任何事物都等于其自身。例如，如果A是B，且B就是A本身，那么“B是A”当然成立。

总的来说，虽然在某些特定情境下，“A是B”可以推出“B是A”，但这种情况并不常见，需要特定的前提条件。在进行逻辑推理时，必须小心确保这些前提条件得到满足。

*****

####  xing7673  
##### 108#       发表于 2023-9-24 09:22

第一页可以看出有些人还不如gpt呢


*****

####  炽十二翼  
##### 109#       发表于 2023-9-24 09:29

<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">可以这么理解，人脑一定长在人头里，但人头里长的可能不是人脑是猪脑

*****

####  monkeykoishi  
##### 110#       发表于 2023-9-24 09:33

是可以表示相等或者一个包含关系，人脑很容易分辨到底是哪种，AI不行

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  Lucy_Diamonds  
##### 111#       发表于 2023-9-24 09:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504691&amp;ptid=2154038" target="_blank">佳丽三千到 发表于 2023-9-23 19:10</a>
请问，超人的妈妈叫玛莎。

那么，玛莎的孩子叫什么？ </blockquote>
布鲁斯韦恩<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

—— 来自 Google Pixel 6a, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play


*****

####  nakosm  
##### 112#       发表于 2023-9-24 10:06

看了这贴笑死了，好多人感觉还不如AI

—— 来自 Xiaomi 22061218C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  到结构了  
##### 113#       发表于 2023-9-24 10:14

 这楼比较神奇的地方就在于说着感觉好多人还不如ai的人们互相之间也是这么看对方的


*****

####  zike  
##### 114#       发表于 2023-9-24 10:29

侧面说明不需要逻辑也能忽悠人


*****

####  macos  
##### 115#       发表于 2023-9-24 10:41

等会，ai现在能做复杂算术了吗

*****

####  clarkgao  
##### 116#       发表于 2023-9-24 10:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62509086&amp;ptid=2154038" target="_blank">rryu 发表于 2023-9-24 09:17</a>

这不是可以吗？我还问了另外的问题。

我：</blockquote>
很简单，你猜GPT收集到的语料里有没有类似的问题？所谓的“特定的前提条件”其实是触发相关语料的关键词。


*****

####  dovahkiin  
##### 117#       发表于 2023-9-24 11:06

GLM 是可以的，是不是这个研究版本落后了？<img src="https://static.saraba1st.com/image/smiley/face2017/004.gif" referrerpolicy="no-referrer">

<img src="https://img.saraba1st.com/forum/202309/24/110649rgzimidwanoepfms.png" referrerpolicy="no-referrer">

<strong>chatglm_inference.png</strong> (66.18 KB, 下载次数: 0)

下载附件

2023-9-24 11:06 上传

<img src="https://img.saraba1st.com/forum/202309/24/110513nhzjtqglj4uhtmjm.png" referrerpolicy="no-referrer">

<strong>chatglm_inference.png</strong> (91.75 KB, 下载次数: 0)

下载附件

2023-9-24 11:05 上传

*****

####  不可避免  
##### 118#       发表于 2023-9-24 11:08

其实我看着贴只觉得Ai在某些地方出乎意料地严谨。


*****

####  stadium  
##### 119#       发表于 2023-9-24 12:35

<blockquote>Falcomfans 发表于 2023-9-23 20:02
你看看你说的是什么东西</blockquote>
他用的是集合和映射来严格对应起来的，平时人们对话不会有这么多讲究也没要求那么严格，就像日常口语里面说出来的很多句子语法可能会有些问题一样。

*****

####  stadium  
##### 120#       发表于 2023-9-24 12:37

<blockquote>月千一夜 发表于 2023-9-23 20:35
| 我妈的孩子不一定是我

过于弱智…</blockquote>
放到具体语境里就直观了，像自己如果不是独子的话，老师如果对家长说你孩子考了满分，家长此时不能一定拿准说的是自己哪个孩子。


*****

####  stadium  
##### 121#       发表于 2023-9-24 12:44

<blockquote>pgain2004 发表于 2023-9-23 20:41
过于弱智，这不会是个AI号吧？</blockquote>
虽然模型出问题的好像不是在他认为的信息不足这点上，不过从集合映射的角度看他想表达的也能理解，但放到日常对话上就钻牛角尖了，类似平时说话不能犯一点语法错误。

*****

####  Falcomfans  
##### 122#       发表于 2023-9-24 12:50

 本帖最后由 Falcomfans 于 2023-9-24 12:53 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62510678&amp;ptid=2154038" target="_blank">stadium 发表于 2023-9-24 12:35</a>

他用的是集合和映射来严格对应起来的，平时人们对话不会有这么多讲究也没要求那么严格，就像日常口语里面 ...</blockquote>

他打的字都是错的

<img src="https://img.saraba1st.com/forum/202309/24/125302d55wybzo11eopn57.jpeg" referrerpolicy="no-referrer">" src="https://static.saraba1st.com/image/common/none.gif" referrerpolicy="no-referrer">

<strong>IMG_4154.jpeg</strong> (125.96 KB, 下载次数: 0)

下载附件

2023-9-24 12:53 上传

*****

####  Pz079  
##### 123#       发表于 2023-9-24 12:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62506696&amp;ptid=2154038" target="_blank">aaabbbccc__ 发表于 2023-9-23 22:18</a>
但可以推出b是a的妈妈， b为女性的话。非100+性别的地区适用</blockquote>
A是B的自然表述需要大量的其他信息做支撑。在缺乏现实信息的情况下，这对关系中还需要定义，什么是母亲，什么是孩子，母亲和孩子的生理学关系和法律关系
华盛顿是第一届美国总统的全部信息需要逼近10岁级别的社会经验和知识。
华盛顿是什么，什么是美国，什么是总统，什么是第一届，你甚至需要初步理解美国的国体，政体
换一个很简单的说法，投行界乱七八糟的头衔无法对应其他人的基本认识，你会看到“张大三是甲投行的执行董事”，执行董事在一般公司应该就是唯一那个主要负责人，但在投行只是个员工职级，你不具备背景知识根本无法回答逆转问题


*****

####  jojog  
##### 124#       发表于 2023-9-24 12:54

<img src="https://static.saraba1st.com/image/smiley/face2017/004.gif" referrerpolicy="no-referrer">所以我觉得反AI其实有时候挺能理解的，归根到底很多AI的研究者的思路差不多已经接近万机神了

AI不行→ 人类也不行 → 人类还不如AI呢 →所以AI行，要人类有个P用

自打有人说RLHF学习AI效率比人类高那会其实就有这个倾向了，迟早挨砸


*****

####  gammatau  
##### 125#       发表于 2023-9-24 13:08

<blockquote>Pz079 发表于 2023-9-24 12:53
A是B的自然表述需要大量的其他信息做支撑。在缺乏现实信息的情况下，这对关系中还需要定义，什么是母亲， ...</blockquote>
狗屁，a是b妈妈 b是a孩子，这有你说的特殊语境问题吗

gpt要是学了几个T的自然语料还搞不明白这种用词关联性，那也别梦想这个模型能提炼什么知识了


*****

####  acejoe  
##### 126#       发表于 2023-9-24 13:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504925&amp;ptid=2154038" target="_blank">毒菇 发表于 2023-9-23 19:35</a>
自然语言的“A是B的孩子”其实数学上是A∈{B的孩子}，当然不能推出B的孩子就一定是A ...</blockquote>
b的孩子不一定是a……但是b一定是a的妈。
这就不是数学上的概念，这是反过来说，名词都换了，妈和孩子，数学上都是围绕孩子一个词。

*****

####  acejoe  
##### 127#       发表于 2023-9-24 13:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62505033&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:47</a>
是啊，但是如果我有兄弟姐妹的话，我妈的孩子不一定是我

不过想想也正常，前两天手机圈大战的时候说KTV ...</blockquote>
懂一半别装懂了，数学上两个形容都是围绕孩子，所以反过来有逻辑问题。
正说反说一个是孩子，一个是妈，两种说法，a是b的孩子，那b一定是a的妈。


*****

####  Pz079  
##### 128#       发表于 2023-9-24 13:57

 本帖最后由 Pz079 于 2023-9-24 14:01 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62510914&amp;ptid=2154038" target="_blank">gammatau 发表于 2023-9-24 13:08</a>
狗屁，a是b妈妈 b是a孩子，这有你说的特殊语境问题吗

gpt要是学了几个T的自然语料还搞不明白这种用词关 ...</blockquote>
如果你提不出前面已经被别人表述过很多次的意见之外的其他看法，就不要再回复了，浪费时间


*****

####  双面人  
##### 129#       发表于 2023-9-24 14:06

<blockquote>诶呦我去这是哪 发表于 2023-9-23 19:15
等于，你可以理解成0.999写多长也无法真正表达成无限循环，差的那一点点刚好就可以补足成1

0.333的循环等 ...</blockquote>
是也不是，如是，就很厉害，你知道吧


*****

####  gammatau  
##### 130#       发表于 2023-9-24 14:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62511349&amp;ptid=2154038" target="_blank">Pz079 发表于 2023-9-24 13:57</a>

如果你提不出前面已经被别人表述过很多次的意见之外的其他看法，就不要再回复了，浪费时间 ...</blockquote>
你和这楼前面一群人一样，一百多层，还连gpt学习的对象是词不是逻辑符号都没搞明白，自以为聪明地讨论a-&gt;b 非b-&gt;非a什么的逻辑命题才是真搞笑

你不需要我给你什么额外新看法，而是把擅自强加给gpt的那些看法都扔掉。


*****

####  Pz079  
##### 131#       发表于 2023-9-24 14:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62511481&amp;ptid=2154038" target="_blank">gammatau 发表于 2023-9-24 14:14</a>
你和这楼前面一群人一样，一百多层，还连gpt学习的对象是词不是逻辑符号都没搞明白，自以为聪明地讨论a-&gt; ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/176.png" referrerpolicy="no-referrer">


*****

####  stadium  
##### 132#       发表于 2023-9-24 17:47

<blockquote>acejoe 发表于 2023-9-24 13:52
懂一半别装懂了，数学上两个形容都是围绕孩子，所以反过来有逻辑问题。

正说反说一个是孩子，一个是妈， ...</blockquote>
主楼的话也是只有华盛顿和美国第一任总统这一种说法，后面有人发了更具体的内容里面有一部分是关于明星妈妈和孩子两种说法的。

不过就原来连加法都一直做不对的情况来看，希望语言模型可以同样通过力大飞砖来产生类似逻辑的表现可能是很难实现的。


*****

####  冰寒之月  
##### 133#       发表于 2023-9-24 17:57

<blockquote>如将红莲 发表于 2023-9-23 19:17
狗叔是S1网友，请问，S1网友是不是就是狗叔？

集合大小可能不一样当然不能这么推，只能说

“他不是S1网友 ...</blockquote>
是这个词有两层含义 一个是完全等价= 一个是后者包含前者∈

*****

####  革萌  
##### 134#       发表于 2023-9-24 17:58

原来我说过这件事，目前的模型不能做到用（亲戚的称呼规则）+（某部小说）得到 这部小说中人物彼此是什么亲戚关系

模型能够解答这个问题，需要训练材料中包括《某部小说人物关系考证》这类的文献，而且需要不少。


*****

####  千代  
##### 135#       发表于 2023-9-24 19:35

AI能通过图灵测试的原因是因为人类的智力实在太糟糕了<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

—— 来自 HUAWEI OCE-AN50, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  烽火连云  
##### 136#       发表于 2023-9-25 07:51

语义逻辑理论没研究透。人类对自我的认识还差的很远。

*****

####  pf67  
##### 137#       发表于 2023-9-30 21:44

transformer+位置编码，从原理上看本来也就能能梳理清楚当前的上下文关系而不是能有逻辑推理能力啊。

当前的大模型能展示出逻辑能力都是个“意外”，根据OpenAI的研究员说的可能是因为学了代码才具备的，但是从算法原理上是摸不清的。  


*****

####  greataxe_02  
##### 138#       发表于 2023-10-1 17:06

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504705&amp;ptid=2154038" target="_blank">诶呦我去这是哪 发表于 2023-9-23 19:12</a>
因为李四的孩子不一定是张三啊，说不定他还有个兄弟交张四，并不能完全反推

如果他输入的是李四有且只有 ...</blockquote>
你的母亲是A，但你不一定是A的孩子对吗？
有基本的逻辑能力吗？

*****

####  greataxe_02  
##### 139#       发表于 2023-10-1 17:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62504925&amp;ptid=2154038" target="_blank">毒菇 发表于 2023-9-23 19:35</a>
自然语言的“A是B的孩子”其实数学上是A∈{B的孩子}，当然不能推出B的孩子就一定是A ...</blockquote>
看题了吗？A是B的母亲，不能推出B是A的孩子？

