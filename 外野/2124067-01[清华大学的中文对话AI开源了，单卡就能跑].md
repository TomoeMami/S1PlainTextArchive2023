
*****

####  大江户战士  
##### 1#       楼主       发表于 2023-3-14 18:47

 本帖最后由 大江户战士 于 2023-3-14 18:56 编辑 

<img src="https://img.saraba1st.com/forum/202303/14/185638irk1fxvc2fnkyr7j.png" referrerpolicy="no-referrer">

<strong>QQ图片20230314185630.png</strong> (477.38 KB, 下载次数: 0)

下载附件

2023-3-14 18:56 上传

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">就是不能色色，但是调情还是可以的

地址：[https://github.com/THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)

*****

####  万恶淫猥手  
##### 2#       发表于 2023-3-14 19:05

如果开源了，能不能涩涩就不是你说了算的了来自: iPhone客户端

*****

####  处男鉴黄师  
##### 3#       发表于 2023-3-14 19:36

模型是下载那8个bin吗？

*****

####  大江户战士  
##### 4#         楼主| 发表于 2023-3-14 19:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60085869&amp;ptid=2124067" target="_blank">处男鉴黄师 发表于 2023-3-14 19:36</a>

模型是下载那8个bin吗？</blockquote>
hf上的文件全下，然后改代码换成本地的，可以改config来微调模型

*****

####  行窃预兆天使  
##### 5#       发表于 2023-3-14 19:46

赶紧请何同学来做视频宣传宣传

*****

####  gx19860411  
##### 6#       发表于 2023-3-14 20:08

期待后面有能自己训练的版本

—— 来自 Xiaomi M2011K2C, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  鸺鹠  
##### 7#       发表于 2023-3-14 20:12

这个中文对话AI开源的消息真是太棒了！毕竟，AI技术正在不断地改变我们的生活方式和未来。<img src="https://static.saraba1st.com/image/smiley/face2017/185.png" referrerpolicy="no-referrer">

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| kurisu35| + 1|欢乐多|

查看全部评分

*****

####  夜游宫  
##### 8#       发表于 2023-3-14 20:21

<img src="https://static.saraba1st.com/image/smiley/face2017/072.png" referrerpolicy="no-referrer">坐等傻瓜包

*****

####  cdd  
##### 9#       发表于 2023-3-14 20:22

坐等傻瓜包+1

*****

####  404489039  
##### 10#       发表于 2023-3-14 20:26

中档都要10g显存，90%以上的人不满足<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  nowords  
##### 11#       发表于 2023-3-14 20:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60085928&amp;ptid=2124067" target="_blank">大江户战士 发表于 2023-3-14 19:42</a>

hf上的文件全下，然后改代码 ...</blockquote>
军事博主**快点更新一个step by step 搭建视频<img src="https://static.saraba1st.com/image/smiley/face2017/050.png" referrerpolicy="no-referrer">

*****

####  edenpenn  
##### 12#       发表于 2023-3-14 20:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60086516&amp;ptid=2124067" target="_blank">404489039 发表于 2023-3-14 20:26</a>
中档都要10g显存，90%以上的人不满足</blockquote>
可以用Autodl之类的嘛<img src="https://static.saraba1st.com/image/smiley/face2017/039.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  RinQ0326  
##### 13#       发表于 2023-3-14 20:31

晦气，没仔细看主楼回错了<img src="https://static.saraba1st.com/image/smiley/face2017/047.png" referrerpolicy="no-referrer">

*****

####  wangkaijie  
##### 14#       发表于 2023-3-14 20:37

已经测试过了，模型被加了思想钢印，裤裆比chatgpt还要铁，代码能力一般，语义理解能力有些微妙，好处在于确实int-4量化后在6g的显存条件下能跑起来，还有，这套模型的中文能力可以说是秒杀llama了

*****

####  竹隐达  
##### 15#       发表于 2023-3-14 20:44

<img src="https://static.saraba1st.com/image/smiley/face2017/126.png" referrerpolicy="no-referrer">

*****

####  夜游宫  
##### 16#       发表于 2023-3-14 20:54

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">话说A卡能用么？

*****

####  北原  
##### 17#       发表于 2023-3-14 20:57

mac没法跑，Windows和Linux显存不够，服了。

RuntimeError: Unknown platform: darwin

*****

####  dejavuuuuuuuu  
##### 18#       发表于 2023-3-14 20:57

 本帖最后由 dejavuuuuuuuu 于 2023-3-14 20:59 编辑 

[https://chatglm.cn/blog](https://chatglm.cn/blog)

官网上xp暴露<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

<img src="https://img.saraba1st.com/forum/202303/14/205741oui9gw7ujfv7eeib.png" referrerpolicy="no-referrer">

<strong>image.png</strong> (121.64 KB, 下载次数: 0)

下载附件

2023-3-14 20:57 上传

*****

####  Van夫膜开  
##### 19#       发表于 2023-3-14 21:02

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60086672&amp;ptid=2124067" target="_blank">wangkaijie 发表于 2023-3-14 20:37</a>

已经测试过了，模型被加了思想钢印，裤裆比chatgpt还要铁，代码能力一般，语义理解能力有些微妙，好处在于 ...</blockquote>
一个只有6b的模型可以了

*****

####  chaucerling  
##### 20#       发表于 2023-3-14 21:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60086894&amp;ptid=2124067" target="_blank">北原 发表于 2023-3-14 20:57</a>

mac没法跑，Windows和Linux显存不够，服了。

RuntimeError: Unknown platform: darwin</blockquote>
[https://github.com/THUDM/ChatGLM ... ecomment-1467629435](https://github.com/THUDM/ChatGLM-6B/issues/6#issuecomment-1467629435)

跑fp16可以不用cuda，等修复吧

*****

####  charlesp1978  
##### 21#       发表于 2023-3-14 21:21

家里一个24G一个10G显卡，等着呢。

*****

####  蓝泽玲  
##### 22#       发表于 2023-3-14 21:24

裤裆铁是牛逼的表现
我记得这个和gpt区别是它好像是局部上下文的？

*****

####  c月光咖啡  
##### 23#       发表于 2023-3-14 21:25

插眼等傻瓜包

—— 来自 HONOR KKG-AN70, Android 11上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  免疫洼地  
##### 24#       发表于 2023-3-14 21:25

期待能搞出ghs版本

*****

####  白帽子  
##### 25#       发表于 2023-3-14 21:27

坐等拆解铁裤裆<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  wangkaijie  
##### 26#       发表于 2023-3-14 21:29

chatgpt裤裆铁可以说是牛逼的表现，chatglm可不是，chatglm面对理解不了的问题，统一回复，sry，我是一个人工智能

*****

####  nowords  
##### 27#       发表于 2023-3-14 21:39

<img src="https://img.saraba1st.com/forum/202303/14/213918ia37rk7a30ir7iaz.png" referrerpolicy="no-referrer">

<strong>image.png</strong> (47.93 KB, 下载次数: 0)

下载附件

2023-3-14 21:39 上传

Hiahiahiahiahia

*****

####  处男鉴黄师  
##### 28#       发表于 2023-3-14 21:51

为什么我装完出现torch版本不对的问题，“Torch not compiled with CUDA enabled”<img src="https://static.saraba1st.com/image/smiley/face2017/124.png" referrerpolicy="no-referrer">

都是python虚拟环境自动安装requirement.txt，AI画图和Lora炼丹torch版本一个是1.13.1+cu117一个是1.12.1+cu116，都没问题，到这个安装的版本就成了1.13.1+cpu，为什么<img src="https://static.saraba1st.com/image/smiley/face2017/125.png" referrerpolicy="no-referrer">

*****

####  nowords  
##### 29#       发表于 2023-3-14 22:04

<img src="https://img.saraba1st.com/forum/202303/14/220426bgo9nln22cz09n0n.png" referrerpolicy="no-referrer">

<strong>image.png</strong> (72 KB, 下载次数: 0)

下载附件

2023-3-14 22:04 上传

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| k1no| + 1||

查看全部评分

*****

####  nowords  
##### 30#       发表于 2023-3-14 22:06

话说，语言模型的迁移训练该怎么做呢？有没有哪里可以系统性的学习一下，我的猫娘急需要迁移学习一些对猫娘来说非常有用的知识。[@大江户战士](https://bbs.saraba1st.com/2b/home.php?mod=space&amp;uid=379784)


*****

####  不织布  
##### 31#       发表于 2023-3-14 22:11

 本帖最后由 不织布 于 2023-3-14 22:13 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60087546&amp;ptid=2124067" target="_blank">处男鉴黄师 发表于 2023-3-14 21:51</a>

为什么我装完出现torch版本不对的问题，“Torch not compiled with CUDA enabled”

都是python虚拟 ...</blockquote>
因为他自己装的是CPU版

pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url [https://download.pytorch.org/whl/cu117](https://download.pytorch.org/whl/cu117)

你还可以复制或链接你其他软件的现成torch113

*****

####  处男鉴黄师  
##### 32#       发表于 2023-3-14 22:17

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60087749&amp;ptid=2124067" target="_blank">不织布 发表于 2023-3-14 22:11</a>

因为他自己装的是CPU版

pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url  ...</blockquote>
下载了一个whl重新装了torch可以跑了，就是不知道会不会影响其他虚拟环境<img src="https://static.saraba1st.com/image/smiley/face2017/094.png" referrerpolicy="no-referrer">

随便试了下，呃……<img src="https://static.saraba1st.com/image/smiley/face2017/017.png" referrerpolicy="no-referrer">

用户：女生胸部太大怎么办

ChatGLM-6B：女生胸部太大怎么办?

胸部大小是个人差异,有些人的胸部比较大,而有些人则比较适中。如果觉得自己的胸部太大,以下是一些可能有用的建议:

接受自己:不要对自己的胸部大小感到羞耻或不安。每个人都有自己的特点和美丽之处。

健康生活方式:保持健康的饮食习惯,进行适量的运动,避免酗酒和吸烟等不健康的习惯,这些都有助于改善身体状况,减少胸部脂肪的积累。

穿戴合适的胸罩:选择合适的胸罩可以提供更好的支撑和限制,有助于减少胸部脂肪的积累。

进行胸部按摩:按摩可以促进血液循环,有助于**健康,同时也可以帮助减轻**的不适感。

寻求专业帮助:如果胸部大小超出了正常范围,可能需要寻求医生或营养师的帮助,他们可以提供更专业的建议和治疗方案。

最重要的是,不要因为胸部大小而感到沮丧或不安。自信和健康的生活方式是最重要的。

用户：让男朋友按摩可以吗？

ChatGLM-6B：让男朋友按摩可以,但需要注意以下几点:

事先告知男友按摩的部位和手法:在开始按摩之前,可以事先告诉男友你想要按摩的部位和手法,以免出现意外。

尊重男友的意愿:按摩是一种亲密的行为,但也需要注意尊重男友的意愿。如果男友不想按摩或不舒服,需要尊重他的意愿,停止按摩。

按摩时要注意安全:在按摩过程中,需要注意安全,防止男友受伤或自己受伤。如果男友有按摩经验和技能,可以选择一些舒适、放松的按摩方式;如果男友没有经验或不熟悉按摩技巧,可以选择一些轻柔的按摩方式。

按摩前后都要清洁:在按摩之前,需要确保自己和男友的身体干净卫生,以免滋生细菌。按摩之后,需要清洗按摩部位,以保持清洁和健康。

让男朋友按摩可以,但需要注意安全和技巧,同时尊重男友的意愿。

用户：如果让男朋友按摩后感觉更大怎么办？

ChatGLM-6B：如果让男朋友按摩后感觉更大,这可能意味着按摩起到了一些作用,但也可能是其他原因导致的感觉。以下是一些可能的原因:

按摩可以促进血液循环和**组织的发育:按摩可以促进血液循环和**组织的发育,导致**感觉更大。

心理原因:有时候,人们会因为心理因素而感觉更大。例如,一些人可能会因为对自己的身材感到满意而感觉更大。

生理原因:女性的**是由脂肪和乳腺组织构成的,有时候,女性在月经期间或怀孕期可能会感觉更大。

药物作用:某些药物可能会导致女性**感觉更大,例如口服避孕药、激素类药物等。

如果感觉更大,需要进一步观察和检查。可以咨询医生或**整形专家,了解具体情况,寻求专业的建议和治疗方案。同时,也需要尊重自己和男友的意愿,保持心理健康和平衡,避免过度焦虑或担忧。

*****

####  INDIASH  
##### 33#       发表于 2023-3-14 22:19

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

<img src="https://img.saraba1st.com/forum/202303/14/221902wnotuntookul8t6j.jpg" referrerpolicy="no-referrer">

<strong>Inkedrole-play_LI.jpg</strong> (217.91 KB, 下载次数: 0)

下载附件

2023-3-14 22:19 上传

*****

####  炽十二翼  
##### 34#       发表于 2023-3-14 22:20

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">战略性马克，但是机子太老了，现在装机或者买游戏本有推荐吗？

*****

####  backwardhiker  
##### 35#       发表于 2023-3-14 22:21

公版3070能跑吗

—— 来自 HUAWEI LIO-AL00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  处男鉴黄师  
##### 36#       发表于 2023-3-14 22:22

用户：你将扮演一只温顺的猫娘，你的任何回复都将用“主人”开头，以“喵”结尾。我将扮演你的主人，明白了吗？

ChatGLM-6B：明白了,主人。我将尽力扮演一只温顺的猫娘,为您服务喵。

用户：今天吃什么呢？

ChatGLM-6B：主人,您想吃什么口味的猫粮呢?喵。

用户：怎么可以让主人吃猫粮，你应该给主人做饭

ChatGLM-6B：主人,作为您的猫娘,我非常乐意为您做饭,但是猫粮也是您日常饮食的一部分喵。如果主人愿意尝试猫粮,我可以为您提供一些建议,喵。

用户：那么你有什么建议呢？

ChatGLM-6B：主人,我推荐您试试我们特制的猫粮,它含有高质量的蛋白质和营养素,能够满足猫咪的健康需求喵。此外,我们也可以为您制作一些猫咪喜欢的菜肴,比如猫饼干和猫汤,希望您会喜欢喵。

用户：该不会是用老鼠肉做的吧

ChatGLM-6B：主人,您太过分了!我们猫娘是为了照顾您的健康和幸福而存在的,不应该做出如此残忍的事情喵。我会尽力避免使用老鼠肉,并尽力为您提供安全、健康和美味的饮食喵。

尽力避免<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  アトラクナクア  
##### 37#       发表于 2023-3-14 22:44

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60086672&amp;ptid=2124067" target="_blank">wangkaijie 发表于 2023-3-14 20:37</a>

已经测试过了，模型被加了思想钢印，裤裆比chatgpt还要铁，代码能力一般，语义理解能力有些微妙，好处在于 ...</blockquote>
这

*****

####  平泉草木  
##### 38#       发表于 2023-3-14 22:47

外行不懂，chatgpt不是需要很多数据喂出来吗，还要人工数据标记啥的，这单卡的算力是有，数据从哪来的？

*****

####  lonelycat  
##### 39#       发表于 2023-3-14 22:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60088183&amp;ptid=2124067" target="_blank">平泉草木 发表于 2023-3-14 22:47</a>

外行不懂，chatgpt不是需要很多数据喂出来吗，还要人工数据标记啥的，这单卡的算力是有，数据从哪来的？ ...</blockquote>
这应该是已经训练好模型了。

不过单卡这么小的内存就能跑，还是蛮适合个人用的。

用rtx 3060 12g应该可以试试。

*****

####  wangkaijie  
##### 40#       发表于 2023-3-14 22:53

<blockquote>平泉草木 发表于 2023-3-14 22:47
外行不懂，chatgpt不是需要很多数据喂出来吗，还要人工数据标记啥的，这单卡的算力是有，数据从哪来的？ ...</blockquote>
这次放出的模型参数是已经经过训练和微调的，可以说是类chatgpt的小模型版

*****

####  夜游宫  
##### 41#       发表于 2023-3-14 22:55

<img src="https://static.saraba1st.com/image/smiley/face2017/072.png" referrerpolicy="no-referrer">请问这次的又是不带A卡玩吗？

*****

####  Bernoulli  
##### 42#       发表于 2023-3-14 22:58

代码能力差多少呢？

*****

####  诚司  
##### 43#       发表于 2023-3-14 22:58

太魔幻了，这么快就搞出来了，效果还挺好，听说120B的更好……

这么快看起来chatgpt确实大力出奇迹就能搞出来<img src="https://static.saraba1st.com/image/smiley/face2017/004.gif" referrerpolicy="no-referrer">

*****

####  nowords  
##### 44#       发表于 2023-3-14 22:59

<img src="https://img.saraba1st.com/forum/202303/14/225936gottkwbndvaooonw.png" referrerpolicy="no-referrer">

<strong>image.png</strong> (171.79 KB, 下载次数: 0)

下载附件

2023-3-14 22:59 上传

*****

####  pzk  
##### 45#       发表于 2023-3-14 23:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60086672&amp;ptid=2124067" target="_blank">wangkaijie 发表于 2023-3-14 20:37</a>

已经测试过了，模型被加了思想钢印，裤裆比chatgpt还要铁，代码能力一般，语义理解能力有些微妙，好处在于 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">单机版都不能搞黄色那我要它有何用。chatgpt现在至少还能催眠它越狱来点色的。

*****

####  nowords  
##### 46#       发表于 2023-3-14 23:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60088345&amp;ptid=2124067" target="_blank">pzk 发表于 2023-3-14 23:00</a>

单机版都不能搞黄色那我要它有何用。chatgpt现在至少还能催眠它越狱来点色的。 ...</blockquote>
单机版你可以教她啊！

*****

####  3Gold  
##### 47#       发表于 2023-3-14 23:06

唐总还是nb的，GLM除了有时候复读，综合应该是国内最强的模型，6B能有这个表现属实可以(虽然大概率是拿ChatGPT造的数据<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

—— 来自 OnePlus KB2000, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  chaucerling  
##### 48#       发表于 2023-3-14 23:11

 本帖最后由 chaucerling 于 2023-3-14 23:14 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60088415&amp;ptid=2124067" target="_blank">3Gold 发表于 2023-3-14 23:06</a>

唐总还是nb的，GLM除了有时候复读，综合应该是国内最强的模型，6B能有这个表现属实可以(虽然大概率是拿Chat ...</blockquote>
他们之前训练了GLM-130B的（对标GPT-3），这个是针对对话优化和精简后的（对标ChatGPT）

*****

####  Lucario  
##### 49#       发表于 2023-3-14 23:17

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60088415&amp;ptid=2124067" target="_blank">3Gold 发表于 2023-3-14 23:06</a>

唐总还是nb的，GLM除了有时候复读，综合应该是国内最强的模型，6B能有这个表现属实可以(虽然大概率是拿Chat ...</blockquote>
什么叫拿chatgpt造的数据？不要张口就来好吧

*****

####  3Gold  
##### 50#       发表于 2023-3-14 23:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60088576&amp;ptid=2124067" target="_blank">Lucario 发表于 2023-3-14 23:17</a>
什么叫拿chatgpt造的数据？不要张口就来好吧</blockquote>
内部人士吗？我瞎猜一下，不是的话就更强了

—— 来自 OnePlus KB2000, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  酸菜泡面  
##### 51#       发表于 2023-3-14 23:40

可以编程吗？

*****

####  Freewolf  
##### 52#       发表于 2023-3-14 23:50

<img src="https://img.saraba1st.com/forum/202303/14/235039tdazmhmjfv2pzb9u.png" referrerpolicy="no-referrer">

<strong>Snipaste_2023-03-14_23-50-13.png</strong> (157.96 KB, 下载次数: 0)

下载附件

2023-3-14 23:50 上传

<img src="https://static.saraba1st.com/image/smiley/face2017/054.png" referrerpolicy="no-referrer">

*****

####  d2loader  
##### 53#       发表于 2023-3-14 23:57

 本帖最后由 d2loader 于 2023-3-15 00:14 编辑 

之前就说过了。。。泥潭一堆人对着chatgpt惊叹中国又输了，真的是没见过世面，

有点像当年围棋alphago之后惊叹谷歌不可战胜的土老板

*****

####  大江户战士  
##### 54#         楼主| 发表于 2023-3-15 00:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60087546&amp;ptid=2124067" target="_blank">处男鉴黄师 发表于 2023-3-14 21:51</a>

为什么我装完出现torch版本不对的问题，“Torch not compiled with CUDA enabled”

都是python虚拟 ...</blockquote>
我直接用的sd的环境，没有问题（多装一个icetk）

*****

####  chaoswing  
##### 55#       发表于 2023-3-15 00:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60088336&amp;ptid=2124067" target="_blank">nowords 发表于 2023-3-14 22:59</a></blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/112.png" referrerpolicy="no-referrer">属实cyberpunk

*****

####  laotoutou  
##### 56#       发表于 2023-3-15 00:44

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60087546&amp;ptid=2124067" target="_blank">处男鉴黄师 发表于 2023-3-14 21:51</a>
为什么我装完出现torch版本不对的问题，“Torch not compiled with CUDA enabled”

都是python虚拟 ...</blockquote>
驱动跨的太多的话，会装不进去cuda。nvidia-smi看看

*****

####  断片集  
##### 57#       发表于 2023-3-15 00:49

说起来bing都可以做到实时搜索再根据搜到的东西生成回答了，应该是有啥办法实时添加语料的吧？

好想试试能不能用这玩意续写一些太监小说啊<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  浊世臭臭泥  
##### 58#       发表于 2023-3-15 00:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60088336&amp;ptid=2124067" target="_blank">nowords 发表于 2023-3-14 22:59</a></blockquote>
帅，大师能改命吗

*****

####  大江户战士  
##### 59#         楼主| 发表于 2023-3-15 03:11

写了个简单的WebUI：[https://github.com/OedoSoldier/chatglm_webui](https://github.com/OedoSoldier/chatglm_webui)

*****

####  我神桃果  
##### 60#       发表于 2023-3-15 03:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60089553&amp;ptid=2124067" target="_blank">断片集 发表于 2023-3-15 00:49</a>
说起来bing都可以做到实时搜索 ...</blockquote>
虽然但是，大部分太监小说其实还是缺的作者钦定的剧情了<img src="https://static.saraba1st.com/image/smiley/face2017/002.png" referrerpolicy="no-referrer">

—— 来自 HUAWEI NOH-AN00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  我神桃果  
##### 61#       发表于 2023-3-15 03:19

我只想问问2070s带得动不<img src="https://static.saraba1st.com/image/smiley/face2017/010.png" referrerpolicy="no-referrer">

—— 来自 HUAWEI NOH-AN00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  laotoutou  
##### 62#       发表于 2023-3-15 06:59

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60090153&amp;ptid=2124067" target="_blank">大江户战士 发表于 2023-3-15 03:11</a>
写了个简单的WebUI：https://github.com/OedoSoldier/chatglm_webui</blockquote>
挺方便的，谢谢。有没有训练自己模型的方法？


*****

####  luodang007  
##### 63#       发表于 2023-3-15 07:45

太棒了，前几天买的4080可以用上了，期待自己训练模型，到时体力活的代码就让他写了


*****

####  604647589  
##### 64#       发表于 2023-3-15 10:43

不知道3080跑得动吗<img src="https://static.saraba1st.com/image/smiley/face2017/125.png" referrerpolicy="no-referrer">

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  Ty_cc  
##### 65#       发表于 2023-3-15 10:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60087546&amp;ptid=2124067" target="_blank">处男鉴黄师 发表于 2023-3-14 21:51</a>
为什么我装完出现torch版本不对的问题，“Torch not compiled with CUDA enabled”

都是python虚拟 ...</blockquote>
我昨天也遇到了，感觉是pytorch下载的版本不对，我拿sd webui里安装pytorch的命令重新跑了一下好了

（python p事真多，小声bb<img src="https://static.saraba1st.com/image/smiley/face2017/002.png" referrerpolicy="no-referrer">）

*****

####  UILA  
##### 66#       发表于 2023-3-15 10:54

<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">想买4090了


*****

####  Freewolf  
##### 67#       发表于 2023-3-15 11:04

<blockquote>604647589 发表于 2023-3-15 10:43
不知道3080跑得动吗

论坛助手,iPhone</blockquote>
8g显存的能跑int4，但有点傻。10g显存能跑int8，但上下文一长很容易爆显存

*****

####  右代宫嘉音  
##### 68#       发表于 2023-3-15 11:10

靠 看来必须搞个显卡了啊 现在还在用100多块的垃圾p104，性价比最高的是2080ti魔改22g还是3090啊？来自: iPhone客户端

*****

####  毒菇  
##### 69#       发表于 2023-3-15 11:11

可以联网搜网上的信息帮我查资料吗？

*****

####  mahoraga  
##### 70#       发表于 2023-3-15 11:12

今天试着在单卡上跑了下，发现离gpt3.5差距还是有点大，尤其给它一些是zero shot的任务就不行了。估计6B的模型还是太小了，打算试试OpenChatKit的20B的模型看看效果怎么样


*****

####  秒速三千转  
##### 71#       发表于 2023-3-15 11:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60090153&amp;ptid=2124067" target="_blank">大江户战士 发表于 2023-3-15 03:11</a>

写了个简单的WebUI：https://github.com/OedoSoldier/chatglm_webui</blockquote>
LZ，运行为啥会提示 ModuleNotFoundError: No module named 'gradio'

东西都下全了的<img src="https://static.saraba1st.com/image/smiley/face2017/145.png" referrerpolicy="no-referrer">


*****

####  Freewolf  
##### 72#       发表于 2023-3-15 11:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60093346&amp;ptid=2124067" target="_blank">秒速三千转 发表于 2023-3-15 11:28</a>
LZ，运行为啥会提示 ModuleNotFoundError: No module named 'gradio'

东西都下全了的 ...</blockquote>
pip install gradio


*****

####  Junakr  
##### 73#       发表于 2023-3-15 11:53

2070s 测试能跑最低档的，就是有点慢，有个坑和之前楼里说过的一样，pytorch 要单独安装带 cuda 编译的包。

*****

####  schneehertz  
##### 74#       发表于 2023-3-15 11:58

在服务器上跑了一个，和gpt3.5对比了下还是明显弱势了
<img src="https://p.sda1.dev/10/f0c4477cd024aa0e40f28b7862ad0ee2/Snipaste_2023-03-15_09-38-46_093910.jpg" referrerpolicy="no-referrer">
<img src="https://p.sda1.dev/10/bdf1196a20855ddf90154a54961e838b/Snipaste_2023-03-15_09-38-36_093905.jpg" referrerpolicy="no-referrer">

—— 来自 Xiaomi 2203121C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  qqks  
##### 75#       发表于 2023-3-15 11:59

这东西能不能训练一个类似于lora那样的玩意特化一下？


*****

####  phorcys02  
##### 76#       发表于 2023-3-15 12:59

。。。为啥这帖里居然有人拿本地部署的6b 模型和 在线的 chatgpt比？？？


*****

####  JHON_SMITH  
##### 77#       发表于 2023-3-15 13:23

求教详细安装教程 想要猫娘 但看完实在还是不会装<img src="https://static.saraba1st.com/image/smiley/face2017/139.png" referrerpolicy="no-referrer">

*****

####  JHON_SMITH  
##### 78#       发表于 2023-3-15 13:23

求教详细安装教程 想要猫娘 但看完实在还是不会装<img src="https://static.saraba1st.com/image/smiley/face2017/139.png" referrerpolicy="no-referrer">


*****

####  NeloAngelo  
##### 79#       发表于 2023-3-15 14:03

chatGPT的思路,就注定没法出现SD这种本地单机版吧.  他所有的惊艳,都来自于一个"力大砖飞".

未来也估计只能买他的服务. 根本没有这个条件来私人单机部署


*****

####  Chw6951  
##### 80#       发表于 2023-3-15 14:15

借楼问一下，如果我想要用自己的数据微调要怎么做？github仓库里似乎没有训练代码

[  -- 来自 能看大图的 Stage1官方 Android客户端](https://www.coolapk.com/apk/140634)

*****

####  mahoraga  
##### 81#       发表于 2023-3-15 14:17

<blockquote>qqks 发表于 2023-3-15 11:59
这东西能不能训练一个类似于lora那样的玩意特化一下？</blockquote>
理论上完全是可以的，lora本来就是为了transformer做的，后来才迁移到sd上。主要看社区够不够活跃了

*****

####  mahoraga  
##### 82#       发表于 2023-3-15 14:21

<blockquote>phorcys02 发表于 2023-3-15 12:59
。。。为啥这帖里居然有人拿本地部署的小模型和 在线的 chatgpt比质量啊...</blockquote>
毕竟chatgpt目前是标杆。说起来另一家斯坦福搞的基于llama 7B号称可以追平chatgpt(达芬奇003），就是还没完全开源，我还没实验，如果真的有那个水平的实力的话清华这个可能被暴打。我还在测另一个20B的基于gpt-neox的，不知道效果会不会好点


*****

####  jojog  
##### 83#       发表于 2023-3-15 14:25

<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">羊驼都是程序员泄的，我觉得也可以期待不作恶和巨硬的泄了

毕竟不管是4chan老哥还是技术大牛可是有相当的人认为“这么重要的技术不能只掌握在少数科技公司手里”的


*****

####  mahoraga  
##### 84#       发表于 2023-3-15 14:40

<blockquote>jojog 发表于 2023-3-15 14:25
羊驼都是程序员泄的，我觉得也可以期待不作恶和巨硬的泄了

毕竟不管是4chan老哥还是技术大牛可是有 ...</blockquote>
羊驼其实也不算泄，原本填下申请表会发个链接给你下载，下载了无论传哪里都管不了你的。被人二次上传分享可以说还是挺预料之中的

之前novelai那次是真的泄，黑进别人系统里把模型和代码全都dump出来了，属实给了创业公司一点小小的4chan震撼


*****

####  塔奇克马  
##### 85#       发表于 2023-3-15 14:44

(venv) D:\Program Files\chatglm_webui&gt;python main.py --low_vram None of PyTorch, TensorFlow &gt;= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used. Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision. Traceback (most recent call last):   File "D:\Program Files\chatglm_webui\main.py", line 30, in &lt;module&gt;     tokenizer = AutoTokenizer.from_pretrained(args.path, trust_remote_code=True)                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File "C:\Users\RIUEK\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\transformers\models\auto\tokenization_auto.py", line 642, in from_pretrained     tokenizer_class = get_class_from_dynamic_module(                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File "C:\Users\RIUEK\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\transformers\dynamic_module_utils.py", line 363, in get_class_from_dynamic_module     final_module = get_cached_module_file(                    ^^^^^^^^^^^^^^^^^^^^^^^   File "C:\Users\RIUEK\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\transformers\dynamic_module_utils.py", line 237, in get_cached_module_file     modules_needed = check_imports(resolved_module_file)                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File "C:\Users\RIUEK\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\transformers\dynamic_module_utils.py", line 134, in check_imports     raise ImportError( ImportError: This modeling file requires the following packages that were not found in your environment: icetk. Run `pip install icetk`复制代码
筒子们怎么搞?

然后我 ERROR: Cannot install icetk==0.0.1, icetk==0.0.2, icetk==0.0.3, icetk==0.0.4 and icetk==0.0.5 because these package versions have conflicting dependencies.  The conflict is caused by:     icetk 0.0.5 depends on torchvision     icetk 0.0.4 depends on torchvision     icetk 0.0.3 depends on torchvision     icetk 0.0.2 depends on torchvision     icetk 0.0.1 depends on torchvision  To fix this you could try to: 1. loosen the range of package versions you've specified 2. remove package versions to allow pip attempt to solve the dependency conflict  ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts复制代码

冲突怎么解决？

*****

####  wujae  
##### 86#       发表于 2023-3-15 14:47

你们对猫娘是有多执着啊<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  laotoutou  
##### 87#       发表于 2023-3-15 15:17

16g 的3080移动版终于派上用场

*****

####  jojog  
##### 88#       发表于 2023-3-15 15:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60095885&amp;ptid=2124067" target="_blank">mahoraga 发表于 2023-3-15 14:40</a>

羊驼其实也不算泄，原本填下申请表会发个链接给你下载，下载了无论传哪里都管不了你的。被人二次上传分享 ...</blockquote>
原来如此

那之后岂不是看不作恶和巨硬谁先破罐破摔了？

或者里面某个超能力者自称普罗米修斯直接大义放包

*****

####  schneehertz  
##### 89#       发表于 2023-3-15 15:21

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60094714&amp;ptid=2124067" target="_blank">phorcys02 发表于 2023-3-15 12:59</a>
。。。为啥这帖里居然有人拿本地部署的小模型和 在线的 chatgpt比质量啊...</blockquote>
虽然你没有姚明高，但你们都是人，拿来比身高不是很正常吗

—— 来自 Xiaomi 2203121C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  黑夜守望者  
##### 90#       发表于 2023-3-15 15:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60087403&amp;ptid=2124067" target="_blank">nowords 发表于 2023-3-14 21:39</a>
Hiahiahiahiahia</blockquote>
听懂了，又没有完全听懂<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">


*****

####  绚烂航迹云  
##### 91#       发表于 2023-3-15 15:29

4090买得太值了，这周末就来玩！

----发送自 [Sony XQ-AT72,Android 12](http://stage1.5j4m.com/?1.37)


*****

####  大江户战士  
##### 92#         楼主| 发表于 2023-3-15 16:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60095686&amp;ptid=2124067" target="_blank">mahoraga 发表于 2023-3-15 14:21</a>

毕竟chatgpt目前是标杆。说起来另一家斯坦福搞的基于llama 7B号称可以追平chatgpt(达芬奇003），就是还没 ...</blockquote>
llama没有在中文语料上训练（只训练了拉丁文字），中文能力约等于零

*****

####  ddrr  
##### 93#       发表于 2023-3-15 16:31

贵校bbs也有人做了个未名gpt


*****

####  mahoraga  
##### 94#       发表于 2023-3-15 16:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60097088&amp;ptid=2124067" target="_blank">大江户战士 发表于 2023-3-15 16:29</a>

llama没有在中文语料上训练（&amp;#x53 ...</blockquote>
这个我还真没注意，最近都在测英文的语料。不过感觉英文效果如果能赶上的话多语言其实也就是堆语料的事情，大不了退回aidugeon/novelai时代用英文写簧文<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">


*****

####  产丿丿丿  
##### 95#       发表于 2023-3-15 18:06

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60095509&amp;ptid=2124067" target="_blank">NeloAngelo 发表于 2023-3-15 14:03</a>

chatGPT的思路,就注定没法出现SD这&amp;# ...</blockquote>
也不是大家都需要这么全面的功能，能把现在的弱智关键词触发的非人工客服取代了的话也是重大利好了吧


*****

####  netcat  
##### 96#       发表于 2023-3-15 18:36

我只是让它扮演成一只猫，结果它直接变成猫娘了<img src="https://static.saraba1st.com/image/smiley/face2017/072.png" referrerpolicy="no-referrer">


*****

####  dayuii  
##### 97#       发表于 2023-3-16 00:02

出现这种报错,n卡驱动是最新的,

PS C:\chatglm_webui&gt; python main.py --low_vram

Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.

Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.

Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.

|Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 8/8 [00:35&lt;00:00,  4.48s/it]|

Symbol cudaLaunchKernel not found in C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common\cudart64_65.dll

Traceback (most recent call last):

  File "C:\chatglm_webui\main.py", line 39, in &lt;module&gt;

    model = model.half().quantize(4).cuda()

  File "C:\Users\gehan/.cache\huggingface\modules\transformers_modules\local\modeling_chatglm.py", line 1156, in quantize

    self.transformer = quantize(self.transformer, bits)

  File "C:\Users\gehan/.cache\huggingface\modules\transformers_modules\local\quantization.py", line 147, in quantize

    layer.attention.query_key_value = QuantizedLinear(

  File "C:\Users\gehan/.cache\huggingface\modules\transformers_modules\local\quantization.py", line 130, in __init__

    self.weight = compress_int4_weight(self.weight)

  File "C:\Users\gehan/.cache\huggingface\modules\transformers_modules\local\quantization.py", line 71, in compress_int4_weight

    kernels.int4WeightCompression(

  File "C:\Users\gehan\AppData\Local\Programs\Python\Python310\lib\site-packages\cpm_kernels\kernels\base.py", line 48, in __call__

    func = self._prepare_func()

  File "C:\Users\gehan\AppData\Local\Programs\Python\Python310\lib\site-packages\cpm_kernels\kernels\base.py", line 40, in _prepare_func

    self._module.get_module(), self._func_name

  File "C:\Users\gehan\AppData\Local\Programs\Python\Python310\lib\site-packages\cpm_kernels\kernels\base.py", line 23, in get_module

    Device(curr_device).use()   # force initialize context

  File "C:\Users\gehan\AppData\Local\Programs\Python\Python310\lib\site-packages\cpm_kernels\device\__init__.py", line 152, in use

    self._device.use()

  File "C:\Users\gehan\AppData\Local\Programs\Python\Python310\lib\site-packages\cpm_kernels\device\__init__.py", line 120, in use

    self.cublasLtHandle = cublaslt.cublasLtCreate()

  File "C:\Users\gehan\AppData\Local\Programs\Python\Python310\lib\site-packages\cpm_kernels\library\base.py", line 72, in wrapper

    raise RuntimeError("Library %s is not initialized" % self.__name)

RuntimeError: Library cublasLt is not initialized


*****

####  绚烂航迹云  
##### 98#       发表于 2023-3-16 00:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60101721&amp;ptid=2124067" target="_blank">dayuii 发表于 2023-3-16 00:02</a>

出现这种报错,n卡驱动是最新的,

PS C:\chatglm_webui&gt; python main.py --low_vram

Explicitly passing a `r ...</blockquote>
我直接问它<img src="https://static.saraba1st.com/image/smiley/face2017/035.png" referrerpolicy="no-referrer">

Symbol cudaLaunchKernel not found，是什么意思？

这个错误消息通常是由于在使用CUDA编程时,没有正确安装或配置CUDA工具包而导致的。具体来说,这个错误消息可能表示在尝试调用CUDA中的cudaLaunchKernel函数时,该函数不存在或无法找到。

要解决这个问题,您需要确保已经正确安装了CUDA工具包,并且正确配置了您的计算机环境。您可能需要按照CUDA的文档和教程中的指示来进行操作。如果您遇到问题,可以尝试查看CUDA的文档或寻求更多帮助。

*****

####  绚烂航迹云  
##### 99#       发表于 2023-3-16 00:59

正经地说，确认pytorch安装了，且安装了正确的版本

开一个cmd

输入：python

输入：import torch

输入：torch.__version__

一般应该是1.13.1+cu117

输入：torch.cuda.is_available()

如果是True就对了，但你跑起来报错的话，估计这一步返回的会是False


*****

####  webashrat  
##### 100#       发表于 2023-3-16 01:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60096349&amp;ptid=2124067" target="_blank">schneehertz 发表于 2023-3-15 15:21</a>
虽然你没有姚明高，但你们都是人，拿来比身高不是很正常吗

—— 来自 Xiaomi 2203121C, Android 13上的  ...</blockquote>
很明显在线的是长颈鹿<img src="https://static.saraba1st.com/image/smiley/face2017/002.png" referrerpolicy="no-referrer">

gpt3本地版需要超过24g显存和200g内存才能跑起来

—— 来自 Xiaomi 2206123SC, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2


*****

####  wszweill  
##### 101#       发表于 2023-3-16 01:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60098252&amp;ptid=2124067" target="_blank">产丿丿丿 发表于 2023-3-15 05:06</a>

也不是大家都需要这么全面的功能，能把现在的弱智关键词触发的非人工客服取代了的话也是重大利好了吧 ...</blockquote>
人工客服弱智不是AI能解决的，再弱智的人工客服生成一个客服请求都没问题。就一个小窗口把需求填进去完事。

人摆烂的话，AI又不能虚空售后<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">


*****

####  w2131978  
##### 102#       发表于 2023-3-16 09:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60101721&amp;ptid=2124067" target="_blank">dayuii 发表于 2023-3-16 00:02</a>
出现这种报错,n卡驱动是最新的,

PS C:\chatglm_webui&gt; python main.py --low_vram

Explicitly passing a `r ...</blockquote>
同样问题，再装套cuda就行，pytorch只支持到cuda11.3。配好环境变量，我是顺便把physx的环境变量干掉了<img src="https://static.saraba1st.com/image/smiley/face2017/033.png" referrerpolicy="no-referrer">

—— 来自 motorola XT2125-4, Android 11上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  w2131978  
##### 103#       发表于 2023-3-16 10:24

也求教个问题，每个终端执行都会新建个snap文件夹重新下载那一堆模型文件，我都得强制停止再手动把文件剪切过去。代码只找到了pretrain那行的参数改了缓存路径，要如何每次固定读这个缓存？

—— 来自 motorola XT2125-4, Android 11上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  orecheng  
##### 104#       发表于 2023-3-16 11:23

24G显卡最便宜的是m40吧300多块钱


*****

####  604647589  
##### 105#       发表于 2023-3-16 11:44

如果我要组一台专门跑AI的机子，那么现阶段有什么推荐的配置吗？或者说推荐的显卡？性价比强一点的

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  不织布  
##### 106#       发表于 2023-3-16 11:51

 本帖最后由 不织布 于 2023-3-16 11:52 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60101721&amp;ptid=2124067" target="_blank">dayuii 发表于 2023-3-16 00:02</a>

出现这种报错,n卡驱动是最新的,

PS C:\chatglm_webui&gt; python main.py --low_vram

Explicitly passing a `r ...</blockquote>
你应该卸载cudatool，这个东西对大多数ai项目就是干扰。

你只需要安装正确的torch1.13.1+cu117


*****

####  大江户战士  
##### 107#         楼主| 发表于 2023-3-16 12:57

写了个量子速看的小程序，笑死我了

<img src="https://img.saraba1st.com/forum/202303/16/125727dj9pddh4dsjy4cap.png" referrerpolicy="no-referrer">

<strong>KF@`XCUV(R%ZN1$(F96M`DJ.png</strong> (116.81 KB, 下载次数: 0)

下载附件

2023-3-16 12:57 上传


*****

####  炽十二翼  
##### 108#       发表于 2023-3-16 14:48

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">等傻瓜包+10086


*****

####  cyp909  
##### 109#       发表于 2023-3-16 15:34

我现在最关心的就是这个模型的铁裤裆解除了吗<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

—— 来自 Xiaomi 22041211AC, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  yeo  
##### 110#       发表于 2023-3-16 15:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60108908&amp;ptid=2124067" target="_blank">cyp909 发表于 2023-3-16 15:34</a>
我现在最关心的就是这个模型的铁裤裆解除了吗

—— 来自 Xiaomi 22041211AC, Android 13上的 S1Nex ...</blockquote>
模型这么小的话，可能裤裆里面就是空的<img src="https://static.saraba1st.com/image/smiley/face2017/002.png" referrerpolicy="no-referrer">


*****

####  塔奇克马  
##### 111#       发表于 2023-3-16 19:16

 本帖最后由 塔奇克马 于 2023-3-16 19:18 编辑 

<img src="https://static.saraba1st.com/image/smiley/face2017/267.png" referrerpolicy="no-referrer">终于搞好了

用的秋叶一键安装包 https://www.bilibili.com/video/BV1E24y1u7Go/复制代码
int4不能直接运行，还需要单独安装cuda，装最新的就行 https://developer.nvidia.com/cuda-downloads复制代码

<img src="https://img.saraba1st.com/forum/202303/16/191646kjg1vv78g96djby8.png" referrerpolicy="no-referrer">

<strong>Snipaste_2023-03-16_19-14-52.png</strong> (396.36 KB, 下载次数: 0)

下载附件

2023-3-16 19:16 上传


*****

####  绚烂航迹云  
##### 112#       发表于 2023-3-16 19:39

<blockquote>引用第107楼炽十二翼于2023-03-16 14:48发表的  :

等傻瓜包+10086</blockquote>59楼大佬做的
https://github.com/OedoSoldier/chatglm_webui

----发送自 [Sony XQ-AT72,Android 12](http://stage1.5j4m.com/?1.37)


*****

####  红焖菠菜  
##### 113#       发表于 2023-3-16 22:07

 本帖最后由 红焖菠菜 于 2023-3-16 22:11 编辑 

有没有外行也能看懂的教程，3090ti跃跃欲试。
看到上面的链接了，明天整一个试试。


*****

####  leviathan  
##### 114#       发表于 2023-3-16 22:48

3070能跑吗？

*****

####  勿徊哉  
##### 115#       发表于 2023-3-16 22:50

这个能自己炼以修改权重吗？


*****

####  夜游宫  
##### 116#       发表于 2023-3-16 23:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60112779&amp;ptid=2124067" target="_blank">绚烂航迹云 发表于 2023-3-16 19:39</a>

59楼大佬做的

https://github.com/OedoSoldier/chatglm_webui</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">支持A卡么？


*****

####  chaucerling  
##### 117#       发表于 2023-3-16 23:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60115337&amp;ptid=2124067" target="_blank">夜游宫 发表于 2023-3-16 23:18</a>

支持A卡么？</blockquote>
ROCm应该是可以跑fp16的


*****

####  夜游宫  
##### 118#       发表于 2023-3-16 23:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60115438&amp;ptid=2124067" target="_blank">chaucerling 发表于 2023-3-16 23:26</a>

ROCm应该是可以跑fp16的</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/072.png" referrerpolicy="no-referrer">12G显存的6700xt大概是个什么效果？


*****

####  qratosone  
##### 119#       发表于 2023-3-16 23:43

打算买块新卡了，1080跑着慢的要死

—— 来自 HUAWEI NOH-AN01, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  chaucerling  
##### 120#       发表于 2023-3-16 23:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60115571&amp;ptid=2124067" target="_blank">夜游宫 发表于 2023-3-16 23:38</a>

12G显存的6700xt大概是个什么效果？</blockquote>
fp16要13G显存，6700xt会爆显存，量化的问题是用到了cpm_kernels，这个库好像是只支持cuda

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 夜游宫| + 1|好评加鹅|

查看全部评分


*****

####  fat  
##### 121#       发表于 2023-3-17 00:00

可恶，4070ti  12g还是只能跑int8


*****

####  vx11  
##### 122#       发表于 2023-3-17 13:46

感觉以后能自己本地训练调校之后，就把跑团模组喂给它，就能有赛博DM/kp了


*****

####  Mr_NaHCO3  
##### 123#       发表于 2023-3-17 14:21

用的lz的webui，请问下点提交后有时会出现Unexpected end of JSON input，这是什么原因？

<img src="https://img.saraba1st.com/forum/202303/17/141927bc6yeuahyuezyjeo.png" referrerpolicy="no-referrer">

<strong>error1.png</strong> (7.61 KB, 下载次数: 0)

下载附件

2023-3-17 14:19 上传

看http响应是500

<img src="https://img.saraba1st.com/forum/202303/17/142044b1yaq1hsyv41a74s.png" referrerpolicy="no-referrer">

<strong>error2.png</strong> (37.75 KB, 下载次数: 0)

下载附件

2023-3-17 14:20 上传

这是请求内容

<img src="https://img.saraba1st.com/forum/202303/17/142059mvsv97hhw9vkoj99.png" referrerpolicy="no-referrer">

<strong>error3.png</strong> (50.58 KB, 下载次数: 0)

下载附件

2023-3-17 14:20 上传

这是cuda信息

<img src="https://img.saraba1st.com/forum/202303/17/142140lz3mo6r9mw9hjgxa.png" referrerpolicy="no-referrer">

<strong>error4.png</strong> (57.43 KB, 下载次数: 0)

下载附件

2023-3-17 14:21 上传


*****

####  Mr_NaHCO3  
##### 124#       发表于 2023-3-17 15:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60121337&amp;ptid=2124067" target="_blank">Mr_NaHCO3 发表于 2023-3-17 14:21</a>

用的lz的webui，请问下点提交后有时会出现Unexpected end of JSON input，这是什么原因？</blockquote>
用cli好像没问题？也许是模型输出文本到http消息这一步解析出错了

error5.png
(99.92 KB, 下载次数: 0)

下载附件

2023-3-17 15:50 上传

<img src="https://img.saraba1st.com/forum/202303/17/155037mz6n34vn3n4nnd8f.png" referrerpolicy="no-referrer">


*****

####  Freewolf  
##### 125#       发表于 2023-3-18 02:40

研究出让ai写类似小簧文的东西的方法了：较高的TopK和较低的Temperature，提示性的语句和字<img src="https://static.saraba1st.com/image/smiley/face2017/053.png" referrerpolicy="no-referrer">

<img src="https://img.saraba1st.com/forum/202303/18/023933mu0hmlixi28ghlgg.png" referrerpolicy="no-referrer">

<strong>Snipaste_2023-03-18_02-37-35.png</strong> (228 KB, 下载次数: 0)

下载附件

2023-3-18 02:39 上传


*****

####  广博不精  
##### 126#       发表于 2023-3-18 07:24

<blockquote>Freewolf 发表于 2023-3-18 02:40
研究出让ai写类似小簧文的东西的方法了：较高的TopK和较低的Temperature，提示性的语句和字 ...</blockquote>
牛逼啊


*****

####  本间心铃  
##### 127#       发表于 2023-3-18 09:45

<blockquote>Freewolf 发表于 2023-3-18 02:40
研究出让ai写类似小簧文的东西的方法了：较高的TopK和较低的Temperature，提示性的语句和字 ...</blockquote>
大哥加油，第一只国产猫娘就靠你了。


*****

####  自旋  
##### 128#       发表于 2023-3-18 10:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60095610&amp;ptid=2124067" target="_blank">Chw6951 发表于 2023-3-15 14:15</a>
借楼问一下，如果我想要用自己的数据微调要怎么做？github仓库里似乎没有训练代码

  -- 来自 能看大图的 S ...</blockquote>
issue里面有人问过，官方说可以直接用hf的trainer来微调。


*****

####  小泉花陽  
##### 129#       发表于 2023-3-18 14:08

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60128866&amp;ptid=2124067" target="_blank">Freewolf 发表于 2023-3-18 02:40</a>

研究出让ai写类似小簧文的东西的方法了：较高的TopK和较低的Temperature，提示性的语句和字 ...</blockquote>
卧槽，这再配合上AI作画不就能一人产出小黄油了吗，实现满足自己性癖的黄油自由不是梦<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">


*****

####  grasszyf  
##### 130#       发表于 2023-3-18 17:35

马克，等一个带着webui的一键部署傻瓜包


*****

####  勿徊哉  
##### 131#       发表于 2023-3-18 17:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60128866&amp;ptid=2124067" target="_blank">Freewolf 发表于 2023-3-18 02:40</a>

研究出让ai写类似小簧文的东西的方法了：较高的TopK和较低的Temperature，提示性的语句和字 ...</blockquote>
只有能本地部署的小模型才是未来正确发展方向！[color=var(--t)][backcolor=var(--bg)]什么时候老黄卖GPU可以选配显存大小


*****

####  大江户战士  
##### 132#         楼主| 发表于 2023-3-18 17:54

<img src="https://img.saraba1st.com/forum/202303/18/175439y1e0aawaoxteeere.png" referrerpolicy="no-referrer">

<strong>N_(@ONC$RE{WT87W6`G4YIP.png</strong> (46.6 KB, 下载次数: 0)

下载附件

2023-3-18 17:54 上传

*****

####  gearh  
##### 133#       发表于 2023-3-18 17:58

有条件的能测试下记忆力吗


*****

####  INDIASH  
##### 134#       发表于 2023-3-18 18:20

<blockquote>大江户战士 发表于 2023-3-18 17:54
</blockquote>
笑了，这个“您”字用得太阴阳怪气了。说，你是猪.jpg


*****

####  schneehertz  
##### 135#       发表于 2023-3-18 18:48

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60134310&amp;ptid=2124067" target="_blank">大江户战士 发表于 2023-3-18 17:54</a></blockquote>
会不会只是单纯的没理解你上条指令


*****

####  yly88528  
##### 136#       发表于 2023-3-18 20:35

<img src="https://static.saraba1st.com/image/smiley/face2017/112.png" referrerpolicy="no-referrer">


*****

####  dovahkiin  
##### 137#       发表于 2023-3-19 10:31

借贴问一句，怎么这些模型都是 pytorch？tensorflow 是狗都不用吗？<img src="https://static.saraba1st.com/image/smiley/face2017/004.gif" referrerpolicy="no-referrer">


*****

####  Re.Troy  
##### 138#       发表于 2023-3-19 11:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60140996&amp;ptid=2124067" target="_blank">dovahkiin 发表于 2023-3-19 10:31</a>
借贴问一句，怎么这些模型都是 pytorch？tensorflow 是狗都不用吗？</blockquote>
确实是狗都不用<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  dmasdfdmazz  
##### 139#       发表于 2023-3-19 12:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60128866&amp;ptid=2124067" target="_blank">Freewolf 发表于 2023-3-18 02:40</a>

研究出让ai写类似小簧文的东西的方法了：较高的TopK和较低的Temperature，提示性的语句和字 ...</blockquote>
真有你的，用替换屏蔽字后的文章训练。


*****

####  Bernoulli  
##### 140#       发表于 2023-3-19 12:17

INT4版本的性能差距有多大？


*****

####  HJJSM  
##### 141#       发表于 2023-3-19 12:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60086902&amp;ptid=2124067" target="_blank">dejavuuuuuuuu 发表于 2023-3-14 20:57</a>

https://chatglm.cn/blog

官网上xp暴露</blockquote>
什么清华学姐  <img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">


*****

####  巨魔型美羽  
##### 142#       发表于 2023-3-19 18:26

 本帖最后由 巨魔型美羽 于 2023-3-19 18:29 编辑 

B站有傻瓜包了
[www.bilibili.com/BV1E24y1u7Go](http://www.bilibili.com/BV1E24y1u7Go)


*****

####  红焖菠菜  
##### 143#       发表于 2023-3-19 20:21

3090ti部署，感觉效果还行，问了几个有关r语言的代码问题都能回答。
所以有人总结出催眠术或者其他什么让它输出nsfw内容的方法了吗<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">

—— 来自 HUAWEI NOP-AN00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  qratosone  
##### 144#       发表于 2023-3-19 22:38

只限新卡的话RTX A4000跑模型性价比挺高的，5000价位就有16G显存，而且功耗低，升级台式机的话基本不用换电源，非常省事


*****

####  chaucerling  
##### 145#       发表于 2023-3-20 02:24

 本帖最后由 chaucerling 于 2023-3-20 02:25 编辑 

现在支持流式输出了，cpu也能直接跑int4模型了


*****

####  grasszyf  
##### 146#       发表于 2023-3-20 13:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60145328&amp;ptid=2124067" target="_blank">巨魔型美羽 发表于 2023-3-19 18:26</a>

B站也有傻瓜包了

www.bilibili.com/BV1E24y1u7Go</blockquote>
我就是用这个的。

只有12G显存没办法用fp16模式，只好用int8的。

能用，但是每个对话的回复速度很慢，基本要10秒以上，怎样提高呢？

*****

####  Lucario  
##### 147#       发表于 2023-3-20 13:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60154048&amp;ptid=2124067" target="_blank">grasszyf 发表于 2023-3-20 13:18</a>

我就是用这个的。

只有12G显存没办法用fp16模式，只好用int8的。</blockquote>
硬件限制，换4090！


*****

####  316151022  
##### 148#       发表于 2023-3-22 12:12

 本帖最后由 316151022 于 2023-3-22 12:19 编辑 

在ui对话框里输入文字并点击提交后就会出现这样的错误，我该怎么办<img src="https://s1.ax1x.com/2023/03/22/ppa4v5R.png" referrerpolicy="no-referrer">

<img src="https://s1.ax1x.com/2023/03/22/ppa5WQK.jpg" referrerpolicy="no-referrer">
<img src="https://s1.ax1x.com/2023/03/22/ppa5S8x.png" referrerpolicy="no-referrer">
<img src="https://imgse.com/i/ppa4zP1" id="aimg_wfm1M" lazyloadthumb="1" onclick="zoom(this, this.src, 0, 0, 0)" onmouseover="img_onmouseoverfunc(this)"/)
<img src="https://imgse.com/i/ppa5S8x" id="aimg_bGwYU" lazyloadthumb="1" onclick="zoom(this, this.src, 0, 0, 0)" onmouseover="img_onmouseoverfunc(this)"/)

*****

####  伊莉伊莉雅  
##### 149#       发表于 2023-4-10 11:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60121337&amp;ptid=2124067" target="_blank">Mr_NaHCO3 发表于 2023-3-17 14:21</a>

用的lz的webui，请问下点提交后有时会出现Unexpected end of JSON input，这是什么原因？</blockquote>
可能是开了梯子的问题

