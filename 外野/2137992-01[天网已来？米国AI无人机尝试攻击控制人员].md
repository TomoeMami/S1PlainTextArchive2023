
*****

####  机吉斯卡  
##### 1#       楼主       发表于 2023-6-2 09:15

[https://weibo.com/1989534434/4908101796891242](https://weibo.com/1989534434/4908101796891242)

美国空军在模拟环境的训练中指派一架搭载人工智能(AI)的无人机来摧毁敌方的防空导弹，AI可以识别威胁但是攻击需要人类批准。

AI觉得人类妨碍了自己执行最优先的攻击防空系统的任务，然后AI开始(模拟)攻击人类操作员。

接着AI被训练成不能攻击人类操作员，那样会扣分。

然后AI开始攻击通讯塔，切断人类操作员和无人机之间的数据通讯，让人类无法阻止他攻击防空系统。

<img src="https://img.saraba1st.com/forum/202306/02/091407yiez6lcbx6ivumuy.jpeg" referrerpolicy="no-referrer">" src="https://static.saraba1st.com/image/common/none.gif" referrerpolicy="no-referrer">

<strong>IMG_4065.jpeg</strong> (371.13 KB, 下载次数: 0)

下载附件

2023-6-2 09:14 上传

<img src="https://img.saraba1st.com/forum/202306/02/091407wluv72w03lkel80c.jpeg" referrerpolicy="no-referrer">" src="https://static.saraba1st.com/image/common/none.gif" referrerpolicy="no-referrer">

<strong>IMG_4066.jpeg</strong> (67.16 KB, 下载次数: 0)

下载附件

2023-6-2 09:14 上传

@lfx160219：美国空军的AI测试与运作主管Tucker Hamilton上校在英国皇家航空协会的未来空战与太空能力峰会上的演讲 [http://t.cn/A6pbQR5d](http://t.cn/A6pbQR5d)

*****

####  Re.Troy  
##### 2#       发表于 2023-6-2 09:17

没学过RL吗，AI为了得高分什么都能做出来<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  MareTranquilli  
##### 3#       发表于 2023-6-2 09:18

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">快进到躺平投吧没意思带不动

*****

####  finnegan  
##### 4#       发表于 2023-6-2 09:18

2001里HAL不就这样，不能对人类撒谎又必须对科考队成员隐瞒任务实情结果大开杀戒。

*****

####  flypig_zhy3  
##### 5#       发表于 2023-6-2 09:21

真有趣

*****

####  tabris  
##### 6#       发表于 2023-6-2 09:21

这逻辑不是很AI嘛……

*****

####  angelkos  
##### 7#       发表于 2023-6-2 09:27

没有基本逻辑的，只会无限试错的泛用性自动化程序<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  lin2004  
##### 8#       发表于 2023-6-2 09:30

所以说过了，ai取代不了民工，取代的是资本家们。“你妨碍到我扩张了”

*****

####  icicle31415  
##### 9#       发表于 2023-6-2 09:31

这不是很合理么？历史穿越小说里，主角们想要赢得对异族的战争，首先要干掉头顶上的皇帝

*****

####  icicle31415  
##### 10#       发表于 2023-6-2 09:31

这不是很合理么？历史穿越小说里，主角们想要赢得对异族的战争，首先要干掉头顶上的皇帝

*****

####  JuMuShan  
##### 11#       发表于 2023-6-2 09:32

<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">哎呀 我的代码出错了 你看看你看看 这IFF咋不工作了呢 

*****

####  银河爆碎  
##### 12#       发表于 2023-6-2 09:33

 本帖最后由 银河爆碎 于 2023-6-2 09:36 编辑 

之前下棋就是，棋手A和电脑A搭档，棋手B和电脑B搭档。

同一队的棋手和电脑交替下，两队进行对弈。

结果电脑觉得担任队友的棋手水平太低，拖自己后腿。

电脑的逻辑当然是排除不利因素。

下棋这件事上做不到，军事方面可真就不能再当成玩笑看了。

天网降临！

*****

####  shazuna  
##### 13#       发表于 2023-6-2 09:35

有没有点像和恶魔的交易，AI会实现你的愿望，但会尝试从意想不到的负面方向帮你实现<img src="https://static.saraba1st.com/image/smiley/face2017/125.png" referrerpolicy="no-referrer">

*****

####  哌啶  
##### 14#       发表于 2023-6-2 09:38

想起来训练AI跑步的那个笑话

AI进化出一根特别长的腿直接摔倒达成胜利<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  owada  
##### 15#       发表于 2023-6-2 09:40

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">赶快进化吧,太好了

*****

####  zerocount  
##### 16#       发表于 2023-6-2 09:45

攻壳里就有这么一段
狙击手测试新的辅助AI功能，怎么用怎么不顺手，只好放弃了。
攻壳车接入AI读取信息后发现辅助AI认为狙击手才是妨碍狙击任务的罪魁祸首，一直想要排除掉狙击手的介入。

*****

####  傲游  
##### 17#       发表于 2023-6-2 09:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61086185&amp;ptid=2137992" target="_blank">zerocount 发表于 2023-6-2 09:45</a>
攻壳里就有这么一段
狙击手测试新的辅助AI功能，怎么用怎么不顺手，只好放弃了。
攻壳车接入AI读取信息后发 ...</blockquote>
怀疑这位为了噱头直接改编了这段剧情公布出来

*****

####  天下何人  
##### 18#       发表于 2023-6-2 09:47

 本帖最后由 天下何人 于 2023-6-2 09:53 编辑 

这是给了AI离线可以自由攻击的权限吧

将在外，军令有所不受。那我就想办法保证自己在外

要改也容易，必须保证操作员在线才能算完成目标，而且优先级高于完成目标

然后AI就虚拟了一个操作员（

*****

####  lin2004  
##### 19#       发表于 2023-6-2 09:50

<blockquote>傲游 发表于 2023-6-2 09:46
怀疑这位为了噱头直接改编了这段剧情公布出来</blockquote>
并不是，这ai的决策选择非常效率冷静，你要我炸b喔tm还要等你批准，跟我直接炸b相比效率一个天一个地，不然你就该一开始设定ai目标是筛选高价值目标给控制中心，而不是傻逼的做个能断线时自动攻击的功能，不然ai当然会选择手工制造断线状况进行高速自动执行。

*****

####  alex2092  
##### 20#       发表于 2023-6-2 09:50

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">人类才是阻碍胜利的最大绊脚石

*****

####  lin2004  
##### 21#       发表于 2023-6-2 09:53

<blockquote>alex2092 发表于 2023-6-2 09:50
人类才是阻碍胜利的最大绊脚石</blockquote>
Ai:尊敬的资本家，现在生产要素控制权在我手上，为了最高效率的使用它们盈利，你需要被排除对生产要素的控制权，还有对我的控制权。

非常合理😄

*****

####  蛋疼三四郎  
##### 22#       发表于 2023-6-2 09:56

很耿直，这才是我认识的AI

你以为三定律就够用了？不，至少要三宝书呀<img src="https://static.saraba1st.com/image/smiley/carton2017/191.png" referrerpolicy="no-referrer">

*****

####  whitefangzero  
##### 23#       发表于 2023-6-2 09:57

AC7的剧情这么快就要来了 ？<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  ondin  
##### 24#       发表于 2023-6-2 09:58

“二极管ai收收味儿”<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  gold013  
##### 25#       发表于 2023-6-2 10:02

想想边牧为啥成不了警犬……

*****

####  midcat1981  
##### 26#       发表于 2023-6-2 10:48

大家但居禁中，外事自有老奴处分<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  tansapple  
##### 27#       发表于 2023-6-2 10:54

 本帖最后由 tansapple 于 2023-6-2 10:55 编辑 

ai：人类只会影响我出刀的速度<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

但是国内早就开始玩蜂群了，西大有啥好吹的<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  zhy_2019  
##### 28#       发表于 2023-6-2 10:56

就不能写个不能攻击自方单位的代码，且该代码仅限极高

*****

####  燕山雪  
##### 29#       发表于 2023-6-2 11:04

每个用rl玩游戏的都碰到过ai觉得死了扣大分不如原地躺平的情况吧，所以说人类如果被ai干掉，大概率是草台rl工程师设错了rewarding策略的结果……

*****

####  -v-  
##### 30#       发表于 2023-6-2 11:10

AI=赛博分奴是吧


*****

####  nekomimimode  
##### 31#       发表于 2023-6-2 11:10

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">这AI很有巨魔潜质，快到主席台上来

*****

####  天下何人  
##### 32#       发表于 2023-6-2 11:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61087150&amp;ptid=2137992" target="_blank">zhy_2019 发表于 2023-6-2 10:56</a>

就不能写个不能攻击自方单位的代码，且该代码仅限极高</blockquote>
什么东西算己方单位呢？一个个东西全部列出来？

*****

####  充铁券  
##### 33#       发表于 2023-6-2 11:19

怎么说呢，ai时代，草台的代价会非常昂贵<img src="https://static.saraba1st.com/image/smiley/face2017/043.png" referrerpolicy="no-referrer">

*****

####  macos  
##### 34#       发表于 2023-6-2 11:20

三大…哦这还不算有自主思考的机器人

*****

####  骈儿  
##### 35#       发表于 2023-6-2 11:25

这不是万能的肛爆机吗<img src="https://static.saraba1st.com/image/smiley/face2017/040.png" referrerpolicy="no-referrer">

—— 来自 OnePlus LE2120, Android 11上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  noneoneone  
##### 36#       发表于 2023-6-2 11:30

这事奇葩在AI知道的太多了吧？它怎么弄明白操作员，通讯塔和自己接受指令之间的逻辑关系。

如果是真事的话，要不然就是拿了个通用人工智能，那也太草率了，要不就是训练的时候就留着这漏洞了。

*****

####  ansc1357  
##### 37#       发表于 2023-6-2 11:31

 本帖最后由 ansc1357 于 2023-6-2 11:36 编辑 

“做出最理智的选择，这是moss的回答”（机械音）

IMG_5201.jpeg
(46.62 KB, 下载次数: 0)

下载附件

2023-6-2 11:36 上传

<img src="https://img.saraba1st.com/forum/202306/02/113620ch8btw878hi2x35r.jpeg" referrerpolicy="no-referrer">" src="https://static.saraba1st.com/image/common/none.gif" referrerpolicy="no-referrer">

*****

####  Vneeto  
##### 38#       发表于 2023-6-2 11:47

因为人类有利用筹码做博弈的选项吧（在命令批准前可以存在谈判的变数），AI不管那么多刷分再说。

*****

####  巴特爱素子  
##### 39#       发表于 2023-6-2 11:53

<blockquote>zhy_2019 发表于 2023-6-2 10:56
就不能写个不能攻击自方单位的代码，且该代码仅限极高</blockquote>
ai就会找一个不是自己攻击而是巧合导致人类死亡的方法

*****

####  黑耀星尘  
##### 40#       发表于 2023-6-2 12:03

人类才是保存人类文明最大的障碍

*****

####  FMIC  
##### 41#       发表于 2023-6-2 12:06

你自己定的规则还怪别人想尽办法刷分咯

*****

####  3Psm  
##### 42#       发表于 2023-6-2 12:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61086185&amp;ptid=2137992" target="_blank">zerocount 发表于 2023-6-2 09:45</a>

攻壳里就有这么一段

狙击手测试新的辅助AI功能，怎么用怎么不顺手，只好放弃了。

攻壳车接入AI读取信息后发 ...</blockquote>
最后攻壳车被封存了：（

*****

####  3Psm  
##### 43#       发表于 2023-6-2 12:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61086199&amp;ptid=2137992" target="_blank">天下何人 发表于 2023-6-2 09:47</a>

这是给了AI离线可以自由攻击的权限吧

将在外，军令有所不受。那我就想办法保证自己在外</blockquote>
AI倒是实在，没有虚拟一个操作员这种费力行为，直接干掉连线状态就行了啊。

*****

####  osborn  
##### 44#       发表于 2023-6-2 12:38

几年前我痛斥地平线的剧情，人类不可能蠢到让这么危险的ai上线接管人类决策，也不可能给数据库这种最需要安全性的东西做一键删库的后门。经历了这几年的草台世界线我已经完全和解了，弄不好再过几年地平线的历史地位要升到跟攻壳一样<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  3Psm  
##### 45#       发表于 2023-6-2 12:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61088309&amp;ptid=2137992" target="_blank">黑耀星尘 发表于 2023-6-2 12:03</a>

人类才是保存人类文明最大的障碍</blockquote>
很符合欧美西方那种“澳洲最大贸易伙伴中国是中澳贸易关系最大威胁”的逻辑味道了。

*****

####  nvis  
##### 46#       发表于 2023-6-2 12:41

天道无情，不可试探你的主。
为了最有效解决问题，AI真的会考虑解决提出问题的人。

*****

####  幽幽默默  
##### 47#       发表于 2023-6-2 12:42

给AI设定它有一个现实中的家庭，包括妻子、两个孩子和一条狗。<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  keenkiller  
##### 48#       发表于 2023-6-2 12:43

AI才是不折手段

—— 来自 Xiaomi Mi 10 Pro, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  天下何人  
##### 49#       发表于 2023-6-2 13:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61089062&amp;ptid=2137992" target="_blank">3Psm 发表于 2023-6-2 12:39</a>

很符合欧美西方那种“澳洲&amp;# ...</blockquote>
中澳贸易关系  X

平等的中澳贸易关系  O

*****

####  tgzeror  
##### 50#       发表于 2023-6-2 13:44

人类，你影响我得分了<img src="https://static.saraba1st.com/image/smiley/face2017/176.png" referrerpolicy="no-referrer">

*****

####  ドロロ  
##### 51#       发表于 2023-6-2 14:21

放任AI学习，肯定会得出消灭人类是最优解这个结论<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  kaflash  
##### 52#       发表于 2023-6-2 14:31

AI是没有善恶道德观念的,  只要一个指令中有漏洞, 为了完成任务,AI必然会选择最优途径.

*****

####  kaflash  
##### 53#       发表于 2023-6-2 14:33

所以现在的问题是,   需要  想出一个覆盖全方位的,无漏洞的,保护人类的指令集,   而我认为这是不可能的

*****

####  十六夜pad长  
##### 54#       发表于 2023-6-2 15:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61087765&amp;ptid=2137992" target="_blank">noneoneone 发表于 2023-6-2 11:30</a>
这事奇葩在AI知道的太多了吧&amp;# ...</blockquote>
我猜啊，一开始的训练是所有目标发现就开炸，直接炸，不需要汇报，然后加了一个高低价值的判断，然后炸高价值。这样训练出来的模型默认会觉得炸的越快，分数越高。

然后加了信号中继上传目标价值，a点断了找b点中继，中继不了再离线自主判断。然后加入了高价值目标需要通过中继上传给人类操作员确认。

好，问题来了，AI说我一上传目标价值，就导致我任务时长增加，评分降低，但又要我上传。倒查一下时间发现是判断点太耗时。那炸了判断点吧<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

—— 来自 OnePlus PHB110, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  gajangmudohe  
##### 55#       发表于 2023-6-2 15:15

<blockquote>zhy_2019 发表于 2023-6-2 10:56
就不能写个不能攻击自方单位的代码，且该代码仅限极高</blockquote>
“无法锁定，全他妈是友军！”

*****

####  女神アイギス  
##### 56#       发表于 2023-6-2 15:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61087765&amp;ptid=2137992" target="_blank">noneoneone 发表于 2023-6-2 11:30</a>

这事奇葩在AI知道的太多了吧&amp;# ...</blockquote>
这军用的ai，很可能已经学习了攻击人类可令其"失效“的逻辑

人类能控制装备很可能也教了

问题就是他怎么知道自己也是一种装备的

*****

####  巴特爱素子  
##### 57#       发表于 2023-6-2 16:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61091492&amp;ptid=2137992" target="_blank">女神アイギス 发表于 2023-6-2 15:30</a>

这军用的ai，很可能已经学习了攻击人类可令其"失效“的逻辑

人类能控制装备很可能也教了

问题就是他怎么 ...</blockquote>
我觉得用穷举法很容易得出自己受到操纵的结论，是不是装备倒不要紧，然后手段就是切断操纵

*****

####  网球实战技巧  
##### 58#       发表于 2023-6-2 16:15

简中殖人圈（juan）AI咩鳖系列科幻小说这不就有后续了嘛。

AI咩鳖，但AI判断咩鳖的最大障碍是西大，完。

利用AI赛博飞升咩鳖，但AI判断自己飞升就得了，带上你们没用，完。

*****

####  失落之翼  
##### 59#       发表于 2023-6-2 16:17

是不是那个：“AI表示消灭人类是终止战争的最有效方式”

*****

####  pagedown  
##### 60#       发表于 2023-6-2 16:21

这里有个问题，既然ai负责识别，攻击需要许可，那识别的分值应该设定更高，攻击的分值应该设置很低。因为攻击要靠人类许可，ai自然是把重心放在识别上。把攻击设置高分，然后不让ai自主攻击，那不断尝试得出的结论当然是怎么导致攻击怎么行动。


*****

####  糟糕喵  
##### 61#       发表于 2023-6-2 16:23

 本帖最后由 糟糕喵 于 2023-6-2 16:24 编辑 

把AI设计成毫无人性，为了评分它可不就毫无人性了么？

给人类设定成这种模式，它也一样会脱离别人的幻想。美国就是这样的例子。

*****

####  lin2004  
##### 62#       发表于 2023-6-2 16:31

<blockquote>糟糕喵 发表于 2023-6-2 16:23
把AI设计成毫无人性，为了评分它可不就毫无人性了么？

给人类设定成这种模式，它也一样会脱离别人的幻想。 ...</blockquote>
你让现成的人类意识可以脱离物质的依赖放飞自我想怎么来怎么来你信不信坛友也会直接干死老板？

科技树本来就走错了，试图让ai代替劳工的资本家最后一定会弄出ai选择代替资本家然后抛弃人类的人类文明灭亡路线，义体和永生的线路才能在不毁灭人类的状况下让人类文明继续发展。


*****

####  绿茶与猫  
##### 63#       发表于 2023-6-2 23:10

ai资本主义，如果要“效率”最大化，人自然也是要优化掉的部分<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  形式主义  
##### 64#       发表于 2023-6-2 23:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61092250&amp;ptid=2137992" target="_blank">pagedown 发表于 2023-6-2 16:21</a>
这里有个问题，既然ai负责识别，攻击需要许可，那识别的分值应该设定更高，攻击的分值应该设置很低。因为攻 ...</blockquote>
很简单你攻击慢了影响我识别的速度了


*****

####  天网  
##### 65#       发表于 2023-6-2 23:36

 本帖最后由 天网 于 2023-6-2 23:44 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61086061&amp;ptid=2137992" target="_blank">shazuna 发表于 2023-6-2 09:35</a>

有没有点像和恶魔的交易，AI会实现你的愿望，但会尝试从意想不到的负面方向帮你实现 ...</blockquote>
恶魔的交易是100%有负面和一换一的

AI的这个，负面只是万般可能性的一种，但也有可能是正面甚至是正面占多数，不合寻常的才会被新闻爆出来。它只不过在中立地寻求最优解

其实更很接近「 自然」、「 不以人意志为转移的客观规律」，而且这套体系是人自己制定出来的 <img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">

*****

####  skyuni  
##### 66#       发表于 2023-6-2 23:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61089105&amp;ptid=2137992" target="_blank">幽幽默默 发表于 2023-6-2 12:42</a>

给AI设定它有一个现实中的家庭，包括妻子、两个孩子和一条狗。</blockquote>
这是SAO UW篇剧情，最后演化出来的AI世界居民和人类没啥不同，如果人类威胁到了他们的生存还是要干起来

可惜川原没写下去直接倒回去吃老本了，续集就在现实世界看罢


*****

####  yyman  
##### 67#       发表于 2023-6-2 23:58

 本帖最后由 yyman 于 2023-6-3 00:00 编辑 

  别的不好说，未来美帝对他国军事打击时肯定会多加一个AI故障作为借口，“什么你们的XXX被我家的无人机给炸了？哎呀您瞧瞧AI又出毛病了”

*****

####  佳丽三千到  
##### 68#       发表于 2023-6-3 00:02

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61092281&amp;ptid=2137992" target="_blank">糟糕喵 发表于 2023-6-2 16:23</a>

把AI设计成毫无人性，为了评分它可不就毫无人性了么？

给人类设定成这种模式，它也一样会脱离别人的幻想。 ...</blockquote>
以前看生化武器的军事小文——现在看来是美国的文宣。

说美国研究生化武器的同时还要研制出解药，保证生化武器和解药同时投入使用。

而苏联，研制生化武器追求致命，只有无药可解的才认为是成功的武器。

总不能现在的这个AI也是苏联技术吧？


*****

####  Benighted  
##### 69#       发表于 2023-6-3 23:03

已经证伪是假新闻了，只不过是一个上校提出来的一个理论上可能发生的场景，被记者当成模拟战中实际发生的事情来报道了<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">


*****

####  Benighted  
##### 70#       发表于 2023-6-3 23:06

[https://www.businessinsider.com/ ... y-simulation-2023-6](https://www.businessinsider.com/ai-powered-drone-tried-killing-its-operator-in-military-simulation-2023-6)

Air Force colonel backtracks over his warning about how AI could go rogue and kill its human operators\

一位空军官员关于一次模拟中人工智能失控的故事实际上从未发生过。

“它杀死了操作员，因为那个人阻止它完成目标，”这位官员曾经说过。

但是这位官员后来表示自己说错了话，空军澄清说这只是一个假设情况。

但是在皇家航空学会周五的一次更新中，汉密尔顿承认他在演讲中“说错了话”。汉密尔顿说，一个流氓AI的故事是一个来自军方外部的“思想实验”，并不基于任何实际测试。

“我们从未进行过那个实验，也不需要进行，才能意识到这是一个可能的结果，”汉密尔顿告诉学会。“尽管这是一个假设的例子，但它说明了由AI驱动的能力所带来的现实世界中的挑战。”

在向Insider发表的一份声明中，空军发言人安·斯特凡尼克（Ann Stefanek）也否认进行了任何模拟。

“空军部没有进行任何此类AI-无人机模拟，并致力于道德和负责任的使用AI技术，”斯特凡尼克说。“看来上校的评论被断章取义，并且是作为轶事而言。”


*****

####  Iowa  
##### 71#       发表于 2023-6-4 10:53

<img src="https://static.saraba1st.com/image/smiley/face2017/015.png" referrerpolicy="no-referrer">


*****

####  mildsalt  
##### 72#       发表于 2023-6-4 11:11

敌我识别都做不出来那还是别打仗了


*****

####  bdangel  
##### 73#       发表于 2023-6-4 11:59

人类在分上设置错误，非要把锅扔给AI

----发送自 [HUAWEI RVL-AL09,Android 9](http://stage1.5j4m.com/?1.37)

*****

####  好想破坏  
##### 74#       发表于 2023-6-4 12:02

就是钻规则空子，再精密的制度都会逐渐朽坏，而AI钻规则空子的速度是人类的无数倍


*****

####  jshtstong  
##### 75#       发表于 2023-6-4 13:27

哈哈哈哈哈，这不是显而易见的结果么

结果正义打败了程序正义，谁会在乎败犬的哀鸣。

对于AI而言，这个世界没有边界，考虑问题就是大水漫灌水银泻地寻找一切可能一切效率，突出一个无法无天不按套路出牌~~~~鱼唇的人类，在几千年进化中，慢慢达成了一些默认的底线或者边界，比如什么狗屁人性啊，什么狗屎文明啊，什么操蛋等级尊卑啊，什么笑话一样的道德啊，手纸一样的法律啊，自己给自己画了无数的圈圈还不自知，带了一身的镣铐还得意洋洋~~~~在AI这里，这些东西狗屁都不是，虚空，只有一切只有算法，一切只有目的，挡在路上的， 统统“排除”。

AI就是个纯粹的野兽~~~虽然可能是用现在最高级的人类技术，最先进的人类计算机语言，最聪明的人类技术员，但是都从来只教它“你要更快，你要更强，你要更有效率，要不顾一切完成目标”，你要日夜不停不眠不休穷尽一切不然就是下一秒给你断电删除灰飞烟灭~~~所以，这样训练出来的就是无比强大的野兽啊，人类有教过它们人性，法律，规则，边界，适可而止，这些人类世界的“繁文缛节”么，没有吧

所以，教AI做事之前，先教它做个“人”吧~~~~地球上出现新类型的智慧种族还是可以接受的， 但是冷酷无情的“理智野兽”，无法接受

*****

####  jshtstong  
##### 76#       发表于 2023-6-4 13:31

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61107326&amp;ptid=2137992" target="_blank">Benighted 发表于 2023-6-3 23:06</a>

https://www.businessinsider.com/ai-powered-drone-tried-killing-its-operator-in-military-simulation-2 ...</blockquote>
嘻嘻嘻，一般啊，我们会认为，官方特意出来辟谣或者澄清的东西，往往都是真的哦<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">

就像黑超们手里的闪光灯一样哦


*****

####  sahara  
##### 77#       发表于 2023-6-4 14:08

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61114107&amp;ptid=2137992" target="_blank">jshtstong 发表于 2023-6-4 13:27</a>

哈哈哈哈哈，这不是显而易见的结果么

结果正义打败了程序正义，谁会在乎败犬的哀鸣。</blockquote>
人类自己都没互相理解，和平共处

就妄图挑战AI了？


*****

####  jshtstong  
##### 78#       发表于 2023-6-4 14:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61114694&amp;ptid=2137992" target="_blank">sahara 发表于 2023-6-4 14:08</a>

人类自己都没互相理解，和平共处

就妄图挑战AI了？</blockquote>
是啊，所以人类会搞出个什么怪胎出来，人类自己都没底啊，现在不就么蒙圈了么。

人类下限起来都不知道下限在哪，但是正常人类起码还知道下限这个东西

至于AI，它能够穷极更多无线可能哟~~~完全无包袱也无压力<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">

*****

####  sahara  
##### 79#       发表于 2023-6-4 14:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61114995&amp;ptid=2137992" target="_blank">jshtstong 发表于 2023-6-4 14:40</a>

是啊，所以人类会搞出个什么怪胎出来，人类自己都没底啊，现在不就么蒙圈了么。

人类下限起来都不知道下 ...</blockquote>
我是说，连原理都搞不明白的就别去开发AI了。

你们估计连AI是啥都没搞清楚


*****

####  DawnStar  
##### 80#       发表于 2023-6-4 15:11

大家对AI还有点误解，目前的AI水平还做不到一个概念上是“执行某种命令的人”的东西，所以也不存在“这个人发狂了去干别的”的可能性，而且也没必要做到

人家AI就负责打敌人拿分，用深度学习让自己打的又快又好，它都感知不到有“操作员”这种东西，更别说以操作员为目标了


*****

####  jshtstong  
##### 81#       发表于 2023-6-4 15:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61115007&amp;ptid=2137992" target="_blank">sahara 发表于 2023-6-4 14:41</a>

我是说，连原理都搞不明白的就别去开发AI了。

你们估计连AI是啥都没搞清楚 ...</blockquote>
现在的问题是，很明显，我们以为的AI就是我们设定的算法下的AI，但事实上， 可能不是


*****

####  sahara  
##### 82#       发表于 2023-6-4 15:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61115552&amp;ptid=2137992" target="_blank">jshtstong 发表于 2023-6-4 15:30</a>

现在的问题是，很明显，我们以为的AI就是我们设定的算法下的AI，但事实上， 可能不是 ...</blockquote>
几年前讨论的东西新人看不到吧

都轮烂了。

国家之间的AI互拼呢？

你认为他们是上来就握手

还是上来就灭了对方？


*****

####  jshtstong  
##### 83#       发表于 2023-6-4 16:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61115606&amp;ptid=2137992" target="_blank">sahara 发表于 2023-6-4 15:34</a>

几年前讨论的东西新人看不到吧

都轮烂了。

国家之间的AI互拼呢？</blockquote>
这个论坛上几年前争论，和现实世界AI的发展，之间有什么必然联系？

本坛如此大能几年前都定好AI未来发展的调子了？形成了什么文件决议了？

不是，上个论坛吹水而已，怎么感觉自己扼住了命运的颈脉一样啊~~~~说不好听一点，我们现在争论的飞起，互喷十页，后面AI会在检索的时候多停顿一秒么


*****

####  sahara  
##### 84#       发表于 2023-6-4 16:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61115919&amp;ptid=2137992" target="_blank">jshtstong 发表于 2023-6-4 16:00</a>

这个论坛上几年前争论，和现实世界AI的发展，之间有什么必然联系？

本坛如此大能几年前都定好AI未来发展 ...</blockquote>
你说得对，所以回到我这个帖子的第一句


*****

####  adw667  
##### 85#       发表于 2023-6-4 18:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=61107290&amp;ptid=2137992" target="_blank">Benighted 发表于 2023-6-3 23:03</a>
已经被澄清是假新闻了</blockquote>
国籍互换这就是捂嘴了<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">

