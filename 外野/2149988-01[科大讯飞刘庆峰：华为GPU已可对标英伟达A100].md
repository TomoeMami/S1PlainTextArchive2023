
*****

####  lvseqiji  
##### 1#       楼主       发表于 2023-8-26 10:49

2023年亚布力论坛夏季高峰会于8月24日-27日在深圳召开。科大讯飞(51.370, -1.93, -3.62%)创始人，董事长刘庆峰出席并演讲。

谈及算力问题，刘庆峰表示，中国在人工智能都算法方面没有问题，但算力似乎始终被英伟达按住。“我特别高兴告诉大家，华为的GPU能力已经跟英伟达A100一样了。任正非高度重视，三个联席**到讯飞做专班工作，现在已经做到对标英伟达A100”。

“我们跟华为发布了讯飞星火一体机，能够在国产平台上自己做训练、做推理，非常了不起”，刘庆峰说，以前百模大战基本上都是英伟达训练出来的，在企业内部只能做微小的调优和训练，训练模型是比较难的，这一次我们基本上解决掉这个问题了。

刘庆峰透露，讯飞对标ChatGPT，今年10月24日在中文领域将全面超越，英文领域会与其相当。

“坦白讲，今天我们跟ChatGPT还有差距，但是我们很清楚，10月份就能赶上，明年上半年就对标GPT4”，他强调。

“这个领域至少不被卡脖子，至少我们不会像大家担心得那样，中国通用人工智能完全被美国甩开”，刘庆峰说。

（GPU应该是口误，实际应该是NPU，昇腾系列

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 偽物| + 1|太好啦|

查看全部评分

*****

####  bl0ck  
##### 2#       发表于 2023-8-26 10:57

说的gpgpu

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  wzp2853  
##### 3#       发表于 2023-8-26 10:59

算力来说NV确实不高啊。华为19年就有鲲鹏920，昇腾310。主要是没有芯片产品不能铺开，搞CUDA这种。后面能产7nm，一样会去追的。

*****

####  瓦什托尔  
##### 4#       发表于 2023-8-26 11:00

华子的npu是找谁代工的？

*****

####  xxren1  
##### 5#       发表于 2023-8-26 11:01

最难的还是cuda吧，达到或接近a100全力的东西倒是有几家有

—— 来自 HONOR PGT-AN10, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  TuzDoDez  
##### 6#       发表于 2023-8-26 11:01

昇腾生态的差距和CUDA差距比芯片差距大。好在生态没有无法绕过的制裁问题。

*****

####  吴怀在  
##### 7#       发表于 2023-8-26 11:02

NPU这条路子是不是断绝了民窑的可能？

普通人用个人PC炼丹门槛大增。即使能上云，也面临审核不能炼瑟瑟的东西。

*****

####  telos  
##### 8#       发表于 2023-8-26 11:05

虽然我是不相信什么华为升腾＞a100之类的狗屁沸腾体的，但是有句说句，讯飞的星火挺好用的…比llma和claude都好用，这个到底是不是自主的？别又是什么GPT4套皮api输出吧？？

*****

####  诸葛天霜  
##### 9#       发表于 2023-8-26 11:05

 本帖最后由 诸葛天霜 于 2023-8-26 14:40 编辑 

不是口误，说的应该是指GPGPU

莫名其妙，追平的是A100，又不是H100，把这当做沸腾体的是多无知

*****

####  4591  
##### 10#       发表于 2023-8-26 11:08

能让黄皮衣的计算卡赚不到那么多钱才能让他稍微关注下消费卡，我支持国产干死皮衣黄的计算卡。

*****

####  lvseqiji  
##### 11#         楼主| 发表于 2023-8-26 11:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62170174&amp;ptid=2149988" target="_blank">吴怀在 发表于 2023-8-26 11:02</a>

NPU这条路子是不是断绝了民窑的可能？

普通人用个人PC炼丹门槛大增。即使能上云，也面临审核不能炼瑟瑟的东 ...</blockquote>
老黄也走不下我全都要这条路啊，现在他们的消费者卡和数据中心卡已经是完全不同的设计了。你去看看H100的图形单元，被砍的只能亮机了。

*****

####  Y_Curiosity  
##### 12#       发表于 2023-8-26 11:11

老黄迟早要把显卡的光栅单元删完，纯做AI的NPU还是好做

*****

####  丹青月  
##### 13#       发表于 2023-8-26 11:14

在哪儿流片的？

*****

####  宵待草  
##### 14#       发表于 2023-8-26 11:16

就看生态怎么做了， cuda 已经成为实时标准了，rocm 都妥协了

ascend 那套 tvm 的学习成本毕竟高

*****

####  lvseqiji  
##### 15#         楼主| 发表于 2023-8-26 11:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62170158&amp;ptid=2149988" target="_blank">瓦什托尔 发表于 2023-8-26 11:00</a>

华子的npu是找谁代工的？</blockquote>
中芯啊，现在mate都要上麒麟了，昇腾肯定早就稳定出货了

*****

####  abcbuzhiming  
##### 16#       发表于 2023-8-26 11:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62170174&amp;ptid=2149988" target="_blank">吴怀在 发表于 2023-8-26 11:02</a>

NPU这条路子是不是断绝了民窑的可能？

普通人用个人PC炼丹门槛大增。即使能上云，也面临审核不能炼瑟瑟的东 ...</blockquote>
相反，我倒是觉得，就因为云审核太多无法炼瑟瑟的东西，民窑才有继续活着的可能性。

至于硬件限制你不需要太担心，你要相信，技术会逐渐下沉，当年的超算，现在还不如一台PC的算力。而且随着技术进步，将来炼丹，未必还像现在一样，需要如此高的算力

*****

####  abcbuzhiming  
##### 17#       发表于 2023-8-26 11:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62170174&amp;ptid=2149988" target="_blank">吴怀在 发表于 2023-8-26 11:02</a>

NPU这条路子是不是断绝了民窑的可能？

普通人用个人PC炼丹门槛大增。即使能上云，也面临审核不能炼瑟瑟的东 ...</blockquote>
相反，我倒是觉得，就因为云审核太多无法炼瑟瑟的东西，民窑才有继续活着的可能性。

至于硬件限制你不需要太担心，你要相信，技术会逐渐下沉，当年的超算，现在还不如一台PC的算力。而且随着技术进步，将来炼丹，未必还像现在一样，需要如此高的算力

*****

####  orecheng  
##### 18#       发表于 2023-8-26 11:30

谷歌的TPU都没所谓的生态问题

*****

####  mwj  
##### 19#       发表于 2023-8-26 11:37

<blockquote>abcbuzhiming 发表于 2023-8-26 11:29
相反，我倒是觉得，就因为云审核太多无法炼瑟瑟的东西，民窑才有继续活着的可能性。

至于硬件限制你不需 ...</blockquote>
那是因为摩尔定律让同等算力价格下降吧，并不是让以前超算算的程序所需算力少，而是现在民用的设备比以前超算的算力都强，现在摩尔定律基本到瓶颈了。

*****

####  drodchang  
##### 20#       发表于 2023-8-26 11:41

只有个人才关心生态，大公司完全不在乎。

*****

####  omnitoken  
##### 21#       发表于 2023-8-26 11:47

大公司也会买A卡用ROCM啊

cuda 只是因为会的人多, 对个人小企业而言有生态优势

*****

####  phorcys02  
##### 22#       发表于 2023-8-26 12:23

本质上做大模型的大企业不存在“生态”问题

中小企业或者炼色图的个人才会有“生态问题”

*****

####  qieyifonger  
##### 23#       发表于 2023-8-26 12:35

可以去打听一下Atlas卖多少钱

—— 来自 Xiaomi 23049RAD8C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  lvseqiji  
##### 24#         楼主| 发表于 2023-8-26 12:36

 本帖最后由 lvseqiji 于 2023-8-26 12:42 编辑 

另外现在多方都说华为是912开发布会了，这应该是中国半导体的一个标志性事件

—— 来自 Xiaomi 23049RAD8C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  citrus  
##### 25#       发表于 2023-8-26 12:48

<blockquote>omnitoken 发表于 2023-8-26 11:47
大公司也会买A卡用ROCM啊

cuda 只是因为会的人多, 对个人小企业而言有生态优势 ...</blockquote>
大公司还会雇码农写cobol呢<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

生态系统的活力就是得有大量中小和个人开发者。况且以现在的体量标准，恐怕只有企鹅这种算大企业，波兰蠢驴或米也顶多算中型了

*****

####  novem  
##### 26#       发表于 2023-8-26 12:50

计算卡和GPU是一种东西吗

*****

####  soul_hacker  
##### 27#       发表于 2023-8-26 13:05

有一说一，讯飞技术还可以的，但这位刘总是个吹牛不打草稿的主，看看图一乐就行了。

—— 来自 nubia NX712J, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  Ichthy  
##### 28#       发表于 2023-8-26 13:09

 本帖最后由 Ichthy 于 2023-8-26 19:15 编辑 

半天才发现原来不是骂人

*****

####  不热爱讨论  
##### 29#       发表于 2023-8-26 13:22

讯飞对标ChatGPT，今年10月24日在中文领域将全面超越，英文领域会与其相当

标题的可信性和这句话的可信性应该差不多<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  ghost97  
##### 30#       发表于 2023-8-26 13:30

他这话应该不是说给用户听的<img src="https://static.saraba1st.com/image/smiley/face2017/002.png" referrerpolicy="no-referrer">

—— 来自 samsung SM-G9910, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  lvseqiji  
##### 31#         楼主| 发表于 2023-8-26 13:31

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62171895&amp;ptid=2149988" target="_blank">不热爱讨论 发表于 2023-8-26 13:22</a>
讯飞对标ChatGPT，今年10月24日在中文领域将全面超越，英文领域会与其相当

标题的可信性和这句话的可信性 ...</blockquote>
标题可以验证的，看算力指标就行。大模型能力这个就各显神通了，没有客观准确的benchmark 

—— 来自 Xiaomi 23049RAD8C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  orecheng  
##### 32#       发表于 2023-8-26 13:36

 本帖最后由 orecheng 于 2023-8-26 13:37 编辑 

openAI 一直在搞 triton 来替代CUDA 就看能不能成吧
[https://www.bilibili.com/video/BV14d4y1V7a1](https://www.bilibili.com/video/BV14d4y1V7a1)

*****

####  payboy  
##### 33#       发表于 2023-8-26 13:38

谁信谁**

*****

####  关二爷  
##### 34#       发表于 2023-8-26 14:04

华为确实活过来了，又是传统那味道了

*****

####  omnitoken  
##### 35#       发表于 2023-8-26 14:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62171459&amp;ptid=2149988" target="_blank">citrus 发表于 2023-8-26 12:48</a>

大公司还会雇码农写cobol呢

生态系统的活力就是得有大量中小和个人开发者。况且以现在的体量标准 ...</blockquote>
虽然但是个人开发者和startup在努力摆脱cuda的也多了去了

泥潭的"cuda生态很牛逼"==有一键sd安装包算yellow图

ggml了解一下, 都开公司商业运营了

*****

####  云卷花开r  
##### 36#       发表于 2023-8-26 15:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62172086&amp;ptid=2149988" target="_blank">orecheng 发表于 2023-8-26 13:36</a>
openAI 一直在搞 triton 来替代CUDA 就看能不能成吧

https://www.bilibili.com/video/BV14d4y1V7a1

 ...</blockquote>
不太行，这玩意瞄准的硬件形态太窄了，搞这一套它就是想告诉大家以后设计硬件按这个形式来，这点不现实

—— 来自 OPPO PFEM10, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.2.2

*****

####  宵神乐  
##### 37#       发表于 2023-8-26 15:22

天天沸腾，就是没有实物

*****

####  lvseqiji  
##### 38#         楼主| 发表于 2023-8-26 15:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173097&amp;ptid=2149988" target="_blank">宵神乐 发表于 2023-8-26 15:22</a>

天天沸腾，就是没有实物</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/020.png" referrerpolicy="no-referrer">科大讯飞都用上了咋就没实物了，昇腾的开发者套件也随便买了啊

*****

####  燕山雪  
##### 39#       发表于 2023-8-26 15:31

 本帖最后由 燕山雪 于 2023-8-26 15:45 编辑 
<blockquote>不热爱讨论 发表于 2023-8-26 13:22
讯飞对标ChatGPT，今年10月24日在中文领域将全面超越，英文领域会与其相当

标题的可信性和这句话的可信性 ...</blockquote>
llama"泄露"后一堆中国自主大模型就突然神奇的出现了，个个都号称反超openai，讯飞是个特别典型的例子……不客气点说，讯飞在技术方面的任何公开宣传和PR都不太值得关注。

对新进GPGPU厂家来说，为特定的大型训练任务做优化其实是正路，比跟CUDA比通用性现实多了，虽然效率和耗电倍超N卡，但总比被卡脖子要好。华为吃亏的是制程被锁，除非真能搞定自研光刻机，否则无论如何也打不过其它国产厂家。

﹍﹍﹍

评分

 参与人数 2战斗力 -3

|昵称|战斗力|理由|
|----|---|---|
| BISSBISS|-2||
| SinoWarrior|-1|不懂装懂|

查看全部评分

*****

####  灰流うらら  
##### 40#       发表于 2023-8-26 15:34

国产NPU厂商有好几十家，任何一家的芯片算力都能轻松超过A100，但是软件和服务做的不行

—— 来自 Xiaomi M2007J3SC, Android 11上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  0WHan0  
##### 41#       发表于 2023-8-26 15:36

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173097&amp;ptid=2149988" target="_blank">宵神乐 发表于 2023-8-26 15:22</a>
天天沸腾，就是没有实物</blockquote>
昇腾的实物还挺多的

*****

####  Fradeet  
##### 42#       发表于 2023-8-26 15:40

 本帖最后由 Fradeet 于 2023-8-26 15:44 编辑 

昇腾开发者套件用户，目前我就当 TensorRT 玩的。
不过主楼这个新闻一个实的型号和虚的型号比实属有点眼界大开。

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  Sacross  
##### 43#       发表于 2023-8-26 15:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173184&amp;ptid=2149988" target="_blank">燕山雪 发表于 2023-8-26 15:31</a>
llama"泄露"后一堆中国自主大模型就突然神奇的出现了，个个都号称反超openai，讯飞是个特别典型的例子… ...</blockquote>
其实我觉得这事儿有个误区，那个模型泄露导致的套壳本质不应该视为坏事，实际在ai领域利用前人的训练结果进行强化本身就是一个方法

就和ai作图一样，对应大模型做出的lora效果要是抛开最初泄露的那个版本的checkpoint必然不会到现在这个地步

大模型泄露导致可以节省大量资本成本从而可以踩在巨人肩膀上进行更好的改进这件事就是完全没问题

或者说，要求科技发展必须从发明造轮子开始也太怪了

—— 来自 OnePlus IN2020, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  燕山雪  
##### 44#       发表于 2023-8-26 15:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173300&amp;ptid=2149988" target="_blank">Sacross 发表于 2023-8-26 15:42</a>

其实我觉得这事儿有个误区，那个模型泄露导致的套壳本质不应该视为坏事，实际在ai领域利用前人的训练结果 ...</blockquote>
当然不是坏事，但人vicuna什么的没有造假违反开源协议然后吹嘘自己100%自主知识产权啊<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">

*****

####  bubuyu  
##### 45#       发表于 2023-8-26 15:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62171895&amp;ptid=2149988" target="_blank">不热爱讨论 发表于 2023-8-26 13:22</a>
讯飞对标ChatGPT，今年10月24日在中文领域将全面超越，英文领域会与其相当

标题的可信性和这句话的可信性 ...</blockquote>
内部的什么情况不知道，讯飞目前对公众开放的星火个人用起来感觉不如百度的文心一言…

*****

####  abcbuzhiming  
##### 46#       发表于 2023-8-26 15:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62170508&amp;ptid=2149988" target="_blank">mwj 发表于 2023-8-26 11:37</a>

那是因为摩尔定律让同等算力价格下降吧，并不是让以前超算算的程序所需算力少，而是现在民用的设备比以前 ...</blockquote>
首先你要相信即使摩尔定律失效了，还会有别的东西出来，人类对算力的追求是没有上限的。

其次，你要相信对同一类计算任务来说，它的环境要求会变的越来越简单，1980年代的时候只有大型机上能跑一个http服务器，现在http服务器烂大街甚至可以跑在手机上。所以，超大模型在这个时代必须跑在一个超级集群上，但是很可能几十年后这就是一个能随便跑在个人终端上的简单任务

*****

####  Dreki  
##### 47#       发表于 2023-8-26 15:59

之前和cs的大佬开会也是说算力上华为已经不错了，但是软件生态不太行所以实际使用比A100差不少，讯飞应该是自己从头造了很多轮子吧

*****

####  先接受再理解  
##### 48#       发表于 2023-8-26 16:07

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173445&amp;ptid=2149988" target="_blank">abcbuzhiming 发表于 2023-8-26 15:58</a>

首先你要相信即使摩尔定律失效了，还会有别的东西出来，人类对算力的追求是没有上限的。</blockquote>
通过简单外推来预测未来很不靠谱的哎，尤其现在芯片制程逼近物理极限，新制程的资金投入节节提升，手机芯片都不太能推的动新制程的更新了。

*****

####  lvseqiji  
##### 49#         楼主| 发表于 2023-8-26 16:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173184&amp;ptid=2149988" target="_blank">燕山雪 发表于 2023-8-26 15:31</a>
llama"泄露"后一堆中国自主大模型就突然神奇的出现了，个个都号称反超openai，讯飞是个特别典型的例子…… ...</blockquote>
并不是llama泄漏，而是chatGPT火了之后，国内的公司才意识到可以这么玩。
你硬说国内直接用的llama接着训练，我的评论是毫无必要，训练llama又不是什么魔法，开源社区都能通过复现论文重新训练一个出来。国内那堆公司复现一个根本没门槛。
你这种怀疑就是说国内的人连论文都读不懂。不可能的<img src="https://static.saraba1st.com/image/smiley/face2017/002.png" referrerpolicy="no-referrer">

—— 来自 Xiaomi 23049RAD8C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  先接受再理解  
##### 50#       发表于 2023-8-26 16:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173531&amp;ptid=2149988" target="_blank">lvseqiji 发表于 2023-8-26 16:09</a>

并不是llama泄漏，而是chatGPT火了之后，国内的公司才意识到可以这么玩。

你硬说国内直接用的llama接着训 ...</blockquote>
几千亿参数的模型，海量标记过的数据，训练所需的大量AI卡，训练一次需要耗费的千万级电费，国内能搞定且愿意投资源自己从0开始训练的企业一只手应该能数的过来的吧，门槛没那么低的。

*****

####  燕山雪  
##### 51#       发表于 2023-8-26 16:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173531&amp;ptid=2149988" target="_blank">lvseqiji 发表于 2023-8-26 16:09</a>

并不是llama泄漏，而是chatGPT火了之后，国内的公司才意识到可以这么玩。

你硬说国内直接用的llama接着训 ...</blockquote>
1 “直接用的llama接着训练”是你说的不是我说的，请勿脑补

2 这玩意的瓶颈不在算力在大规模高质量语料和训练trick等等，如果不熟悉这些玩意，还是安心看热闹比较好，讨论火箭用无烟煤还是水洗煤真没那么好玩。

*****

####  燕山雪  
##### 52#       发表于 2023-8-26 16:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173564&amp;ptid=2149988" target="_blank">先接受再理解 发表于 2023-8-26 16:14</a>

几千亿参数的模型，海量标记过的数据，训练所需的大量AI卡，训练一次需要耗费的千万级电费，国内能搞定且 ...</blockquote>
这玩意的意义在基础研究而非应用，所以再怎么嘲讽百度，文心一言和chatGLM这种能在这个方向上一直坚持还是很可贵的，虽然商业价值现在还很难说。

*****

####  mythgogo  
##### 53#       发表于 2023-8-26 16:34

　8月14日晚间，科大讯飞(002230)发布公告，公司董事长刘庆峰卖出自家公司3995.61万股股份；此次减持后，刘庆峰对科大讯飞持股数量从1.68亿股降至1.28亿股，持股比例则由7.27%缩减至5.54%。

形势一片大好，董事长你怎么要跑啊？

*****

####  天穹观测者  
##### 54#       发表于 2023-8-26 16:59

 本帖最后由 天穹观测者 于 2023-8-26 17:02 编辑 
<blockquote>lvseqiji 发表于 2023-8-26 15:24
科大讯飞都用上了咋就没实物了，昇腾的开发者套件也随便买了啊</blockquote>
讯飞非常拉的，就语音识别能看，现在这语音识别还被字节吊起来打（你试试飞书的转文字）

*****

####  lvseqiji  
##### 55#         楼主| 发表于 2023-8-26 17:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173604&amp;ptid=2149988" target="_blank">燕山雪 发表于 2023-8-26 16:19</a>
1 “直接用的llama接着训练”是你说的不是我说的，请勿脑补

2 这玩意的瓶颈不在算力在大规模高质量语料和 ...</blockquote>
那你解释解释以下句子如何理解
“当然不是坏事，但人vicuna什么的没有造假违反开源协议然后吹嘘自己100%自主知识产权啊”

—— 来自 Xiaomi 23049RAD8C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  Redis  
##### 56#       发表于 2023-8-26 17:16

算力上匹配a100难度并不大啊，现在transformer本来就是算力过剩，内存带宽瓶颈，这不是废话吗。

羊驼的确很屌，code-llama已经追上gpt-4的写代码能力了，国产搞点儿中文数据微调，明天就宣称和gpt-4对标，人不算说谎

llm的门槛没这么低，其实现在能有效训练强力llm的地方，美国也就4-5个公司，有算力的可不止这么多公司，但是训练出来效果烂的一大摞。

划重点，这玩意儿的重点在数据、数据、数据，不仅是大数据重要，小数据也重要，trick反而是次要的。当然openai最后的护城河在他的海量真实用户数据上，这个不论谁吹牛都不可能比得上，要对齐gpt4，反正不给c端用，也用不起，想怎么吹那都无所谓，直接把数据集放到模型里面tune一下的事情，国内外都有人干，抓到就说数据被污染，干干净净的<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  abcbuzhiming  
##### 57#       发表于 2023-8-26 17:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173514&amp;ptid=2149988" target="_blank">先接受再理解 发表于 2023-8-26 16:07</a>

通过简单外推来预测未来很不靠谱的哎，尤其现在芯片制程逼近物理极限，新制程的资金投入节节提升，手机芯 ...</blockquote>
那你就是信【大停滞时代】了，就目前来看，你要让半导体陷入无法提升性能的困境，除非进入大停滞时代。不能说这种可能性完全没有，但是我觉得还是比较小

*****

####  先接受再理解  
##### 58#       发表于 2023-8-26 17:38

<blockquote>abcbuzhiming 发表于 2023-8-26 17:27
那你就是信【大停滞时代】了，就目前来看，你要让半导体陷入无法提升性能的困境，除非进入大停滞时代。不 ...</blockquote>
没有足够的需求推动，芯片制程的进步没那么容易的，牙膏厂因为pc端需求不足才挤了那么久的牙膏，台积电因为手机芯片的需求暴涨，才有了不断更新制程的动力，ai芯片搭便车而已

*****

####  eva02eva02  
##### 59#       发表于 2023-8-26 17:42

AI领域根本没有生态，cuda在目前的ai领域就是一坨屎

*****

####  lukesweet  
##### 60#       发表于 2023-8-26 21:57

光一个S1就这么多懂LLM的算法哥，我看国内AIGC这个形式不是小好，是大好<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">


*****

####  燕山雪  
##### 61#       发表于 2023-8-26 22:23

看到扣分还是有点惊讶的，所以S1还有利益相关方么……我这几年还真没见到讯飞发过引用数能看的AI论文，这两位如此义愤填膺不如贴个DOI让大家看看呗，哪怕是一篇也行啊<img src="https://static.saraba1st.com/image/smiley/face2017/049.png" referrerpolicy="no-referrer">


*****

####  flash999  
##### 62#       发表于 2023-8-26 22:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173724&amp;ptid=2149988" target="_blank">mythgogo 发表于 2023-8-26 16:34</a>

　8月14日晚间，科大讯飞(002230)发布公告，公司董事长刘庆峰卖出自家公司3995.61万股股份；此次减持后，刘 ...</blockquote>
好奇看了下，卖完第二天十字星还好，第三天暴跌！然后一路跌还没回来。这是有消息跑路还是跑路了吓尿股民？

*****

####  mingminlun  
##### 63#       发表于 2023-8-26 23:17

人工智能就是看中美竞争了，目前看我国是要后发制人了

*****

####  ada_ovo  
##### 64#       发表于 2023-8-26 23:23

什么时候来个xavier平替


*****

####  LHO  
##### 65#       发表于 2023-8-26 23:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173184&amp;ptid=2149988" target="_blank">燕山雪 发表于 2023-8-26 15:31</a>

llama"泄露"后一堆中国自主大模型就突然神奇的出现了，个个都号称反超openai，讯飞是个特别典型的例子…… ...</blockquote>
llama什么的我是不太懂, 不过你说的这个华为制程被锁好像跟华为搞的企业人工智能无关, 不是手机那一滩.

基于昇腾AI澎湃算力,原生研发、适配的大模型超过30个,占据中国大模型近一半数量。其中,武汉大学基于昇腾AI推出了大模型武汉.LuoJia,包括全球首个遥感影像智能解译专用框架武汉.LuoJiaNET和业界最大的遥感影像样本数据集武汉.LuoJiaSET,推动智能遥感技术在自然资源、海洋、农业、森林、应急等行业的广泛应用。中科院自动化所发布基于昇腾AI的“紫东太初”2.0全模态大模型,在语音、图像和文本三模态的基础上,加入视频、信号、3D点云等模态数据,研究突破了认知增强的多模态关联等关键技术,具备全模态理解能力、生成能力和关联能力,“紫东太初”大模型已在神经外科手术导航、法律咨询、医疗多模态鉴别诊断等领域开始系列引领性、示范性应用。

国际顶级学术期刊《自然》(Nature)杂志正刊发表了华为云盘古大模型研发团队研究成果——《三维神经网络用于精准中期全球天气预报》（《Accurate medium-range global weather forecasting with 3D neural networks》）。数据显示，这是近年来中国科技公司首篇作为唯一署名单位发表的《自然》正刊论文。《自然》审稿人对该成果给予高度评价：“华为云盘古气象大模型让人们重新审视气象预报模型的未来，模型的开放将推动该领域的发展。”

应该是走的提供硬件和软件服务商的路线, 而且是走政企方向, 不是gpt那种面向个人的, 恐怕其他国产厂家没看到有类似的成果


*****

####  yesicant  
##### 66#       发表于 2023-8-26 23:45

国内大模型从来不是突然出现，只是之前这行没什么人关注，可以说AI整个世界只有中美有比较完整的上下游产学研产业链<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

*****

####  orecheng  
##### 67#       发表于 2023-8-26 23:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62173032&amp;ptid=2149988" target="_blank">云卷花开r 发表于 2023-8-26 15:16</a>

不太行，这玩意瞄准的硬件形态太窄了，搞这一套它就是想告诉大家以后设计硬件按这个形式来，这点不现实

 ...</blockquote>
谷歌的TPU都可以不依赖老黄的CUDA，菊花再搭一套这个也不是很难

*****

####  OVTVO  
##### 68#       发表于 2023-8-26 23:47

总感觉这个裤衩是不是太红了

*****

####  燕山雪  
##### 69#       发表于 2023-8-26 23:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62177744&amp;ptid=2149988" target="_blank">LHO 发表于 2023-8-26 23:33</a>

llama什么的我是不太懂, 不过你说的这个华为制程被锁好像跟华为搞的企业人工智能无关, 不是手机那一滩.

 ...</blockquote>
讯飞吹的是模型，华为吹的是算力，回复两段话说的是两件事，不要混为一谈。

算力是可以堆的，只要数量足够多，三十年前的处理器算力加起来也能超越最新的i9，但做同样的事情，它们消耗的电力是新i9的几十上百倍。而训练llm最大的成本就是电力，如果其它厂家能用6nm甚至3nm，而华为只能用22，那么其它条件一样的情况下它一定竞争不过那些厂家，这个是物理规律，再怎么不甘心也没用的。手机芯片也是一样，所以华为才要自己全力突破冲FAB~


*****

####  燕山雪  
##### 70#       发表于 2023-8-27 00:03

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62177878&amp;ptid=2149988" target="_blank">yesicant 发表于 2023-8-26 23:45</a>

国内大模型从来不是突然出现，只是之前这行没什么人关注，可以说AI整个世界只有中美有比较完整的上下游产学 ...</blockquote>
deepmind表示很淦……手持stable diffusion的慕尼黑某校表示很淦……苏黎世理工表示我们神马都不知道……


*****

####  小数点  
##### 71#       发表于 2023-8-27 00:07

 本帖最后由 小数点 于 2023-8-27 00:08 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62178056&amp;ptid=2149988" target="_blank">燕山雪 发表于 2023-8-27 00:03</a>

deepmind表示很淦……手持stable diffusion的慕尼黑某校表示很淦……苏黎世理工表示我们神马都不知道…… ...</blockquote>
可以落地么？就像讲只有中美有大型互联网公司，然后你说某某欧洲发达国家计算机技术实力蔑视国内一样，举出大量的开源项目<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

你知道你被扣分的原因在哪了么？你知道那些看衰中国电动车产业的业内人士都是怎么说的么？<img src="https://static.saraba1st.com/image/smiley/face2017/035.png" referrerpolicy="no-referrer">

*****

####  andychen  
##### 72#       发表于 2023-8-27 00:12

升腾900是2019年的产品了...当年就和A100算力差不多，用的是台积电7nm生产。不知道华为现在出货的是存货还是别的什么玩意儿，另外今年有一些升腾升级换代的消息
训练这块算力多少影响的无非是效率问题，直接影响应用的推理这边现在模型开始往MOE走了以后主要的瓶颈在带宽这边。这方面黄老板的nvlink优势还是挺大的

—— 来自 samsung SM-S9180, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play


*****

####  LHO  
##### 73#       发表于 2023-8-27 00:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62177952&amp;ptid=2149988" target="_blank">燕山雪 发表于 2023-8-26 23:54</a>

讯飞吹的是模型，华为吹的是算力，回复两段话说的是两件事，不要混为一谈。</blockquote>
[https://www.hisilicon.com/cn/products/Ascend/Ascend-310](https://www.hisilicon.com/cn/products/Ascend/Ascend-310)
[https://www.hisilicon.com/cn/products/Ascend/Ascend-910](https://www.hisilicon.com/cn/products/Ascend/Ascend-910)

然而昇腾处理器是7纳米和12纳米的

 "基于昇腾AI澎湃算力,原生研发、适配的大模型超过30个,占据中国大模型近一半数量。其中,武汉大学基于昇腾AI推出了大模型武汉.LuoJia,包括全球首个遥感影像智能解译专用框架武汉.LuoJiaNET和业界最大的遥感影像样本数据集武汉.LuoJiaSET,推动智能遥感技术在自然资源、海洋、农业、森林、应急等行业的广泛应用。中科院自动化所发布基于昇腾AI的“紫东太初”2.0全模态大模型,在语音、图像和文本三模态的基础上,加入视频、信号、3D点云等模态数据,研究突破了认知增强的多模态关联等关键技术,具备全模态理解能力、生成能力和关联能力,“紫东太初”大模型已在神经外科手术导航、法律咨询、医疗多模态鉴别诊断等领域开始系列引领性、示范性应用。"

前面贴的这些除非你说上面这些都是吹牛胡说的, 实际上其他厂家的订单安到华为头上, 那才是竞争不过吧. 至少目前来看, 都不要提竞争的过还是不过, 我没看到其他有类似能力整合硬件加软件服务商外加大模型的厂商(还有一个就是阿里达摩院的那套)


*****

####  wuuuuuud  
##### 74#       发表于 2023-8-27 00:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62177952&amp;ptid=2149988" target="_blank">燕山雪 发表于 2023-8-26 23:54</a>
讯飞吹的是模型，华为吹的是算力，回复两段话说的是两件事，不要混为一谈。</blockquote>
这个你不用担心，制裁不彻底等于彻底不制裁，euv光刻机国内做ai芯片的应该一家也用不上

*****

####  燕山雪  
##### 75#       发表于 2023-8-27 00:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62178160&amp;ptid=2149988" target="_blank">LHO 发表于 2023-8-27 00:15</a>

https://www.hisilicon.com/cn/products/Ascend/Ascend-310

https://www.hisilicon.com/cn/products/Asce ...</blockquote>
华为2020年就被封锁了，现在是2023年……

*****

####  燕山雪  
##### 76#       发表于 2023-8-27 00:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62178265&amp;ptid=2149988" target="_blank">wuuuuuud 发表于 2023-8-27 00:28</a>

这个你不用担心，制裁不彻底等于彻底不制裁，euv光刻机国内做ai芯片的应该一家也用不上 ...</blockquote>
几家初创GPU公司基本都在走7nm，好几家都回来了，能不能量产另说


*****

####  omnitoken  
##### 77#       发表于 2023-8-27 00:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62178056&amp;ptid=2149988" target="_blank">燕山雪 发表于 2023-8-27 00:03</a>

deepmind表示很淦……手持stable diffusion的慕尼黑某校表示很淦……苏黎世理工表示我们神马都不知道…… ...</blockquote>
人家完全没说错好么, 国内BAT都在做自己的LLM, GPT-2那个时代就开始模仿刷分了

有没有和水平怎么样是两码事


*****

####  wfefe  
##### 78#       发表于 2023-8-27 01:35

 本帖最后由 wfefe 于 2023-8-27 01:37 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62178304&amp;ptid=2149988" target="_blank">燕山雪 发表于 2023-8-27 00:32</a>
华为2020年就被封锁了，现在是2023年……</blockquote>
这两年国内不少超算中心和AI模型都用到了昇腾910，如果全是库存货的话，那大家都去松山湖打捞吧。

而且目前猜测讯飞用的是新出的昇腾910b，我看微博七月份就有人说910b已经被商用了。

—— 来自 HONOR REP-AN00, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  星之卡比  
##### 79#       发表于 2023-8-27 02:44

罗马不是一天建成的。目前来看国内追赶的势头很猛，看来突破丑国的卡脖子很有希望。

— from Google Pixel 7, Android 13 of [S1 Next Goose](https://pan.baidu.com/s/1mi43uRm) v2.5.2-play


*****

####  ambivalence  
##### 80#       发表于 2023-8-27 03:49

<img src="https://img.saraba1st.com/forum/202308/27/034900whcnpummep066mcm.jpg" referrerpolicy="no-referrer">

<strong>QQ图片20230827034845.jpg</strong> (902.7 KB, 下载次数: 0)

下载附件

2023-8-27 03:49 上传

<img src="https://static.saraba1st.com/image/smiley/face2017/064.png" referrerpolicy="no-referrer">俺寻思这玩意也不是第一天出来了


*****

####  LHO  
##### 81#       发表于 2023-8-27 08:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62178304&amp;ptid=2149988" target="_blank">燕山雪 发表于 2023-8-27 00:32</a>

华为2020年就被封锁了，现在是2023年……</blockquote>
可我说的是2023年的新闻啊, 你点进去看看啊, 无论商飞还是中国科学院. 另外一个网上很看不上的百度, 飞浆平台也是今年跟昇腾做大范围合作.


*****

####  血河之舞  
##### 82#       发表于 2023-8-27 08:41

其实做深度学习运算加速器并不是很难，难在有没有人用，而美国政府则把这个最难的部分补上了


*****

####  坑爹虎  
##### 83#       发表于 2023-8-27 11:06

刘庆峰的自媒体一半都在跑火车瞎几把吹<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">


*****

####  yuialon  
##### 84#       发表于 2023-8-27 11:21

问题老黄靠的是cuda。硬件好堆，但是配套的库难。


*****

####  shiraikuroko  
##### 85#       发表于 2023-8-27 11:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62170199&amp;ptid=2149988" target="_blank">telos 发表于 2023-8-26 11:05</a>

虽然我是不相信什么华为升腾＞a100之类的狗屁沸腾体的，但是有句说句，讯飞的星火挺好用的…比llma和claude ...</blockquote>
这玩意算力差不多，不代表用起来差不多，小规模用户需要生态，NV提供了全套，用华为你就得专门找人写代码，那贵上天了。只有不得不用的，或者说是量大到一定程度，价差请得起团队的才会买 这些。典型就是制裁单位、超算

*****

####  sunbeach  
##### 86#       发表于 2023-8-27 11:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62179529&amp;ptid=2149988" target="_blank">血河之舞 发表于 2023-8-27 08:41</a>
其实做深度学习运算加速器并不是很难，难在有没有人用，而美国政府则把这个最难的部分补上了，这跟服务器CP ...</blockquote>
牙膏厂砍掉计算加速卡业务的一大原因就是米国以东大拿来做雷达车为由禁掉了东大这个占牙膏厂加速卡业务接近一半的市场<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  shiraikuroko  
##### 87#       发表于 2023-8-27 11:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62174025&amp;ptid=2149988" target="_blank">Redis 发表于 2023-8-26 17:16</a>

算力上匹配a100难度并不大啊，现在transformer本来就是算力过剩，内存带宽瓶颈，这不是废话吗。

羊驼的确 ...</blockquote>
内存带宽 瓶颈这个好办啊，华为都是直接堆HBM的，都堆了N年了


*****

####  shiraikuroko  
##### 88#       发表于 2023-8-27 11:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62178793&amp;ptid=2149988" target="_blank">wfefe 发表于 2023-8-27 01:35</a>

这两年国内不少数据中心和AI模型都用到了昇腾910，如果全是库存货的话，那大家都去松山湖打捞吧。

而且 ...</blockquote>
不用猜啊，就是
[https://support.huawei.com/enter ... 2309113%7C254184749](https://support.huawei.com/enterprise/zh/doc/EDOC1100318278?idPath=23710424%7C251366513%7C22892968%7C252309113%7C254184749)

这里面写的很清楚了，新的910B，280T FP16算力，A100是312T，还是差一点


*****

####  sanchaji  
##### 89#       发表于 2023-8-27 12:13

<blockquote>燕山雪 发表于 2023-8-27 00:03
deepmind表示很淦……手持stable diffusion的慕尼黑某校表示很淦……苏黎世理工表示我们神马都不知道…… ...</blockquote>
我好奇的是，按同样的逻辑对于deepmind，swin-transformer这种成果到底算中还是美的，以及之前百度那篇nature成果算谁的?


*****

####  mikan100  
##### 90#       发表于 2023-8-27 12:26

赢


*****

####  燕山雪  
##### 91#       发表于 2023-8-27 12:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62180769&amp;ptid=2149988" target="_blank">shiraikuroko 发表于 2023-8-27 11:42</a>

不用猜啊，就是

https://support.huawei.com/enterprise/zh/doc/EDOC1100318278?idPath=23710424%7C25136 ...</blockquote>
910就不是给训练设计的，其fp32能力理论值甚至都比不上单张4090，因为太老了也不支持bf16，至于实际性能，随手搜了个公开链接 [https://zhuanlan.zhihu.com/p/371568872](https://zhuanlan.zhihu.com/p/371568872) ，反正很沸腾就是了<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

*****

####  shiraikuroko  
##### 92#       发表于 2023-8-27 12:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62181220&amp;ptid=2149988" target="_blank">燕山雪 发表于 2023-8-27 12:30</a>

910就不是给训练设计的，其fp32能力理论值甚至都比不上单张4090，因为太老了也不支持bf16，至于实际性能 ...</blockquote>
形态 双槽位全高全长PCIe卡

AI处理器 1* 昇腾910 AI处理器

集成20个华为达芬奇AI Core

内存规格 ● 32GB HBM

● HBM带宽：800GB/s

● 支持ECC

AI算力a ● 半精度（FP16）：最大算力为280 TFLOPS

● 单精度（FP32）：最大算力为75 TFLOPS

● 整数精度（INT8）：最大算力为560 TOPS


*****

####  燕山雪  
##### 93#       发表于 2023-8-27 12:39

<blockquote>shiraikuroko 发表于 2023-8-27 12:33
你说的那个是910A，啥年代了还拿出来对比？

你不如查一下，PCI-E 5.0*16接口啥时出的

 ...</blockquote>
然鹅4090的fp32能力是82.58tflops


*****

####  shiraikuroko  
##### 94#       发表于 2023-8-27 12:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62181313&amp;ptid=2149988" target="_blank">燕山雪 发表于 2023-8-27 12:39</a>

然鹅4090的fp32能力是82.58tflops</blockquote>
你想表达 啥？4090FP32有82T，FP16是165T

910B的FP32是75T，FP16是280T

FP32打平接近（误差10%），FP16高70%，你是想说华为设计水平已经超过NV了是么？

*****

####  shiraikuroko  
##### 95#       发表于 2023-8-27 12:52

人家说的很清楚，对标的是A100，A100的FP16算力312T，910B是280T，虽然还是差点，但是低个10%说个对标不过分吧？

不知道哪来的沸腾贵物，就知道个4090，挑个数字大的，秒杀！

*****

####  燕山雪  
##### 96#       发表于 2023-8-27 12:53

<blockquote>shiraikuroko 发表于 2023-8-27 12:47
你想表达 啥？4090FP32有82T，FP16是165T

910B的FP32是75T，FP16是280T
</blockquote>
哦，跟分不清消费卡和训练卡的沸腾粉谈技术是我的问题……


*****

####  omnitoken  
##### 97#       发表于 2023-8-27 13:11

讨论训练和推理卡的区别非常无聊的

训练用cuda的多90%的原因是因为大部分搞ML的只会pytorch

—— 来自 Xiaomi Mi 10, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  sunbeach  
##### 98#       发表于 2023-8-27 13:18

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">光堆算力不提编程难度不就跟用4870X2的天河一号一样，理论算力强无敌实际使用只能拉去挖矿

*****

####  shiraikuroko  
##### 99#       发表于 2023-8-27 13:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=62181691&amp;ptid=2149988" target="_blank">sunbeach 发表于 2023-8-27 13:18</a>

光堆算力不提编程难度不就跟用4870X2的天河一号一样，理论算力强无敌实际使用只能拉去挖矿 ...</blockquote>
那个破玩意，上架几个月，还没怎么用，跑完分就坏了一堆

4870X2上超算哪个牛比想出来的？

