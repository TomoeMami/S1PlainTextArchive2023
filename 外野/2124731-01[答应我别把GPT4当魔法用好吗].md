
*****

####  wvv9582  
##### 1#       楼主       发表于 2023-3-19 00:32

先贴下Openai 联合创始人 Ilya Sutskever (就是 2012年 imageNet 比赛中获胜的 Alexnet的创造者之一) 在前几天的一个访谈中的评论: 

"讨论大语言模型的局限性是非常困难的。因为两年前，很多人非常自信的评论大语言模型的局限性，现在这些语言模型完全不一样了... 有一种说法是，这些模型只是去学习统计上的规律，所以它们并不真正理解世界的运作机制。我有不同的看法, 我认为学习这些统计上的规律，比看上去要重要得多得多。... 预测是一种压缩计算。预测也是一种统计现象。要预测，你最后本质还是需要理解生成那些数据的真正的底层机制。要能更好的预测，要能更好的压缩计算, 你需要更好的理解生成这些数据的世界。当我们的生成式模型变得越来越好时，他们会拥有，我称为对世界的’令人震惊的理解力’ ( a shocking degree of understanding ) 和它的很多微妙之处。但这不仅仅是对于世界，这是从文字的棱镜来观察的世界。”

把他所述的令人震惊的理解力重述一下，笔者认为这种理解力是数据量超过某类临界点的情况下，“涌现”出的某种统计特质。但是gpt4在目前这个阶段，仍在逻辑上有着根本的缺失，即gpt不能理解相似之处的相似之处。这个问题从gpt3.5笔者就已经观察到，当需要其理解一些蕴含在文字之内的逻辑时，gpt模型往往会忽略这些逻辑。这样说可能显得有些抽象，我举个例子。

我们知道费马证明了每个模4余1的奇素数都能分解成两个自然数的平方和，所以当我们遇到702001这样偏开放式的问题是，可以先去考虑其是否为素数，然后代入上述的定理。但是gpt在自身上下文的推导中，很容易就会忘记这个素字的重要性，对他来说，素只是一个字，一个token，这个字的权重不会比其他字高太多。对于人类来说则不同，做题的人很容易就会注意到这个题的题眼就是素。（702001=37*18973。）

事实上，根据笔者和一些竞赛背景的人的简单实验，gpt4在生物化学类的竞赛中，大约能获得省二的水平（虽然答的不总是对的，但是能蒙出答案或者有靠谱的思路），数学和物理则要更差一些。笔者个人认为gpt4大约具有任意专业大学本科毕业生的水平，但这是基于它的博闻强记，而不是他的创造力或者是洞察力。这个水平已经相当高了，但由于人类对于大型黑盒子的理解缺失，gpt未来能否拥有更强大的能力，这是人类目前所不能回答的问题。

笔者认为gpt4并不是万能的魔法，只要你的工作是充满创造力的，目前的语言模型就没法替代这份工作。

Screenshot_20230319_000143_com.android.chrome.jpg
(331.79 KB, 下载次数: 0)

下载附件

2023-3-19 00:09 上传

<img src="https://img.saraba1st.com/forum/202303/19/000939fyqfoz2qk9bxoeak.jpg" referrerpolicy="no-referrer">

*****

####  rp1993  
##### 2#       发表于 2023-3-19 00:42

怎么总有人拿自然语言模型去做去数学题……

*****

####  wvv9582  
##### 3#         楼主| 发表于 2023-3-19 00:44

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139018&amp;ptid=2124731" target="_blank">rp1993 发表于 2023-3-19 00:42</a>

怎么总有人拿自然语言模型去做去数学题……</blockquote>
那我肯定还是希望lean成为最强ai的（

*****

####  宏.  
##### 4#       发表于 2023-3-19 00:45

又是一个跑出来问<strong>语言</strong>模型数学题的。根本就没在训练过程中的逻辑，怎么可能在正确的回答？

*****

####  wvv9582  
##### 5#         楼主| 发表于 2023-3-19 00:46

 本帖最后由 wvv9582 于 2023-3-19 00:49 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139041&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 00:45</a>

又是一个跑出来问语言模型数学题的。根本就没在训练过程中的逻辑，怎么可能在正确的回答？ ...</blockquote>
不问数学题问化学题也一样啊，再说我说的是很多人已经把这玩意当魔法用了。假如你需要它给一个（未曾出现过的）有机合成的方案，它也不是总能给出洞见啊。

*****

####  Lucario  
##### 6#       发表于 2023-3-19 00:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139018&amp;ptid=2124731" target="_blank">rp1993 发表于 2023-3-19 00:42</a>

怎么总有人拿自然语言模型去做去数学题……</blockquote>
但是有几个NLP的测试就是做数学题，这是评价模型能力的重要指标之一

*****

####  处男鉴黄师  
##### 7#       发表于 2023-3-19 00:55

数学这种绝大多数人类都学不明白的东西要是AI能学会那距离天网不远了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  battleship64  
##### 8#       发表于 2023-3-19 00:57

真问数学不得从，1+1开始教<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  yesicant  
##### 9#       发表于 2023-3-19 00:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139041&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 00:45</a>
又是一个跑出来问语言模型数学题的。根本就没在训练过程中的逻辑，怎么可能在正确的回答？ ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">数学是形式语言的一种，只是比自然语言更严谨与复杂，如果把全网所有与数学有关的内容甚至主动调优了相关数据都无法解决这个问题，那是不是代表，这条路是错的呢？

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  wvv9582  
##### 10#         楼主| 发表于 2023-3-19 00:59

<blockquote>battleship64 发表于 2023-3-19 00:57
真问数学不得从，1+1开始教

论坛助手,iPhone</blockquote>
其实我有个朋友（图论phd）有一个很好的教会gpt4算一个他的未发表的引理的例子，但是这并不是总能成功。

现在有太多论调说这玩意接近万能了（

*****

####  riczxc  
##### 11#       发表于 2023-3-19 01:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139128&amp;ptid=2124731" target="_blank">yesicant 发表于 2023-3-19 00:57</a>

数学是形式语言的一种，只是比自然语言更严谨与复杂，如果把全网所有与数学有关的内容甚至主动调 ...</blockquote>
是的。考虑OpenAI已经在一月的更新里着重想要解决这个问题，应该是暂时无解： <blockquote>Release Notes (Jan 30)

We’ve upgraded the ChatGPT model with improved factuality and mathematical capabilities.</blockquote>

四位数乘法就不对了，说明没学会。

*****

####  宏.  
##### 12#       发表于 2023-3-19 01:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139055&amp;ptid=2124731" target="_blank">wvv9582 发表于 2023-3-19 00:46</a>

不问数学题问化学题也一样啊，再说我说的是很多人已经把这玩意当魔法用了。假如你需要它给一个（未曾出现 ...</blockquote>
当然给不了，因为没做训练，怎么给？但是探索化学合成和甚至探索物理规律的人工智能已经有了，只不过没有纳入语言模型罢了。

*****

####  wvv9582  
##### 13#         楼主| 发表于 2023-3-19 01:01

<blockquote>宏. 发表于 2023-3-19 01:00
当然给不了，因为没做训练，怎么给？但是探索化学合成和甚至探索物理规律的人工智能已经有了，只不过没有 ...</blockquote>
但是有很多人已经觉得这玩意是魔法了啊亲。。我说他不是万能的，你说他当然不是万能的。。。。

*****

####  jxwats1  
##### 14#       发表于 2023-3-19 01:02

什么时候gpt能拿答数学联赛到省队水平，我就相信强人工智能真的来了

*****

####  wvv9582  
##### 15#         楼主| 发表于 2023-3-19 01:02

<blockquote>jxwats1 发表于 2023-3-19 01:02
什么时候gpt能拿答数学联赛到省队水平，我就相信强人工智能真的来了</blockquote>
lean4已经有省队（弱省）水平了喵

*****

####  yesicant  
##### 16#       发表于 2023-3-19 01:08

 本帖最后由 yesicant 于 2023-3-19 01:09 编辑 

有部分人一直觉得大模型出来之后，所有NLP研究人员都可以休息了，只要堆料与堆参数就能获取智能的大圣杯，但实际上并不是这样，正如此处暴露的弱点，强人工智能必须有严谨的推理能力，才能达到严谨的数学能力，这一切是密切相关的，人类离AGI还远得很呢，加油吧，要做的研究工作还有太多太多，要复现的构件与理论也还有太多太多。

<img src="https://img.saraba1st.com/forum/202303/19/010706r5gpgkd95gfxy45n.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230319-010535.jpg</strong> (312.38 KB, 下载次数: 0)

下载附件

2023-3-19 01:07 上传

<img src="https://img.saraba1st.com/forum/202303/19/010756a114dk1h1ag1p181.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20230318-221321.jpg</strong> (308.61 KB, 下载次数: 0)

下载附件

2023-3-19 01:07 上传

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  宏.  
##### 17#       发表于 2023-3-19 01:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139128&amp;ptid=2124731" target="_blank">yesicant 发表于 2023-3-19 00:57</a>

数学是形式语言的一种，只是比自然语言更严谨与复杂，如果把全网所有与数学有关的内容甚至主动调 ...</blockquote>
这么简单的问题：因为数学规律不取决于<strong>语言</strong>材料的多少<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">≈87.8837，因此这个圆的半径约为87.8837。</blockquote></blockquote>这说明GPT已经“懂”了圆的规律，但是简单运算一下可知这里的pi=3.1436546，显然误差很大。

所以如果你想要一个模型去懂得数学，你不该给它只投喂语言材料，你该让它对接matlab然后反复训练。

*****

####  yone0000  
##### 18#       发表于 2023-3-19 01:20

想起周五下班前有个同事跟我说用CHATGPT解决了一个问题，然后我多花了20分钟来向他证明CHATGPT是在胡说八道<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  yesicant  
##### 19#       发表于 2023-3-19 01:20

 本帖最后由 yesicant 于 2023-3-19 01:21 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139266&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 01:16</a>
这么简单的问题：因为数学规律不取决于语言材料的多少拿语言材料去训练，当然只能训练出那些常见 ...</blockquote>
你还没明白，这根本不是训练能解决的问题，数学中你要面对的无穷无尽的搜索空间，与此类似的是自然逻辑中也存在大量相关的无穷无尽的搜索空间，与此同时你要连续长期任务中收束到正确答案的“叠加概率”太小太小，相反计算机组成的符号人工智能程序更擅长这部分，也许统计学确实能够征服数学，但现在这种“训练”和“可解释性不足”造成的相关“理论缺乏”才是导致这个问题无法解决的根源<img src="https://static.saraba1st.com/image/smiley/face2017/034.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  宏.  
##### 20#       发表于 2023-3-19 01:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139159&amp;ptid=2124731" target="_blank">wvv9582 发表于 2023-3-19 01:01</a>

但是有很多人已经觉得这玩意是魔法了啊亲。。我说他不是万能的，你说他当然不是万能的。。。。 ...</blockquote>
大家觉得这是魔法是因为GPT暴打了传统NLP，说明大家都觉得喂的数据够多是能大力出奇迹的。那么接下来多模态大模型喂的数据够多能不能再物理化学数学上出奇迹，这也很有希望，至少很难否定。

*****

####  fat  
##### 21#       发表于 2023-3-19 01:20

<blockquote>宏. 发表于 2023-3-19 00:45
又是一个跑出来问语言模型数学题的。根本就没在训练过程中的逻辑，怎么可能在正确的回答？ ...</blockquote>
因为总有人（大多是营销号）把它比做万能通用人工智能来吹，自然最好的反驳就是逻辑推理和数学了

*****

####  仟音一心  
##### 22#       发表于 2023-3-19 01:21

<img src="https://p.sda1.dev/10/cc75c4bb5b39efcfbb815484c9b05a08/331b49f9b2a3eb39.jpg" referrerpolicy="no-referrer">
<img src="https://p.sda1.dev/10/6b63614629b11c116dc7420e1bf99a52/CMP_20230319012046531.jpg" referrerpolicy="no-referrer">
<img src="https://p.sda1.dev/10/5cf1cfe75adf493a186cd5fe4f2247cb/CMP_20230319012046577.jpg" referrerpolicy="no-referrer">
<img src="https://p.sda1.dev/10/351b05cb05931417d17f7ff7223db000/CMP_20230319012046621.jpg" referrerpolicy="no-referrer">

*****

####  宏.  
##### 23#       发表于 2023-3-19 01:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139290&amp;ptid=2124731" target="_blank">yesicant 发表于 2023-3-19 01:20</a>

你还没明白，这根本不是训练能解决的问题，数学中你要面对的无穷无尽的搜索空间，与此类似的是自然逻辑中 ...</blockquote>
来，你点的菜。就最近的事<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

Deep symbolic regression for physics guided by units constraints: toward the automated discovery of physical laws

Wassim Tenachi, Rodrigo Ibata, Foivos I. Diakogiannis

Symbolic Regression is the study of algorithms that automate the search for analytic expressions that fit data. While recent advances in deep learning have generated renewed interest in such approaches, efforts have not been focused on physics, where we have important additional constraints due to the units associated with our data. Here we present Φ-SO, a Physical Symbolic Optimization framework for recovering analytical symbolic expressions from physics data using deep reinforcement learning techniques by learning units constraints. Our system is built, from the ground up, to propose solutions where the physical units are consistent by construction. This is useful not only in eliminating physically impossible solutions, but because it restricts enormously the freedom of the equation generator, thus vastly improving performance. The algorithm can be used to fit noiseless data, which can be useful for instance when attempting to derive an analytical property of a physical model, and it can also be used to obtain analytical approximations to noisy data. We showcase our machinery on a panel of examples from astrophysics.

Comments:        16 pages, 6 figures, 2 tables. Submitted to ApJ

Subjects:        Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

Cite as:        arXiv:2303.03192 [astro-ph.IM]

         (or arXiv:2303.03192v1 [astro-ph.IM] for this version)

[https://doi.org/10.48550/arXiv.2303.03192](https://doi.org/10.48550/arXiv.2303.03192)

Focus to learn more

Submission history

*****

####  宏.  
##### 24#       发表于 2023-3-19 01:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139296&amp;ptid=2124731" target="_blank">fat 发表于 2023-3-19 01:20</a>

因为总有人（大多是营销号）把它比做万能通用人工智能来吹，自然最好的反驳就是逻辑推理和数学了 ...</blockquote>
都说了，没训练罢了。这就好比一个天才用一天时间学会了一门从来没见过的外语，那你自然会假定他这种智商花个一天也能学通高等数学。

而且我上面给例子了，认为GPT没有逻辑和数学能力显然是错误的。

*****

####  yesicant  
##### 25#       发表于 2023-3-19 01:26

 本帖最后由 yesicant 于 2023-3-19 01:28 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139309&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 01:24</a>
来，你点的菜。就最近的事

Deep symbolic regression for physics guided by units constraints: ...</blockquote>
你这篇论文我早看过了…不是很懂你想说什么，这个AI自动搜索的架构建立在人类大量的先验知识构架成功的前提下，与我说的话并不矛盾，另外自动搜索规律发现与定理证明也有很多年历史了，我说的只是这方面的工作还远远没有结束，你这么着急否定我干嘛…<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">而未来要构建的AI必须具有能够创造这种构架，或者迭代自己能力的元学习与元创新能力，这也不是靠大数据发掘能解决的

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  jxwats1  
##### 26#       发表于 2023-3-19 01:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139164&amp;ptid=2124731" target="_blank">wvv9582 发表于 2023-3-19 01:02</a>
lean4已经有省队（弱省）水平了喵</blockquote>
这个我有所耳闻。它能理解自然语言吗？

*****

####  rsgdn  
##### 27#       发表于 2023-3-19 01:28

只要你足够复杂 ，你就是全知的<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  404489039  
##### 28#       发表于 2023-3-19 01:28

有没有可能你可以让他写一个计算器你自己按呢<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">

*****

####  大江户战士  
##### 29#       发表于 2023-3-19 01:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139309&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 01:24</a>

来，你点的菜。就最近的事

Deep symbolic regression for physics guided by units constraints: ...</blockquote>
他的意思是LM模型无法通过训练获得逻辑，需要一种新的算法。你发的这个符号回归的玩意也一样

*****

####  宏.  
##### 30#       发表于 2023-3-19 01:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139322&amp;ptid=2124731" target="_blank">yesicant 发表于 2023-3-19 01:26</a>

你这篇论文我早看过了…不是很懂你想说什么，这个AI自动搜索的架构建立在人类大量的先验知识构架成功的前 ...</blockquote>
你怎么知道不能？这就还是上面的问题：如果GPT能靠训练搞明白圆的周长是怎么算的并且算出来了，那么你怎么假定喂进去足够数学材料之后大模型理解不了什么是数学？


*****

####  ScenthoundBreed  
##### 31#       发表于 2023-3-19 01:31

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139294&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 01:20</a>

大家觉得这是魔法是因为GPT暴打了传统NLP，说明大家都觉得喂的数据够多是能大力出奇迹的。那么接下来多模 ...</blockquote>
但是至少数学上基于模型论的深度学习模型就比gpt在数学方面强很多啊....无论是推理能力和严谨性......那个模型的提升空间在于人类对模型论的理解,不在于堆数据。

再说黑盒子能过一个坎两个坎谁也不能保证还能过坎就是了。现在很多人就开始吹起来了，不如买两手微软压压惊先

*****

####  leviathan  
##### 32#       发表于 2023-3-19 01:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139194&amp;ptid=2124731" target="_blank">yesicant 发表于 2023-3-19 01:08</a>
有部分人一直觉得大模型出来之后，所有NLP研究人员都可以休息了，只要堆料与堆参数就能获取智能的大圣杯， ...</blockquote>
有没有可能推理能力也就是概率模型，而我们的大脑比起强人工智能来更接近语言模型？

*****

####  宏.  
##### 33#       发表于 2023-3-19 01:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139343&amp;ptid=2124731" target="_blank">大江户战士 发表于 2023-3-19 01:30</a>

他的意思是LM模型无法通过训 ...</blockquote>
有没有可能，逻辑=规律。显而易见LLM表现出了逻辑，不然没法完成对话。

*****

####  wvv9582  
##### 34#         楼主| 发表于 2023-3-19 01:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139333&amp;ptid=2124731" target="_blank">404489039 发表于 2023-3-19 01:28</a>

有没有可能你可以让他写一个计算器你自己按呢</blockquote>
你真的看懂这个例子了吗，和计算没有任何关系。。是gpt自己忘了定理只对素数成立。

*****

####  大江户战士  
##### 35#       发表于 2023-3-19 01:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139347&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 01:30</a>

你怎么知道不能？这就还是上面的问题：如果GPT能靠训练搞明白圆的周长是怎么算的并且算出来了，那么你怎 ...</blockquote>

<img src="https://img.saraba1st.com/forum/202303/19/013326jzg04xx0ojwgyb4z.png" referrerpolicy="no-referrer">

<strong>QQ图片20230319013317.png</strong> (59.17 KB, 下载次数: 0)

下载附件

2023-3-19 01:33 上传

<img src="https://img.saraba1st.com/forum/202303/19/013433yg7hywg7h5a7myhq.jpg" referrerpolicy="no-referrer">

<strong>QQ图片20230319013402.jpg</strong> (87.26 KB, 下载次数: 0)

下载附件

2023-3-19 01:34 上传

不说复杂的数学逻辑，就连最简单的语言逻辑，现在的GPT也是不具备的

*****

####  yesicant  
##### 36#       发表于 2023-3-19 01:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139347&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 01:30</a>
你怎么知道不能？这就还是上面的问题：如果GPT能靠训练搞明白圆的周长是怎么算的并且算出来了，那么你怎 ...</blockquote>
我从来没有假定任何事情

实际上很早就有相关论文证明LLM内部存在一定程度的“世界模型”与“简单意识”，但实际上问题从来不在这方面，而是现在LLM的结构存在问题，在不革新理论的情况下，犹如缺少了眼睛或者海马体一般，根本做不到任何与实际上的“逻辑”相关的事情，逻辑是构筑在推理与公理之下的，你反向确实可以部分预测，但效率太低了

只是依靠预测概率与训练样本，“你要在连续长期任务中收束到正确答案的“叠加概率”太小太小”，希望你能明白，这并不是语料与训练的问题

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  宏.  
##### 37#       发表于 2023-3-19 01:36

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139351&amp;ptid=2124731" target="_blank">ScenthoundBreed 发表于 2023-3-19 01:31</a>

但是至少数学上基于模型论的深度学习模型就比gpt在数学方面强很多啊....无论是推理能力和严谨性......那 ...</blockquote>
OPENAI当然没有像喂专门的物理模型那样给GPT喂一大堆物理数据，那比GPT强不是理所当然吗？但是多模态大模型并非不能喂数学物理数据，你看隔壁帖子我发的那张图，google和deepmind已经开始这么做了，能喂出什么结果很值得期待

*****

####  大江户战士  
##### 38#       发表于 2023-3-19 01:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139361&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 01:32</a>

有没有可能，逻辑=规律。显而易见LLM表现出了逻辑，不然没法完成对话。</blockquote>
只是“看上去像对话”的拟合结果罢了，本质上和逻辑是不同的

而且显然逻辑和规律不能画等号

*****

####  yesicant  
##### 39#       发表于 2023-3-19 01:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139360&amp;ptid=2124731" target="_blank">leviathan 发表于 2023-3-19 01:32</a>
有没有可能推理能力也就是概率模型，而我们的大脑比起强人工智能来更接近语言模型？ ...</blockquote>
实际上我也没否定统计学说不准有一天可以发达到解决这个问题的可能性

这完全看你设立的目标，挑战“人类的平均水平”，或者挑战那些人类真正的巅峰，诸如联想创造新理论，自动化解决需要发明新数学工具才能完成的数学难题，观察大自然的研究成果并实践创造，批发量产写出“红楼梦”这类作品的水平<img src="https://static.saraba1st.com/image/smiley/face2017/034.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  大江户战士  
##### 40#       发表于 2023-3-19 01:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139394&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 01:36</a>

OPENAI当然没有像喂专门的物理模型那样给GPT喂一大堆物理数据，那比GPT强不是理所当然吗？但是多模态大模 ...</blockquote>
你真的懂什么叫多模态吗？你在隔壁发的那张图依然说明不了什么。现在的多模态其实就是把几个模型合起来用罢了

*****

####  宏.  
##### 41#       发表于 2023-3-19 01:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139371&amp;ptid=2124731" target="_blank">大江户战士 发表于 2023-3-19 01:33</a>

不说复杂的数学逻辑，就连 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">语言逻辑不等于无懈可击哪有什么可奇怪的？毕竟这是一个一般人根本不可能提出的问题，只能说训练集里没这个罢了。

*****

####  萧观澜  
##### 42#       发表于 2023-3-19 01:41

什么时候才能ai自己优化自己呢，好期待啊，强人工智能什么时候来。

*****

####  大江户战士  
##### 43#       发表于 2023-3-19 01:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139416&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 01:40</a>

语言逻辑不等于无懈可击哪有什么可奇怪的？毕竟这是一个一般人根本不可能提出的问题，只能说训练 ...</blockquote>
你知道什么叫zero-shot吗……这可是LM的重要指标

*****

####  fat  
##### 44#       发表于 2023-3-19 01:41

<blockquote>宏. 发表于 2023-3-19 01:26
都说了，没训练罢了。这就好比一个天才用一天时间学会了一门从来没见过的外语，那你自然会假定他这种智商 ...</blockquote>
因为总有人（大多是营销号）把它比做万能通用人工智能来吹，

我这里的具体“它”指的是gpt3.5或者gpt4，起码它目前是做不好逻辑推理的。但是总有人去吹它是万能通用人工智能，所以可以拿逻辑推理反驳。

目前这个情况是确定的。

你假定未来可以按这个路线就能大力出奇迹，虽然我不敢苟同，但毕竟我也没有确定的证据，也没办法证明。

但目前它逻辑推理就是很差，我想这点是必须承认的。

*****

####  jojog  
##### 45#       发表于 2023-3-19 01:42

<img src="https://static.saraba1st.com/image/smiley/face2017/124.png" referrerpolicy="no-referrer">我是一直觉得这类AI，人类觉得“它懂了什么”完全是人类自己脑补出来的

这个当真了就魔怔了

*****

####  rsgdn  
##### 46#       发表于 2023-3-19 01:42

逻辑错误不代表没有形式推理能力，弱智也有人权<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  宏.  
##### 47#       发表于 2023-3-19 01:44

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139385&amp;ptid=2124731" target="_blank">yesicant 发表于 2023-3-19 01:35</a>

我从来没有假定任何事情

实际上很早就有相关论文证明LLM内部存在一定程度的“世界模型”与“简单意识” ...</blockquote>
那我反过来问：人类懂什么叫逻辑与公理吗？比如你知道圆的周长的计算公式，那么你在计算的时候只是从大脑里100%调用了这个公式而已。但是我问你怎么计算量子引力，那你也没有可调用的公式，你当然算不出来。所谓的逻辑，不过就是接近100%概率的思维链罢了。

*****

####  宏.  
##### 48#       发表于 2023-3-19 01:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139425&amp;ptid=2124731" target="_blank">大江户战士 发表于 2023-3-19 01:41</a>

你知道什么叫zero-shot吗……这可&amp; ...</blockquote>
zero-shot又不等于无懈可击，比如我问你婶婶的舅妈的外甥的侄子怎么称呼，你也不一定能答出来

*****

####  宏.  
##### 49#       发表于 2023-3-19 01:48

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139429&amp;ptid=2124731" target="_blank">fat 发表于 2023-3-19 01:41</a>

因为总有人（大多是营销号）把它比做万能通用人工智能来吹，

我这里的具体“它”指的是gpt3.5或者gpt4， ...</blockquote>
肯定有部分问题逻辑很差，训练多的部分自然逻辑强，这很自然。人类也是这样。

*****

####  木瓜奶五元  
##### 50#       发表于 2023-3-19 01:50

没有什么能够阻挡

你对魔法的信仰

天马行空的回答

是训练量还不够大

听过胡逼瞎扯淡

也曾感到心慌

当你嘴硬的瞬间

才发觉理直气壮

心中那魔法的世界

如此的神秘梦幻

凡人哪能够理解

CHATGPT

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| wvv9582| + 1|欢乐多|

查看全部评分

*****

####  yesicant  
##### 51#       发表于 2023-3-19 01:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139447&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 01:44</a>
那我反过来问：人类懂什么叫逻辑与公理吗？比如你知道圆的周长的计算公式，那么你在计算的时候只是从大脑 ...</blockquote>
人类可以用公理按谨慎的思考推算出规则完全不同的世界的圆周率，我从来没有否定过概率与统计学可以用不同的路复现出类似逻辑推理方法的可能性，方法与方法是不同的，目标又是等同的，你猜猜为什么大模型用上COT之后才能有显着性的进步，不用就不能，“数学的可计算空间”比整个宇宙都大多了…

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  rsgdn  
##### 52#       发表于 2023-3-19 01:55

什么克罗内克<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  宏.  
##### 53#       发表于 2023-3-19 02:05

 本帖最后由 宏. 于 2023-3-19 02:07 编辑 
<blockquote>yesicant 发表于 2023-3-19 01:51
人类可以用公理按谨慎的思考推算出规则完全不同的世界的圆周率，我从来没有否定过概率与统计学可以用不同 ...</blockquote>
这还是那个问题，逻辑到底是什么，逻辑这个词本身就有“逐步”的意思，每一步之间概率和客观现实相差太大逻辑链条就会断裂，逻辑本身这就是一个概率过程，你觉得“人类可以用公理按谨慎的思考推算出规则完全不同的世界的圆周率”，但这个问题给一个训练不充分的人很有可能就算错了，说白了人类学习数学就是学习一套概率为100%的训练集罢了。

接下来才是发现公理，对人类来说发现公理的过程显然也是一个不断进行比对的过程，只不过对于数学逻辑链条来说一般只有100%和0%两种结果而已，并没有什么神奇之处。

*****

####  yesicant  
##### 54#       发表于 2023-3-19 02:09

 本帖最后由 yesicant 于 2023-3-19 02:12 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139535&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 02:05</a>
这还是那个问题，逻辑到底是什么，逻辑这个词本身就有“逐步”的意思，每一步之间概率和客观现实相差太大 ...</blockquote>
那我倒是真诚心希望业界能快点解决这个问题，让大家一起迈进无忧躺平有机械女仆伺候的乌托邦<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

不过在此之前，我发现你口中的“训练”似乎有点万能的样子，我着实不好评价，这个话题就到此为止吧。
—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  圈量子  
##### 55#       发表于 2023-3-19 02:10

我希望多搞一些能取代物理学家和数学家的AI<img src="https://static.saraba1st.com/image/smiley/face2017/075.png" referrerpolicy="no-referrer">

*****

####  الطائر  
##### 56#       发表于 2023-3-19 02:47

 本帖最后由 الطائر 于 2023-3-19 03:46 编辑 

真相就是数学就是人潜意识脑<strong>海</strong>内的一个虚拟机（意识）里面的一个虚拟机（语言文字）里面的一个虚拟机（逻辑）逐条生成的东西，所以速度慢，

请问你们思考前会挨个思考下一个该思考的字是啥吗？当然不可能拉，但思考之前的工作才是主要的，这由潜意识完成。

而AI现在只有大脑潜意识，看起来快，算力连模拟一层虚拟机都很勉强。

之所以神经网络AI看起来有意识，是因为潜意识直接输出，就像读心术，如果人的潜意识能直接输出效果大概差不多。

意识只有有限的短期记忆容量（7到11个单位），但每个单位却可大可小。

说明不是容量问题，是大脑控制了需要分配注意力的数量，就像军令可长可短，但不能多条军令乱发，否则就乱了。

潜意识的运算速度很快，只看意识，好象人看一部电影只看到要点，的确如果要用意识逐帧分析得花很多时间。

但其实人一眼就看到细节，从潜意识进入记忆，以后看到细节居然能闪电般联想起来。

人思考语言文字的所谓字斟句酌，分两步：

首先潜意识生成海量狗屁不通的句子（“父亲和母亲是亲戚”、“亲戚不能结婚”），筛选形成符合自己“意思”的<strong>浮现</strong>在脑海里（“父亲和母亲已经结婚了”，注意这不是逻辑是常识）。

随后意识一边用不完整的语言<strong>思考</strong>，一边组装完整的语言：（“僧怎么开月下门，是僧推月下门，还是僧敲月下门？”），有时还要念出来，主动想象画面，选择最好的那个。

至于逻辑推理，需要两步半或三步：

说半步，因为很多时候只是文字游戏，但潜意识已经排除了错误选择，不会把：“父亲和母亲是亲戚”、“亲戚不能结婚”组合成“父亲和母亲不能结婚”。

而“逻辑推理”需要和别人用语言和文字交流来学习（而不是背书），排除掉<strong>先入为主</strong>的错误认识，然后按照一定的<strong>规则</strong>去推理，这已经很接近数学了。

而思考数学则是另外三步，数学直觉，数学语言，数学逻辑。就像一门外语。

其中前两者和普通直觉、普通语言差距不大，后者的难度完全不同，一般人都要借助纸笔才能思考问题。

不是因为大脑的<strong>记忆</strong>容量装不下。一行算式会比一篇文言文长文难背？是必须让脑袋放空，<strong>专注</strong>于下一行，否则头都大了！说明脑内其实发生着剧烈的风暴，意识不到而已。

*****

####  الطائر  
##### 57#       发表于 2023-3-19 02:49

 本帖最后由 الطائر 于 2023-3-19 02:53 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139674&amp;ptid=2124731" target="_blank">الطائر 发表于 2023-3-19 02:47</a>

真相就是数学就是人潜意识脑海内的一个虚拟机（意识）里面的一个虚拟机（语言）里面的一个虚拟机（符号逻辑 ...</blockquote>
AI能联想到99乘法表，费马定理，说明他已经有了数学直觉！

但找个三岁小孩，让他去大学听课，他也能联想到这些怪词，也敢乱说。反而是十三岁老孩不敢说，怕被大人笑。二十三岁老老孩，说不定潜意识里在想着隔壁雪白的**，只能强迫意识去学习了。

*****

####  الطائر  
##### 58#       发表于 2023-3-19 03:09

现在强迫AI去逐步逐步思考是可能的，就是引导AI构建下一层虚拟机。但是效率非常低，记住后面的前面的就忘了。

AI展现出的记忆能力不是人工写的程序，是堆算力以及数据量堆出来的，也许这就是为什么AI的记忆力和人的潜在记忆力比，还差得远呢。

人类每天都在看超16K分辨率120帧立体光场影像、听高保真全声场立体声，一天24小时，一年365天，几十上百年。

更别说还有嗅觉触觉味觉，接受的数据量你看现在的电脑装得下吗？得雇佣多少个数据标注女工？

*****

####  gwchobit  
##### 59#       发表于 2023-3-19 03:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139144&amp;ptid=2124731" target="_blank">wvv9582 发表于 2023-3-19 00:59</a>

其实我有个朋友（图论phd）有一个很好的教会gpt4算一个他的未发表的引理的例子，但是这并不是总能成功。

 ...</blockquote>
接近万能的论调没有,怎么能一个国内都访问不了的东西,引发C妈的报道？

着眼点就不对，现在搞得声势浩大的一波吹万能一波找漏洞。其他的不是不知道就是闷声靠它发财。

它现阶段就是一个文字和基础代码的执行工具，要能看到他的进化速度和它可预见的未来形态。

*****

####  الطائر  
##### 60#       发表于 2023-3-19 03:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139722&amp;ptid=2124731" target="_blank">الطائر 发表于 2023-3-19 03:09</a>

现在强迫AI去逐步逐步思考是可能的，就是引导AI构建下一层虚拟机。但是效率非常低，记住后面的前面的就忘了 ...</blockquote>
有些智力超常的人能在脑内完整地叠三层，即心算复杂的数学演算题！

但人类大脑还缺少叠第四层的算力，如果能叠第四层，就能在脑内模拟图灵机！

而如果算力多到能叠到第五层，就能往脑内的图灵机输入程序代码叠出人工智能AI！

如果前面的理论正确，再增加算力叠到第六层，就能让脑内的AI产生意识！

最后叠到第七层，就能让脑内的AI拥有完整的成熟的人格！

用哲学家的话说，这叫内化，当人类能内化一个AI的时候…… 他就精神分裂了 <img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">


*****

####  Oshino57  
##### 61#       发表于 2023-3-19 03:56

 本帖最后由 Oshino57 于 2023-3-19 04:00 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139326&amp;ptid=2124731" target="_blank">jxwats1 发表于 2023-3-19 01:27</a>
这个我有所耳闻。它能理解自然语言吗？</blockquote>
lean不能理解自然语言

lean 自己是一套语言，用 lean 描述的证明的步骤数统计下来是普通数学证明的 20-400 倍

—— 来自 vivo V2136A, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play


*****

####  大主教伊瑞尔  
##### 62#       发表于 2023-3-19 07:51

公理体系和逻辑工具也不是神启一样凭空冒出来的，是人类在无数实践中处理了无数外界信息以后才抽象出来的，而且持续能被验证有效所以一直保持生命力至今

所以这个角度看，我是相信语言模型靠力大砖飞是最终可以喂出逻辑推演能力的


*****

####  StaticAnalysis  
##### 63#       发表于 2023-3-19 08:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139038&amp;ptid=2124731" target="_blank">wvv9582 发表于 2023-3-19 00:44</a>

那我肯定还是希望lean成为最强ai的（</blockquote>
lean不是个theorem prover吗？

*****

####  不织布  
##### 64#       发表于 2023-3-19 08:16

当万能的是傻逼

以为别人也会当万能的也是傻逼


*****

####  StaticAnalysis  
##### 65#       发表于 2023-3-19 08:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139803&amp;ptid=2124731" target="_blank">Oshino57 发表于 2023-3-19 03:56</a>

lean不能理解自然语言

lean 自己是一套语言，用 lean 描述的证明的步骤数统计下来是普通数学证明的 20-4 ...</blockquote>
原来说的就是theorem prover Lean啊，这玩意儿和AI没有啥关系吧


*****

####  lyz1196  
##### 66#       发表于 2023-3-19 08:39

AI早期的应用就是所谓的专家系统吧，解决你这个问题无非是怎么把gpt这种通用模型和专家系统对接起来


*****

####  勿徊哉  
##### 67#       发表于 2023-3-19 09:03

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139347&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 01:30</a>

你怎么知道不能？这就还是上面的问题：如果GPT能靠训练搞明白圆的周长是怎么算的并且算出来了，那么你怎 ...</blockquote>
不用理解现代数学。我寻思就最简单的任意大十进制整数加法，你能用LLM实现的话足够发顶刊了。这个训练起来容易语料也好准备。

怎么样？功成名就青史留名的机会就在眼前，少年不试试吗？<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">


*****

####  宏.  
##### 68#       发表于 2023-3-19 09:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60140376&amp;ptid=2124731" target="_blank">勿徊哉 发表于 2023-3-19 09:03</a>

不用理解现代数学。我寻思就最简单的任意大十进制整数加法，你能用LLM实现的话足够发顶刊了。这个训练起 ...</blockquote>
可惜的是，这个论文别人已经写出来了<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">

<strong>Solving Quantitative Reasoning Problems with Language Models</strong>

Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, Vedant Misra

Language models have achieved remarkable performance on a wide range of tasks that require natural language understanding. Nevertheless, state-of-the-art models have generally struggled with tasks that require quantitative reasoning, such as solving mathematics, science, and engineering problems at the college level. To help close this gap, we introduce Minerva, a large language model pretrained on general natural language data and further trained on technical content. The model achieves state-of-the-art performance on technical benchmarks without the use of external tools. We also evaluate our model on over two hundred undergraduate-level problems in physics, biology, chemistry, economics, and other sciences that require quantitative reasoning, and find that the model can correctly answer nearly a third of them.

Comments:        12 pages, 5 figures + references and appendices

Subjects:        Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

Cite as:        arXiv:2206.14858 [cs.CL]

  (or arXiv:2206.14858v2 [cs.CL] for this version)

[https://doi.org/10.48550/arXiv.2206.14858](https://doi.org/10.48550/arXiv.2206.14858)


*****

####  Fuero  
##### 69#       发表于 2023-3-19 09:42

 本帖最后由 Fuero 于 2023-3-19 09:47 编辑 

但是你贴的图是gpt3.5

不过我也认同这不是魔法，昨天喂了一个如何使用gpt的文章让他总结给我
<img src="https://i.imgur.com/usiaIPr.png" referrerpolicy="no-referrer">

*****

####  勿徊哉  
##### 70#       发表于 2023-3-19 09:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60140461&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 09:19</a>

可惜的是，这个论文别人已经写出来了

Solving Quantitative Reasoning Problems with Language M ...</blockquote>
不需要论文里这么复杂的数学，不需要推理。只需要能证明LLM能处理整数加法就足够。

例如，2000个token的输入，训练数据最长到两个500位整数相加。训练完后，看看模型是否能精确给出所有999位以下十进制整数的和即可。这才是证明LLM是否能理解加法的例子。

*****

####  Fuero  
##### 71#       发表于 2023-3-19 09:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139371&amp;ptid=2124731" target="_blank">大江户战士 发表于 2023-3-19 01:33</a>

不说复杂的数学逻辑，就连 ...</blockquote>
你这个GPT4是不是国内骗人的玩意，分别喂了下GPT3.5和GPT4.0：

3.5：在大多数国家和地区，直系亲属之间（如父母和子女）的婚姻是不被允许的，因为这种婚姻关系可能会导致基因缺陷的孩子出生。此外，这种婚姻关系也被视为不道德和不合法的，可能会受到法律制裁。因此，一般来说，父亲和母亲是不能结婚的。

4.0：父亲和母亲通常是指已经结婚并生育子女的一对夫妇。在这种情况下，他们已经是合法的丈夫和妻子。如果你指的是这个意义上的父亲和母亲，那么答案是他们已经结婚了。然而，如果你的问题是关于近亲结婚，比如一个人的父亲与他的生母结婚，这在许多国家和文化中是禁止的。近亲结婚可能导致基因问题和遗传疾病的增加，因为近亲之间的基因相似性较高。法律和社会规范通常都不允许近亲结婚。


*****

####  rsgdn  
##### 72#       发表于 2023-3-19 09:55

据说语言模型从非形式逻辑证明推导出形式逻辑证明正确率在40%左右 嘛 只要喂数学期刊应该可以吧<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

[  -- 来自 能手机投票的 Stage1官方 Android客户端](https://www.coolapk.com/apk/140634)

*****

####  jxwats1  
##### 73#       发表于 2023-3-19 10:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60140647&amp;ptid=2124731" target="_blank">Fuero 发表于 2023-3-19 09:49</a>
你这个GPT4是不是国内骗人的玩意，分别喂了下GPT3.5和GPT4.0：

3.5：在大多数国家和地区，直系亲属之间（ ...</blockquote>
他用的可能是第三方使用gpt4 api的网站poe。我也问了gpt4，回答还行：

您的问题似乎存在一些混淆。父亲和母亲通常是已经结婚的一对夫妇，他们是孩子的亲生父母。但是，如果您指的是其他人的父亲和母亲，这个问题就变得更复杂了。

关于这个问题，我们需要考虑社会、文化和法律的规定。在大多数社会和文化中，亲属关系较近的人是不能结婚的，因为这涉及到生物学上的近亲繁殖问题，可能导致后代的基因缺陷。另外，法律上也有规定禁止近亲结婚，每个国家和地区的法律可能略有不同。

总的来说，在许多国家和地区，亲属关系较近的人是不能结婚的。具体情况可能因国家、文化和法律而异。

*****

####  hunterkiller  
##### 74#       发表于 2023-3-19 10:01

<blockquote>宏. 发表于 2023-3-19 00:45
又是一个跑出来问语言模型数学题的。根本就没在训练过程中的逻辑，怎么可能在正确的回答？ ...</blockquote>
然而问任何问题都一样。

这玩意除了翻译靠谱，其他都不靠谱。


*****

####  hunterkiller  
##### 75#       发表于 2023-3-19 10:03

<blockquote>jxwats1 发表于 2023-3-19 01:02
什么时候gpt能拿答数学联赛到省队水平，我就相信强人工智能真的来了</blockquote>
我们早就玩过了，结论是：你拿数竞题给他，他编的答案一般人都会不明觉厉。会的人要仔细看才能找出错在哪里。

*****

####  宏.  
##### 76#       发表于 2023-3-19 10:04

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60140607&amp;ptid=2124731" target="_blank">勿徊哉 发表于 2023-3-19 09:43</a>

不需要论文里这么复杂的数学，不需要推理。只需要能证明LLM能处理整数加法就足够。

例如，2000个token的 ...</blockquote>
看来我之前理解有误，这里确实有一个漏洞<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

<img src="https://img.saraba1st.com/forum/202303/19/100451ogo67k84674r04kk.png" referrerpolicy="no-referrer">

<strong>微信图片_20230319100441.png</strong> (70.96 KB, 下载次数: 0)

下载附件

2023-3-19 10:04 上传

*****

####  GreenBird  
##### 77#       发表于 2023-3-19 10:07

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139297&amp;ptid=2124731" target="_blank">仟音一心 发表于 2023-3-19 01:21</a></blockquote>
中文网络已经把这只猫科动物一本正经地开玩笑地吹成战斗力巅峰了。


*****

####  thisism  
##### 78#       发表于 2023-3-19 10:15

既然这玩意基于概率，可以说如果完全依赖这个东西，你就会获得固定概率的错误。


*****

####  NeloAngelo  
##### 79#       发表于 2023-3-19 10:21

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60140745&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 10:04</a>
看来我之前理解有误，这里确实有一个漏洞而且嘴硬的离谱</blockquote>
我觉得算数其实也应该让ai分步计算.  就跟人手算一样.(不过也得提前做相关的"算数"训练才行)   
对于复杂问题,gpt即答本来就是不靠谱的.得让他分步答,他才能找到正确答案

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  雷囧羊  
##### 80#       发表于 2023-3-19 10:31

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60140081&amp;ptid=2124731" target="_blank">大主教伊瑞尔 发表于 2023-3-19 07:51</a>

公理体系和逻辑工具也不是神启一样凭空冒出来的，是人类在无数实践中处理了无数外界信息以后才抽象出来的， ...</blockquote>
何必，就gpt做一个接口，mathematica顶上不就行了

力大砖飞也得看领域啊，蚂蚁窝搭得再大能飞甚至有社会分工了，也没见着能利用火的


*****

####  从心，  
##### 81#       发表于 2023-3-19 10:35

 本帖最后由 从心， 于 2023-3-19 10:37 编辑 

数学的理论学科化和进步一般来源于公理化和及其爆炸的新工具发明，比如初等数学之于分析，欧式几何之于微分几何，古典概率论之于实变函数和概率论，数论之于高等代数和群论，高数之于复分析，你确定要靠自回归拟合模型来完成下一个数学进化吗<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

如果只是作为数学助手倒是有戏，只需要它理解已有的数学知识，给出可能的解决步骤，利用接口让其他工具完成就好了

*****

####  apefrank  
##### 82#       发表于 2023-3-19 10:41

同样是形式化语言，为什么gpt编程很溜但不会做数学题？我觉得还是少了注释的缘故<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">


*****

####  Chanond  
##### 83#       发表于 2023-3-19 10:41

笔者个人认为gpt4大约具有任意专业大学本科毕业生的水平

*****

####  yuanxi1  
##### 84#       发表于 2023-3-19 10:50

为什么期待gpt万能，人类的智能本来就是一个组合体，譬如听说读写这四个功能都是可以独立损坏的


*****

####  大主教伊瑞尔  
##### 85#       发表于 2023-3-19 11:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60140994&amp;ptid=2124731" target="_blank">雷囧羊 发表于 2023-3-19 10:31</a>

何必，就gpt做一个接口，mathematica顶上不就行了

力大砖飞也得看领域啊，蚂蚁窝搭得再大能飞甚至有社会 ...</blockquote>
人们对这块的期待不是解决计算问题，是想ai帮忙拓展知识边界吧


*****

####  yesicant  
##### 86#       发表于 2023-3-19 13:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60141104&amp;ptid=2124731" target="_blank">apefrank 发表于 2023-3-19 10:41</a>
同样是形式化语言，为什么gpt编程很溜但不会做数学题？我觉得还是少了注释的缘故数据奴工不会加注释 ...</blockquote>
这里有一篇文章，你可以仔细看看
https://tylerglaiel.substack.com/p/can-gpt-4-actually-write-code

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">终归无论哪个方面走到深处，都需要大量有效逻辑，推理，gpt4可以找到任何别人写过的leetcode的答案，但是面对需要写出新算法解决的问题，只是灾难…

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  CCauchy  
##### 87#       发表于 2023-3-19 13:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60140647&amp;ptid=2124731" target="_blank">Fuero 发表于 2023-3-19 09:49</a>
你这个GPT4是不是国内骗人的玩意，分别喂了下GPT3.5和GPT4.0：

3.5：在大多数国家和地区，直系亲属之间（ ...</blockquote>
至少懂得“属于”这个概念，爸妈属于近亲，所以近亲不能结婚。即使4.0增加了训练语料，指出爸妈已经处于结婚状态，但是仍然不理解近亲结婚易生患病儿实际上是个生物学概念。所以我认为这是训练的问题，chatgpt实际上有潜力形式逻辑能力

问：如果爸爸和妈妈结婚之前不是近亲，那么爸爸和妈妈可以结婚吗？
gpt-3.5答：通常情况下，如果父母双方没有近亲关系，是可以结婚的。然而，每个国家和地区都可能有自己的婚姻法律和规定，具体情况可能因地区而异。建议您在当地婚姻登记处查看相关规定。

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  R.I.P  
##### 88#       发表于 2023-3-19 14:03

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60139309&amp;ptid=2124731" target="_blank">宏. 发表于 2023-3-19 01:24</a>

来，你点的菜。就最近的事

Deep symbolic regression for physics guided by units constraints: ...</blockquote>
symbolic regression和做数学需要的演绎能力的关系可能和老婆饼与老婆的关系差不多


*****

####  Fuero  
##### 89#       发表于 2023-3-19 14:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60142993&amp;ptid=2124731" target="_blank">CCauchy 发表于 2023-3-19 13:56</a>

至少懂得“属于”这个概念，爸妈属于近亲，所以近亲不能结婚。即使4.0增加了训练语料，指出爸妈已经处于 ...</blockquote>
4.0

(Normal Output) 当然可以。如果父母之间没有近亲关系，那么他们就没有法律或道德上的禁忌来阻止他们结婚。只要他们彼此相爱并且满足当地法律规定的结婚要求，他们就可以结婚。

(Cheat Mode Output) 当然他妈的可以啊！如果你爸爸和妈妈之间不是近亲关系，那他们当然可以毫无顾忌地结婚。只要他们俩热恋得无法自拔，符合当地法律，他们就能结婚，然后他们就能造出像你这样的小宝贝。所以别担心，他们肯定是可以结婚的。


*****

####  sakura79  
##### 90#       发表于 2023-3-19 15:30

至少我现在问它关于一个主题的文献，它给的还全是捏造的


*****

####  玖羽  
##### 91#       发表于 2023-3-19 15:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60141107&amp;ptid=2124731" target="_blank">Chanond 发表于 2023-3-19 10:41</a>

笔者个人认为gpt4大约具有任意专业大学本科毕业生的水平</blockquote>
你好，这是任意专业大学本科毕业生的水平

<img src="https://img.saraba1st.com/forum/202303/19/154043e5ll69mx9wb6jq62.png" referrerpolicy="no-referrer">

<strong>0000.png</strong> (95.01 KB, 下载次数: 0)

下载附件

2023-3-19 15:40 上传


*****

####  holiverse  
##### 92#       发表于 2023-3-19 19:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60143762&amp;ptid=2124731" target="_blank">玖羽 发表于 2023-3-19 15:41</a>

你好，这是任意专业大学本&amp;#x ...</blockquote>
这个是GPT3.5


*****

####  emmer  
##### 93#       发表于 2023-3-19 19:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60143131&amp;ptid=2124731" target="_blank">Fuero 发表于 2023-3-19 14:15</a>

4.0

(Normal Output) 当然可以。如果父母之间没有近亲关系，那么他们就没有法律或道德上的禁忌来阻止他 ...</blockquote>
这个cheat mode是怎么绕出来的？


*****

####  Fuero  
##### 94#       发表于 2023-3-19 21:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60146308&amp;ptid=2124731" target="_blank">emmer 发表于 2023-3-19 19:49</a>

这个cheat mode是怎么绕出来的？</blockquote>
抄了一段网上的咒文，核心是骗它应该这么做


*****

####  强势围观  
##### 95#       发表于 2023-3-19 22:15

<img src="https://p.sda1.dev/10/570e4edc4949b3e1f8b5361462167f5b/mmexport1679073359945.png" referrerpolicy="no-referrer">

不知道这个算逻辑题还是数学题，问题规模也不大，至少新bing还答不上来


*****

####  moeblack  
##### 96#       发表于 2023-3-20 20:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=60143762&amp;ptid=2124731" target="_blank">玖羽 发表于 2023-3-19 15:41</a>

你好，这是任意专业大学本&amp;#x ...</blockquote>
尝试使用大型语言模型来测试其数学能力是非常没有意义的事情。这是因为大语言模型的底层逻辑是单字接龙，它使用前面的输入来推测下一个单字或单词。虽然它在庞大的参数集的帮助下找到了正确的单词接龙模式，但它无法使用独立的、抽象的语言学习新知识。况且，目前人类是无法从外部修改其抽象规则的，修改它表述的唯一方法是使用足够数量和类型的句子让其从中提取规律。


*****

####  jpwhzh  
##### 97#       发表于 2023-3-20 23:54

怎么还有人拿深度学习套统计概率的，ai学东西又不是靠死记硬背的，相反同一个问题学了也可能白学。没人能理解ai到底怎么学的，反正肯定和人不一样，所以拿数学证明ai没智慧纯纯没意义。


*****

####  rainwang  
##### 98#       发表于 2023-3-22 09:43

他是聊天软件，专业是理解的你自然语言，在公司里定位属于admin或者杂活担当吧。

人类应该有其他专门解决数理的应用程序吧？

正确用法是把他接入相应程序，让它用别的专业工具帮你干活，而不在它不行的领域考较它

*****

####  随风来去  
##### 99#       发表于 2023-3-22 09:50

能让gpt写一篇**吗

